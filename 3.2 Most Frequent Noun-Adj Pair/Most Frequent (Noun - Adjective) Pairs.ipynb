{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e8535c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries needed\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import matplotlib as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd\n",
    "import random\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.lang.en import English\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import requests\n",
    "from spacy.symbols import nsubj, amod, nsubj, acomp, conj, VERB, NOUN, AUX, PRON, ADJ\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75494a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is B636-6DD6\n",
      "\n",
      " Directory of C:\\Users\\JIA SHENG\\Documents\\My Projects\\CZ4045-project1\\3.2 Most Frequent Noun-Adj Pair\n",
      "\n",
      "25/10/2021  03:45 PM    <DIR>          .\n",
      "25/10/2021  03:45 PM    <DIR>          ..\n",
      "25/10/2021  03:45 PM    <DIR>          .ipynb_checkpoints\n",
      "25/10/2021  03:19 PM            21,320 Most Frequent (Noun - Adjective) Pairs.ipynb\n",
      "               1 File(s)         21,320 bytes\n",
      "               3 Dir(s)  28,809,060,352 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ec63917",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "reviews = pd.read_json('../data/reviewSelected100.json', encoding='ISO-8859-1', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea8dd19",
   "metadata": {},
   "source": [
    "### Top 10 Noun Adjective pairs for 1 stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cae97eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('experience', 'bad'), 7), (('service', 'horrible'), 5), (('service', 'bad'), 5), (('food', 'chinese'), 4), (('food', 'horrible'), 3), (('experience', 'terrible'), 3), (('experience', 'absolute'), 2), (('restaurant', 'chinese'), 2), (('time', 'whole'), 2), (('family', 'other'), 2)]\n"
     ]
    }
   ],
   "source": [
    "rating1 = reviews.loc[reviews['stars'] == 1]\n",
    "rating1.drop_duplicates(subset=['business_id'])\n",
    "rating1 = rating1.sample(50)\n",
    "rating1 = list(rating1['text'])\n",
    "rating1 = [nlp(rating.lower()) for rating in rating1]\n",
    "\n",
    "noun_adj_pairs_one = []\n",
    "\n",
    "def checkconj(token, noun, neg):\n",
    "    for child in token.children:\n",
    "        if child.dep == conj:\n",
    "            adjective = child.lemma_ if neg == False else \"not \" + child.lemma_ \n",
    "            noun_adj_pairs_one.append((noun, adjective))\n",
    "            checkconj(child, noun, neg)\n",
    "                 \n",
    "for rating in rating1:\n",
    "    sentence_spans = list(rating.sents)\n",
    "    for sentence in sentence_spans:\n",
    "        for token in sentence:\n",
    "            if token.dep == amod and token.head.pos is NOUN:\n",
    "                noun = token.head.lemma_ \n",
    "                noun_adj_pairs_one.append((noun,token.lemma_))\n",
    "                #check if there are other ADJ conjuncted \n",
    "                checkconj(token, noun, False)\n",
    "                \n",
    "            elif token.dep == acomp:\n",
    "                for child in token.head.children:\n",
    "                    \n",
    "                    #Check for negation modifier\n",
    "                    neg = False\n",
    "                    for word in token.head.children:\n",
    "                        if(word.dep_ == \"neg\"):\n",
    "                            neg = True\n",
    "                            break\n",
    "                    \n",
    "                    if(child.dep == nsubj):\n",
    "                        noun = child.lemma_ if token.head.pos == NOUN else child.text\n",
    "                        adjective = token.lemma_ if neg == False else \"not \" + token.lemma_ \n",
    "                        noun_adj_pairs_one.append((noun, adjective))\n",
    "                        #check if there are other ADJ conjuncted                      \n",
    "                        checkconj(token, noun, neg)\n",
    "noun_adj_pairs_one\n",
    "\n",
    "c = Counter(noun_adj_pairs_one)\n",
    "print (c.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a990187c",
   "metadata": {},
   "source": [
    "### Top 10 Noun Adjective pairs for 2 stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b85dac8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('i', 'disappointed'), 4), (('service', 'slow'), 4), (('food', 'fast'), 3), (('staff', 'friendly'), 3), (('food', 'average'), 3), (('food', 'good'), 3), (('pork', 'pull'), 3), (('buffet', 'chinese'), 3), (('hotel', 'other'), 2), (('week', 'few'), 2)]\n"
     ]
    }
   ],
   "source": [
    "rating1 = reviews.loc[reviews['stars'] == 2]\n",
    "rating1.drop_duplicates(subset=['business_id'])\n",
    "rating1 = rating1.sample(50)\n",
    "rating1 = list(rating1['text'])\n",
    "rating1 = [nlp(rating.lower()) for rating in rating1]\n",
    "\n",
    "noun_adj_pairs_two = []\n",
    "\n",
    "def checkconj(token, noun, neg):\n",
    "    for child in token.children:\n",
    "        if child.dep == conj:\n",
    "            adjective = child.lemma_ if neg == False else \"not \" + child.lemma_ \n",
    "            noun_adj_pairs_two.append((noun, adjective))\n",
    "            checkconj(child, noun, neg)\n",
    "                 \n",
    "for rating in rating1:\n",
    "    sentence_spans = list(rating.sents)\n",
    "    for sentence in sentence_spans:\n",
    "        for token in sentence:\n",
    "            if token.dep == amod and token.head.pos is NOUN:\n",
    "                noun = token.head.lemma_ \n",
    "                noun_adj_pairs_two.append((noun,token.lemma_))\n",
    "                #check if there are other ADJ conjuncted \n",
    "                checkconj(token, noun, False)\n",
    "                \n",
    "            elif token.dep == acomp:\n",
    "                #print(token.text)\n",
    "                for child in token.head.children:\n",
    "                    #Check for negation modifier\n",
    "                    neg = False\n",
    "                    for word in token.head.children:\n",
    "                        if(word.dep_ == \"neg\"):\n",
    "                            neg = True\n",
    "                            break\n",
    "                    if(child.dep == nsubj):\n",
    "                        noun = child.lemma_ if token.head.pos == NOUN else child.text\n",
    "                        adjective = token.lemma_ if neg == False else \"not \" + token.lemma_ \n",
    "                        noun_adj_pairs_two.append((noun, adjective))\n",
    "                        #check if there are other ADJ conjuncted \n",
    "                        checkconj(token, noun, neg)\n",
    "noun_adj_pairs_two\n",
    "c = Counter(noun_adj_pairs_two)\n",
    "print (c.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ced591c",
   "metadata": {},
   "source": [
    "### Top 10 Noun Adjective pairs for 3 stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "63edbe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('food', 'good'), 6), (('which', 'good'), 3), (('service', 'good'), 3), (('it', 'expensive'), 3), (('marshmallow', 'burn'), 2), (('job', 'good'), 2), (('i', 'surprised'), 2), (('food', 'decent'), 2), (('food', 'average'), 2), (('waiter', 'nice'), 2)]\n"
     ]
    }
   ],
   "source": [
    "rating1 = reviews.loc[reviews['stars'] == 3]\n",
    "rating1.drop_duplicates(subset=['business_id'])\n",
    "rating1 = rating1.sample(50)\n",
    "rating1 = list(rating1['text'])\n",
    "rating1 = [nlp(rating.lower()) for rating in rating1]\n",
    "\n",
    "noun_adj_pairs_three = []\n",
    "\n",
    "def checkconj(token, noun, neg):\n",
    "    for child in token.children:\n",
    "        if child.dep == conj:\n",
    "            adjective = child.lemma_ if neg == False else \"not \" + child.lemma_ \n",
    "            noun_adj_pairs_three.append((noun, adjective))\n",
    "            checkconj(child, noun, neg)\n",
    "                 \n",
    "for rating in rating1:\n",
    "    sentence_spans = list(rating.sents)\n",
    "    for sentence in sentence_spans:\n",
    "        for token in sentence:\n",
    "            if token.dep == amod and token.head.pos is NOUN:\n",
    "                noun = token.head.lemma_ \n",
    "                noun_adj_pairs_three.append((noun,token.lemma_))\n",
    "                #check if there are other ADJ conjuncted \n",
    "                checkconj(token, noun, False)\n",
    "                \n",
    "            elif token.dep == acomp:\n",
    "                #print(token.text)\n",
    "                for child in token.head.children:\n",
    "                    \n",
    "                    #Check for negation modifier\n",
    "                    neg = False\n",
    "                    for word in token.head.children:\n",
    "                        if(word.dep_ == \"neg\"):\n",
    "                            neg = True\n",
    "                            break\n",
    "                    \n",
    "                    if(child.dep == nsubj):\n",
    "                        noun = child.lemma_ if token.head.pos == NOUN else child.text\n",
    "                        adjective = token.lemma_ if neg == False else \"not \" + token.lemma_ \n",
    "                        noun_adj_pairs_three.append((noun,adjective))\n",
    "                        #check if there are other ADJ conjuncted \n",
    "                        checkconj(token, noun, neg)\n",
    "noun_adj_pairs_three\n",
    "\n",
    "c = Counter(noun_adj_pairs_three)\n",
    "print (c.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29def87",
   "metadata": {},
   "source": [
    "### Top 10 Noun Adjective pairs for 4 stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "af8ce3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('food', 'good'), 12), (('it', 'good'), 7), (('place', 'good'), 6), (('price', 'reasonable'), 4), (('time', 'first'), 4), (('restaurant', 'korean'), 3), (('service', 'good'), 3), (('staff', 'friendly'), 3), (('food', 'fresh'), 3), (('food', 'korean'), 3)]\n"
     ]
    }
   ],
   "source": [
    "rating1 = reviews.loc[reviews['stars'] == 4]\n",
    "rating1.drop_duplicates(subset=['business_id'])\n",
    "rating1 = rating1.sample(50)\n",
    "rating1 = list(rating1['text'])\n",
    "rating1 = [nlp(rating.lower()) for rating in rating1]\n",
    "\n",
    "noun_adj_pairs_four = []\n",
    "\n",
    "def checkconj(token, noun, neg):\n",
    "    for child in token.children:\n",
    "        if child.dep == conj:\n",
    "            adjective = child.lemma_ if neg == False else \"not \" + child.lemma_ \n",
    "            noun_adj_pairs_four.append((noun, adjective))\n",
    "            checkconj(child, noun, neg)\n",
    "                 \n",
    "for rating in rating1:\n",
    "    sentence_spans = list(rating.sents)\n",
    "    for sentence in sentence_spans:\n",
    "        for token in sentence:\n",
    "            if token.dep == amod and token.head.pos is NOUN:\n",
    "                noun = token.head.lemma_ \n",
    "                noun_adj_pairs_four.append((noun,token.lemma_))\n",
    "                #check if there are other ADJ conjuncted \n",
    "                checkconj(token, noun, False) \n",
    "                \n",
    "            elif token.dep == acomp:\n",
    "                #print(token.text)\n",
    "                for child in token.head.children:\n",
    "                    \n",
    "                     #Check for negation modifier\n",
    "                    neg = False\n",
    "                    for word in token.head.children:\n",
    "                        if(word.dep_ == \"neg\"):\n",
    "                            neg = True\n",
    "                            break\n",
    "                    \n",
    "                    if(child.dep == nsubj):\n",
    "                        noun = child.lemma_ if token.head.pos == NOUN else child.text\n",
    "                        adjective = token.lemma_ if neg == False else \"not \" + token.lemma_ \n",
    "                        noun_adj_pairs_four.append((noun,adjective))\n",
    "                        #check if there are other ADJ conjuncted \n",
    "                        checkconj(token, noun, neg)\n",
    "noun_adj_pairs_four\n",
    "\n",
    "c = Counter(noun_adj_pairs_four)\n",
    "print (c.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa125083",
   "metadata": {},
   "source": [
    "### Top 10 Noun Adjective pairs for 5 stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4b6dc826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('it', 'good'), 6), (('staff', 'friendly'), 5), (('food', 'delicious'), 3), (('food', 'amazing'), 3), (('service', 'awesome'), 3), (('food', 'great'), 3), (('place', 'small'), 2), (('hygienist', 'dental'), 2), (('service', 'excellent'), 2), (('size', 'regular'), 2)]\n"
     ]
    }
   ],
   "source": [
    "rating1 = reviews.loc[reviews['stars'] == 5]\n",
    "rating1.drop_duplicates(subset=['business_id'])\n",
    "rating1 = rating1.sample(50)\n",
    "rating1 = list(rating1['text'])\n",
    "rating1 = [nlp(rating.lower()) for rating in rating1]\n",
    "\n",
    "noun_adj_pairs_five = []\n",
    "\n",
    "def checkconj(token, noun, neg):\n",
    "    for child in token.children:\n",
    "        if child.dep == conj:\n",
    "            adjective = child.lemma_ if neg == False else \"not \" + child.lemma_ \n",
    "            noun_adj_pairs_five.append((noun, adjective))\n",
    "            checkconj(child, noun, neg)\n",
    "                 \n",
    "for rating in rating1:\n",
    "    sentence_spans = list(rating.sents)\n",
    "    for sentence in sentence_spans:\n",
    "        for token in sentence:\n",
    "            if token.dep == amod and token.head.pos is NOUN:\n",
    "                noun = token.head.lemma_ \n",
    "                noun_adj_pairs_five.append((noun,token.lemma_))\n",
    "                #check if there are other ADJ conjuncted \n",
    "                checkconj(token, noun, False)\n",
    "                \n",
    "            elif token.dep == acomp:\n",
    "                #print(token.text)\n",
    "                for child in token.head.children:\n",
    "                    \n",
    "                    #Check for negation modifier\n",
    "                    neg = False\n",
    "                    for word in token.head.children:\n",
    "                        if(word.dep_ == \"neg\"):\n",
    "                            neg = True\n",
    "                            break\n",
    "                    \n",
    "                    if(child.dep == nsubj):\n",
    "                        noun = child.lemma_ if token.head.pos == NOUN else child.text\n",
    "                        adjective = token.lemma_ if neg == False else \"not \" + token.lemma_ \n",
    "                        noun_adj_pairs_five.append((noun,adjective))\n",
    "                        #check if there are other ADJ conjuncted \n",
    "                        checkconj(token, noun, neg)\n",
    "noun_adj_pairs_five\n",
    "\n",
    "c = Counter(noun_adj_pairs_five)\n",
    "print (c.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3166ef3b",
   "metadata": {},
   "source": [
    "## NLTK vader sentimental analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bd178f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\JIA\n",
      "[nltk_data]     SHENG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "233ac3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "#The Compound score is a metric that calculates the sum of all the lexicon ratings \n",
    "#which have been normalized between -1(most extreme negative) and +1 \n",
    "#(most extreme positive).\n",
    "\n",
    "def get_sentimental_score(noun_adj_pairs):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    numPos = 0\n",
    "    numNeg = 0\n",
    "    numNeu = 0\n",
    "    sentimental_score = 0\n",
    "    for pair in noun_adj_pairs:\n",
    "        x = sia.polarity_scores(pair[1]) \n",
    "        compound = x.get(\"compound\")\n",
    "        sentimental_score += compound\n",
    "        if compound >= 0.05:\n",
    "            numPos += 1\n",
    "        elif compound >0.05 and compound < 0.05 :\n",
    "            numNeu += 1\n",
    "        elif compound <= -0.05:\n",
    "            numNeg += 1\n",
    "            \n",
    "    sentimental_score /= len(noun_adj_pairs)\n",
    "    return sentimental_score, numPos, numNeg, numNeu\n",
    "\n",
    "#sentimental analysis for 1 star\n",
    "sentimental_score_one, one_pos, one_neg, one_neu = get_sentimental_score(noun_adj_pairs_one)\n",
    "sentimental_score_two, two_pos, two_neg, two_neu = get_sentimental_score(noun_adj_pairs_two)\n",
    "sentimental_score_three, three_pos, three_neg, three_neu = get_sentimental_score(noun_adj_pairs_three)\n",
    "sentimental_score_four, four_pos, four_neg, four_neu = get_sentimental_score(noun_adj_pairs_four)\n",
    "sentimental_score_five, five_pos, five_neg, five_neu = get_sentimental_score(noun_adj_pairs_five)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "96f99e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For one star review, the average compound score is: -0.048514647887323965 #of positive words: 62, # of negative words: 89, # of neutral words: 0 \n",
      "For two star review, the average compound score is: 0.052908627450980364#of positive words: 115, # of negative words: 54, # of neutral words: 0 \n",
      "For three star review, the average compound score is: 0.10780743243243228#of positive words: 138, # of negative words: 30, # of neutral words: 0 \n",
      "For four star review, the average compound score is: 0.1534163179916314#of positive words: 170, # of negative words: 14, # of neutral words: 0 \n",
      "For five star review, the average compound score is: 0.1844296536796533#of positive words: 196, # of negative words: 19, # of neutral words: 0 \n"
     ]
    }
   ],
   "source": [
    "print('For one star review, the average compound score is: {} #of positive words: {}, # of negative words: {}, # of neutral words: {} '.format(sentimental_score_one,one_pos,one_neg, one_neu))\n",
    "print('For two star review, the average compound score is: {}#of positive words: {}, # of negative words: {}, # of neutral words: {} '.format(sentimental_score_two,two_pos,two_neg, two_neu))\n",
    "print('For three star review, the average compound score is: {}#of positive words: {}, # of negative words: {}, # of neutral words: {} '.format(sentimental_score_three,three_pos,three_neg, three_neu))\n",
    "print('For four star review, the average compound score is: {}#of positive words: {}, # of negative words: {}, # of neutral words: {} '.format(sentimental_score_four,four_pos,four_neg, four_neu))\n",
    "print('For five star review, the average compound score is: {}#of positive words: {}, # of negative words: {}, # of neutral words: {} '.format(sentimental_score_five,five_pos,five_neg, five_neu))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
