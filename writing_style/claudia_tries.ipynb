{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e6fb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries needed\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from collections import Counter\n",
    "# import httplib2\n",
    "import itertools\n",
    "import matplotlib as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd \n",
    "import random\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.lang.en import English\n",
    "import urllib.request\n",
    "from urllib.request import urlopen, Request\n",
    "import random\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc45d509-90f8-4db6-a063-13e17fad1c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e70f63a",
   "metadata": {},
   "source": [
    "## Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2790af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_json('../data/reviewSelected100.json', encoding='ISO-8859-1', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1e12df",
   "metadata": {},
   "source": [
    "## 3.2 Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14711fd",
   "metadata": {},
   "source": [
    "### Tokenisation and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78f7f863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9318</th>\n",
       "      <td>o1I5vkgoK5JYqW0sbGJowA</td>\n",
       "      <td>rTIVsxvTEm5b94C2th5xQQ</td>\n",
       "      <td>AktuBx1W7c3ZdzwuaOp8xg</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Gross!! I tried it cuz I woke across the stree...</td>\n",
       "      <td>2014-03-14 04:03:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9359</th>\n",
       "      <td>x0m4DhqCX4Gqf-r7Am8VhQ</td>\n",
       "      <td>bC6kZANVn0-S19Y91drogA</td>\n",
       "      <td>AktuBx1W7c3ZdzwuaOp8xg</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fantastic, we tried 5 items and they were all ...</td>\n",
       "      <td>2016-06-12 04:35:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9361</th>\n",
       "      <td>wnd6yVRVZEibaRJs4Jjgqg</td>\n",
       "      <td>HJj82f-csBI7jjgenwqhvw</td>\n",
       "      <td>AktuBx1W7c3ZdzwuaOp8xg</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Not far from the house I really wanted to try ...</td>\n",
       "      <td>2011-12-01 07:09:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9366</th>\n",
       "      <td>Jvm_diKSnZX2I8tYKbRN2Q</td>\n",
       "      <td>eytpwJXgg5nWU6jrlQ6qAA</td>\n",
       "      <td>AktuBx1W7c3ZdzwuaOp8xg</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Dumpling is in their name and I didn't try one...</td>\n",
       "      <td>2014-01-18 14:58:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9372</th>\n",
       "      <td>LPrp5XfAp86T33mHZ7Rkyw</td>\n",
       "      <td>7SijZ5lsoXWfCW3rKZ5BCg</td>\n",
       "      <td>AktuBx1W7c3ZdzwuaOp8xg</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Came here for late lunch with my husband and s...</td>\n",
       "      <td>2015-12-21 22:31:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   review_id                 user_id             business_id  \\\n",
       "9318  o1I5vkgoK5JYqW0sbGJowA  rTIVsxvTEm5b94C2th5xQQ  AktuBx1W7c3ZdzwuaOp8xg   \n",
       "9359  x0m4DhqCX4Gqf-r7Am8VhQ  bC6kZANVn0-S19Y91drogA  AktuBx1W7c3ZdzwuaOp8xg   \n",
       "9361  wnd6yVRVZEibaRJs4Jjgqg  HJj82f-csBI7jjgenwqhvw  AktuBx1W7c3ZdzwuaOp8xg   \n",
       "9366  Jvm_diKSnZX2I8tYKbRN2Q  eytpwJXgg5nWU6jrlQ6qAA  AktuBx1W7c3ZdzwuaOp8xg   \n",
       "9372  LPrp5XfAp86T33mHZ7Rkyw  7SijZ5lsoXWfCW3rKZ5BCg  AktuBx1W7c3ZdzwuaOp8xg   \n",
       "\n",
       "      stars  useful  funny  cool  \\\n",
       "9318      1       3      1     0   \n",
       "9359      5       0      0     0   \n",
       "9361      2       3      0     0   \n",
       "9366      4       6      6     6   \n",
       "9372      4       0      0     0   \n",
       "\n",
       "                                                   text                date  \n",
       "9318  Gross!! I tried it cuz I woke across the stree... 2014-03-14 04:03:47  \n",
       "9359  fantastic, we tried 5 items and they were all ... 2016-06-12 04:35:12  \n",
       "9361  Not far from the house I really wanted to try ... 2011-12-01 07:09:23  \n",
       "9366  Dumpling is in their name and I didn't try one... 2014-01-18 14:58:34  \n",
       "9372  Came here for late lunch with my husband and s... 2015-12-21 22:31:27  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get reviews for a random business \n",
    "random_business = reviews.sample()\n",
    "random_business_id = random_business.iloc[0]['business_id']\n",
    "small_business_dataset = reviews.loc[reviews['business_id'] == random_business_id]\n",
    "small_business_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c91d93e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_business_dataset_reviews = list(small_business_dataset['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0669b8f6-714b-4708-840b-2c65c03f97eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the reviews into a concatenated string \n",
    "b1_review = ''.join(small_business_dataset_reviews)\n",
    "clean_review = re.sub(r\"[^A-Za-z0-9\\s]+\", \"\", b1_review)\n",
    "b1_review = nlp(clean_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deaa0847-5dec-4317-b9f5-ece17562bfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 463), ('and', 414), ('I', 306), ('to', 246), ('a', 241), ('was', 216), ('it', 167), ('is', 167), ('of', 158), ('for', 125)]\n"
     ]
    }
   ],
   "source": [
    "# removed punctuation and get the top 10 most common words (including stopwords)\n",
    "b1_review_words = [token.text for token in b1_review if token.is_alpha == True] \n",
    "b1_word_freq = Counter(b1_review_words)\n",
    "common_words = b1_word_freq.most_common(10)\n",
    "print(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ede74a1b-4e6c-4436-8c3b-df2f479aad26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('food', 111), ('nt', 82), ('place', 63), ('good', 63), ('order', 61), ('chicken', 51), ('Chinese', 49), ('like', 40), ('ordered', 32), ('shrimp', 31)]\n"
     ]
    }
   ],
   "source": [
    "# removed punctuation and get the top 10 most common words (excluding stopwords)\n",
    "b1_review_words = [token.text for token in b1_review if token.is_stop != True and token.is_alpha == True] \n",
    "b1_word_freq = Counter(b1_review_words)\n",
    "common_words = b1_word_freq.most_common(10)\n",
    "print(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82e4306f-2536-450b-ba7d-cc0f073dfef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: plot log graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeb35a0e-7b64-4e9a-9d53-e89a299e51ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we do some stemming after removing the stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "porter_st = PorterStemmer()\n",
    "lancaster_st = LancasterStemmer()\n",
    "snow_st = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfe90886-30ac-4282-978f-f66739952d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('food', 119), ('order', 110), ('nt', 82), ('place', 78), ('chicken', 75), ('good', 68), ('chines', 60), ('littl', 49), ('like', 46), ('shrimp', 42)]\n"
     ]
    }
   ],
   "source": [
    "# Using Porter Stemmer\n",
    "porter_stemmed_words = [porter_st.stem(word) for word in b1_review_words]\n",
    "porter_freq = Counter(porter_stemmed_words)\n",
    "porter_common = porter_freq.most_common(10)\n",
    "print(porter_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "993edaec-02a4-4bef-9a21-c61302974a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('food', 119), ('ord', 110), ('nt', 82), ('plac', 78), ('chick', 75), ('good', 68), ('chines', 60), ('littl', 49), ('lik', 46), ('shrimp', 41)]\n"
     ]
    }
   ],
   "source": [
    "# Using Lancaster Stemmer\n",
    "lancaster_stemmed_words = [lancaster_st.stem(word) for word in b1_review_words]\n",
    "lancaster_freq = Counter(lancaster_stemmed_words)\n",
    "lancaster_common = lancaster_freq.most_common(10)\n",
    "print(lancaster_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32ce69f4-074a-4ab0-ae2d-d6e466205781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('food', 119), ('order', 110), ('nt', 82), ('place', 78), ('chicken', 75), ('good', 68), ('chines', 60), ('littl', 49), ('like', 46), ('shrimp', 42)]\n"
     ]
    }
   ],
   "source": [
    "# Using Snowball Stemmer\n",
    "snow_stemmed_words = [snow_st.stem(word) for word in b1_review_words]\n",
    "snow_freq = Counter(snow_stemmed_words)\n",
    "snow_common = snow_freq.most_common(10)\n",
    "print(snow_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603d6c54",
   "metadata": {},
   "source": [
    "### POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4c24448",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sentences = reviews.sample(5, random_state=42)\n",
    "random_sentences = list(random_sentences['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c81cc594-a486-47fa-91bf-0f4043a6cd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Que ce soit pour leurs délicieux bubbles tea/smooties, leurs ''Bánh mì'' , leurs petits snacks (viennoiseries, tapioca, ...), on adore Vua et aussi leurs prix très abordables. On y retourne lorsqu'on est dans le Quartier Latin !\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8155e95-94cb-490a-bbff-2db99e5b7cf0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Que', 'NNP'),\n",
       "  ('ce', 'NN'),\n",
       "  ('soit', 'VBD'),\n",
       "  ('pour', 'JJ'),\n",
       "  ('leurs', 'NNS'),\n",
       "  ('délicieux', 'VBP'),\n",
       "  ('bubbles', 'NNS'),\n",
       "  ('tea/smooties', 'NNS'),\n",
       "  (',', ','),\n",
       "  ('leurs', 'VBZ'),\n",
       "  ('``', '``'),\n",
       "  ('Bánh', 'NNP'),\n",
       "  ('mì', 'NN'),\n",
       "  (\"''\", \"''\"),\n",
       "  (',', ','),\n",
       "  ('leurs', 'VBZ'),\n",
       "  ('petits', 'NNS'),\n",
       "  ('snacks', 'NNS'),\n",
       "  ('(', '('),\n",
       "  ('viennoiseries', 'NNS'),\n",
       "  (',', ','),\n",
       "  ('tapioca', 'NN'),\n",
       "  (',', ','),\n",
       "  ('...', ':'),\n",
       "  (')', ')'),\n",
       "  (',', ','),\n",
       "  ('on', 'IN'),\n",
       "  ('adore', 'IN'),\n",
       "  ('Vua', 'NNP'),\n",
       "  ('et', 'CC'),\n",
       "  ('aussi', 'JJ'),\n",
       "  ('leurs', 'NNS'),\n",
       "  ('prix', 'VBP'),\n",
       "  ('très', 'JJ'),\n",
       "  ('abordables', 'NNS'),\n",
       "  ('.', '.'),\n",
       "  ('On', 'IN'),\n",
       "  ('y', 'JJ'),\n",
       "  ('retourne', 'JJ'),\n",
       "  (\"lorsqu'on\", 'NN'),\n",
       "  ('est', 'JJS'),\n",
       "  ('dans', 'NNS'),\n",
       "  ('le', 'VBP'),\n",
       "  ('Quartier', 'NNP'),\n",
       "  ('Latin', 'NNP'),\n",
       "  ('!', '.')],\n",
       " [('As', 'IN'),\n",
       "  ('I', 'PRP'),\n",
       "  (\"'ve\", 'VBP'),\n",
       "  ('said', 'VBD'),\n",
       "  ('previously', 'RB'),\n",
       "  ('...', ':'),\n",
       "  ('we', 'PRP'),\n",
       "  (\"'ve\", 'VBP'),\n",
       "  ('been', 'VBN'),\n",
       "  ('coming', 'VBG'),\n",
       "  ('to', 'TO'),\n",
       "  ('LMAH', 'NNP'),\n",
       "  ('for', 'IN'),\n",
       "  ('over', 'IN'),\n",
       "  ('10', 'CD'),\n",
       "  ('years', 'NNS'),\n",
       "  ('.', '.'),\n",
       "  ('At', 'IN'),\n",
       "  ('least', 'JJS'),\n",
       "  ('15', 'CD'),\n",
       "  ('.', '.'),\n",
       "  ('And', 'CC'),\n",
       "  ('we', 'PRP'),\n",
       "  (\"'ve\", 'VBP'),\n",
       "  ('ALWAYS', 'NNP'),\n",
       "  ('seen', 'VBN'),\n",
       "  ('Dr.', 'NNP'),\n",
       "  ('White', 'NNP'),\n",
       "  ('.', '.'),\n",
       "  ('I', 'PRP'),\n",
       "  ('had', 'VBD'),\n",
       "  ('to', 'TO'),\n",
       "  ('bring', 'VB'),\n",
       "  ('my', 'PRP$'),\n",
       "  ('cat', 'NN'),\n",
       "  ('in', 'IN'),\n",
       "  ('to', 'TO'),\n",
       "  ('have', 'VB'),\n",
       "  ('a', 'DT'),\n",
       "  ('urine', 'JJ'),\n",
       "  ('sample', 'NN'),\n",
       "  ('done', 'VBN'),\n",
       "  ('.', '.'),\n",
       "  ('While', 'IN'),\n",
       "  ('being', 'VBG'),\n",
       "  ('done', 'VBN'),\n",
       "  (',', ','),\n",
       "  ('my', 'PRP$'),\n",
       "  ('cat', 'NN'),\n",
       "  ('pee', 'NN'),\n",
       "  (\"'d\", 'MD'),\n",
       "  ('on', 'IN'),\n",
       "  ('himself', 'PRP'),\n",
       "  ('.', '.'),\n",
       "  ('The', 'DT'),\n",
       "  ('vet', 'NN'),\n",
       "  ('or', 'CC'),\n",
       "  ('staff', 'NN'),\n",
       "  ('only', 'RB'),\n",
       "  ('tried', 'VBD'),\n",
       "  ('to', 'TO'),\n",
       "  ('clean', 'VB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('off', 'IN'),\n",
       "  ('of', 'IN'),\n",
       "  ('him', 'PRP'),\n",
       "  ('with', 'IN'),\n",
       "  ('alcohol', 'NN'),\n",
       "  ('.', '.'),\n",
       "  ('They', 'PRP'),\n",
       "  ('did', 'VBD'),\n",
       "  (\"n't\", 'RB'),\n",
       "  ('try', 'VB'),\n",
       "  ('to', 'TO'),\n",
       "  ('actually', 'RB'),\n",
       "  ('get', 'VB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('off', 'IN'),\n",
       "  ('of', 'IN'),\n",
       "  ('him', 'PRP'),\n",
       "  ('.', '.'),\n",
       "  ('They', 'PRP'),\n",
       "  ('did', 'VBD'),\n",
       "  (\"n't\", 'RB'),\n",
       "  ('even', 'RB'),\n",
       "  ('TELL', 'VB'),\n",
       "  ('ME', 'NNP'),\n",
       "  ('that', 'IN'),\n",
       "  ('he', 'PRP'),\n",
       "  ('pee', 'VBZ'),\n",
       "  (\"'d\", 'MD'),\n",
       "  ('all', 'DT'),\n",
       "  ('over', 'IN'),\n",
       "  ('his', 'PRP$'),\n",
       "  ('stomach', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('legs', 'NN'),\n",
       "  ('.', '.'),\n",
       "  ('So', 'RB'),\n",
       "  ('now', 'RB'),\n",
       "  ('I', 'PRP'),\n",
       "  ('e', 'VBP'),\n",
       "  ('had', 'VBD'),\n",
       "  ('to', 'TO'),\n",
       "  ('give', 'VB'),\n",
       "  ('my', 'PRP$'),\n",
       "  ('cat', 'NN'),\n",
       "  ('a', 'DT'),\n",
       "  ('bath', 'NN'),\n",
       "  ('because', 'IN'),\n",
       "  ('they', 'PRP'),\n",
       "  ('ca', 'MD'),\n",
       "  (\"n't\", 'RB'),\n",
       "  ('take', 'VB'),\n",
       "  ('a', 'DT'),\n",
       "  ('urine', 'JJ'),\n",
       "  ('sample', 'NN'),\n",
       "  ('properly', 'RB'),\n",
       "  ('.', '.'),\n",
       "  ('I', 'PRP'),\n",
       "  ('am', 'VBP'),\n",
       "  ('LIVID', 'NNP'),\n",
       "  ('.', '.')],\n",
       " [('Pretty', 'NNP'),\n",
       "  ('decent', 'NN'),\n",
       "  ('but', 'CC'),\n",
       "  ('so', 'RB'),\n",
       "  ('spacious', 'JJ'),\n",
       "  ('!', '.'),\n",
       "  ('Very', 'RB'),\n",
       "  ('good', 'JJ'),\n",
       "  ('for', 'IN'),\n",
       "  ('kids', 'NNS'),\n",
       "  ('and', 'CC'),\n",
       "  ('you', 'PRP'),\n",
       "  ('can', 'MD'),\n",
       "  ('order', 'NN'),\n",
       "  ('dim', 'VB'),\n",
       "  ('sum', 'NN'),\n",
       "  ('!', '.'),\n",
       "  ('They', 'PRP'),\n",
       "  (\"'re\", 'VBP'),\n",
       "  ('open', 'JJ'),\n",
       "  ('!', '.'),\n",
       "  ('!', '.'),\n",
       "  ('Free', 'JJ'),\n",
       "  ('wifi', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('awesome', 'JJ'),\n",
       "  (':', ':'),\n",
       "  (')', ')')],\n",
       " [('Dumpling', 'VBG'),\n",
       "  ('Village', 'NNP'),\n",
       "  ('really', 'RB'),\n",
       "  ('suffering', 'VBG'),\n",
       "  ('from', 'IN'),\n",
       "  ('identity', 'NN'),\n",
       "  ('crisis', 'NN'),\n",
       "  ('!', '.'),\n",
       "  ('!', '.'),\n",
       "  ('Is', 'VBZ'),\n",
       "  ('it', 'PRP'),\n",
       "  ('a', 'DT'),\n",
       "  ('Korean', 'JJ'),\n",
       "  ('Restaurant', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('not', 'RB'),\n",
       "  ('really', 'RB'),\n",
       "  ('.', '.'),\n",
       "  ('There', 'EX'),\n",
       "  ('are', 'VBP'),\n",
       "  ('mostly', 'RB'),\n",
       "  ('Northern', 'NNP'),\n",
       "  ('Chinese', 'NNP'),\n",
       "  ('items', 'NNS'),\n",
       "  ('on', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('menu', 'NN'),\n",
       "  ('like', 'IN'),\n",
       "  ('dumplings', 'NNS'),\n",
       "  ('.', '.'),\n",
       "  ('Is', 'VBZ'),\n",
       "  ('it', 'PRP'),\n",
       "  ('a', 'DT'),\n",
       "  ('Northern', 'NNP'),\n",
       "  ('Chinese', 'NNP'),\n",
       "  ('restaurant', 'NN'),\n",
       "  (',', ','),\n",
       "  ('not', 'RB'),\n",
       "  ('really', 'RB'),\n",
       "  ('There', 'EX'),\n",
       "  ('are', 'VBP'),\n",
       "  ('a', 'DT'),\n",
       "  ('lot', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('Korean', 'JJ'),\n",
       "  ('dishes', 'NNS'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('menu', 'NN'),\n",
       "  ('like', 'IN'),\n",
       "  ('pork', 'NN'),\n",
       "  ('bone', 'NN'),\n",
       "  ('soup', 'NN'),\n",
       "  (',', ','),\n",
       "  ('cold', 'JJ'),\n",
       "  ('wheat', 'NN'),\n",
       "  ('bucknoodle', 'NN'),\n",
       "  ('soup', 'NN'),\n",
       "  (',', ','),\n",
       "  ('kimchi', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('bean', 'NN'),\n",
       "  ('sprout', 'NN'),\n",
       "  ('as', 'IN'),\n",
       "  ('appetitizers', 'NNS'),\n",
       "  ('.', '.'),\n",
       "  ('The', 'DT'),\n",
       "  ('only', 'JJ'),\n",
       "  ('Korean', 'JJ'),\n",
       "  ('characters', 'NNS'),\n",
       "  ('are', 'VBP'),\n",
       "  ('the', 'DT'),\n",
       "  ('3', 'CD'),\n",
       "  ('on', 'IN'),\n",
       "  ('their', 'PRP$'),\n",
       "  ('business', 'NN'),\n",
       "  ('sign', 'NN'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('front', 'NN'),\n",
       "  ('..', 'NNP'),\n",
       "  ('and', 'CC'),\n",
       "  ('all', 'PDT'),\n",
       "  ('the', 'DT'),\n",
       "  ('rest', 'NN'),\n",
       "  ('are', 'VBP'),\n",
       "  ('in', 'IN'),\n",
       "  ('Chinese', 'NNP'),\n",
       "  ('and', 'CC'),\n",
       "  ('English', 'NNP'),\n",
       "  ('.', '.'),\n",
       "  ('All', 'PDT'),\n",
       "  ('the', 'DT'),\n",
       "  ('wait', 'NN'),\n",
       "  ('staffs', 'NNS'),\n",
       "  ('here', 'RB'),\n",
       "  ('speak', 'VBP'),\n",
       "  ('Mandarian', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('even', 'RB'),\n",
       "  ('most', 'JJS'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('patrons', 'NNS'),\n",
       "  ('are', 'VBP'),\n",
       "  ('Chinese', 'JJ'),\n",
       "  ('.', '.'),\n",
       "  ('It', 'PRP'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('located', 'VBN'),\n",
       "  ('in', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('really', 'RB'),\n",
       "  ('tiny', 'JJ'),\n",
       "  ('strip', 'NN'),\n",
       "  ('mall', 'NN'),\n",
       "  ('..', 'NN'),\n",
       "  ('with', 'IN'),\n",
       "  ('limited', 'JJ'),\n",
       "  ('parkings', 'NNS'),\n",
       "  ('!', '.'),\n",
       "  ('To', 'TO'),\n",
       "  ('tell', 'VB'),\n",
       "  ('you', 'PRP'),\n",
       "  ('the', 'DT'),\n",
       "  ('truth', 'NN'),\n",
       "  ('I', 'PRP'),\n",
       "  ('am', 'VBP'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('area', 'NN'),\n",
       "  ('for', 'IN'),\n",
       "  ('over', 'IN'),\n",
       "  ('10', 'CD'),\n",
       "  ('years', 'NNS'),\n",
       "  ('I', 'PRP'),\n",
       "  ('never', 'RB'),\n",
       "  ('notice', 'VBP'),\n",
       "  ('it', 'PRP'),\n",
       "  ('until', 'IN'),\n",
       "  ('I', 'PRP'),\n",
       "  ('read', 'VBP'),\n",
       "  ('the', 'DT'),\n",
       "  ('reviews', 'NNS'),\n",
       "  ('on', 'IN'),\n",
       "  ('yelp', 'NN'),\n",
       "  ('!', '.'),\n",
       "  ('We', 'PRP'),\n",
       "  ('arrived', 'VBD'),\n",
       "  ('around', 'RB'),\n",
       "  ('6', 'CD'),\n",
       "  ('pm', 'NN'),\n",
       "  ('on', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('Saturday', 'NNP'),\n",
       "  ('.', '.'),\n",
       "  ('The', 'DT'),\n",
       "  ('restaurant', 'NN'),\n",
       "  ('was', 'VBD'),\n",
       "  ('almost', 'RB'),\n",
       "  ('full', 'JJ'),\n",
       "  ('.', '.'),\n",
       "  ('The', 'DT'),\n",
       "  ('tables', 'NNS'),\n",
       "  ('are', 'VBP'),\n",
       "  ('not', 'RB'),\n",
       "  ('really', 'RB'),\n",
       "  ('packed', 'VBN'),\n",
       "  ('together', 'RB'),\n",
       "  (',', ','),\n",
       "  ('so', 'IN'),\n",
       "  ('you', 'PRP'),\n",
       "  ('still', 'RB'),\n",
       "  ('have', 'VBP'),\n",
       "  ('a', 'DT'),\n",
       "  ('certain', 'JJ'),\n",
       "  ('degree', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('privacy', 'NN'),\n",
       "  ('at', 'IN'),\n",
       "  ('least', 'JJS'),\n",
       "  ('I', 'PRP'),\n",
       "  ('can', 'MD'),\n",
       "  ('not', 'RB'),\n",
       "  ('tell', 'VB'),\n",
       "  ('what', 'WP'),\n",
       "  ('the', 'DT'),\n",
       "  ('table', 'NN'),\n",
       "  ('next', 'JJ'),\n",
       "  ('to', 'TO'),\n",
       "  ('me', 'PRP'),\n",
       "  ('were', 'VBD'),\n",
       "  ('eating', 'VBG'),\n",
       "  ('.', '.'),\n",
       "  ('We', 'PRP'),\n",
       "  ('decided', 'VBD'),\n",
       "  ('on', 'IN'),\n",
       "  ('my', 'PRP$'),\n",
       "  ('favourite', 'JJ'),\n",
       "  ('chives', 'NNS'),\n",
       "  ('and', 'CC'),\n",
       "  ('pork', 'NN'),\n",
       "  ('dumplings', 'NNS'),\n",
       "  (',', ','),\n",
       "  ('kimchi', 'NNS'),\n",
       "  ('fried', 'VBD'),\n",
       "  ('rice', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('Korean', 'NNP'),\n",
       "  ('cold', 'VBD'),\n",
       "  ('bucknoodle', 'JJ'),\n",
       "  ('soup', 'NN'),\n",
       "  ('.', '.'),\n",
       "  ('They', 'PRP'),\n",
       "  ('are', 'VBP'),\n",
       "  ('all', 'DT'),\n",
       "  ('$', '$'),\n",
       "  ('4.99', 'CD'),\n",
       "  ('.', '.'),\n",
       "  ('The', 'DT'),\n",
       "  ('cold', 'JJ'),\n",
       "  ('noodle', 'JJ'),\n",
       "  ('soup', 'NN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('so', 'RB'),\n",
       "  ('so', 'RB'),\n",
       "  ('good', 'JJ'),\n",
       "  ('!', '.'),\n",
       "  ('Nice', 'NNP'),\n",
       "  ('and', 'CC'),\n",
       "  ('refreshing', 'VBG'),\n",
       "  ('!', '.'),\n",
       "  ('and', 'CC'),\n",
       "  ('the', 'DT'),\n",
       "  ('soup', 'NN'),\n",
       "  ('based', 'VBN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('a', 'DT'),\n",
       "  ('little', 'JJ'),\n",
       "  ('sour', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('it', 'PRP'),\n",
       "  ('really', 'RB'),\n",
       "  ('stimulate', 'VB'),\n",
       "  ('your', 'PRP$'),\n",
       "  ('tastebuds', 'NNS'),\n",
       "  ('and', 'CC'),\n",
       "  ('just', 'RB'),\n",
       "  ('make', 'VB'),\n",
       "  ('you', 'PRP'),\n",
       "  ('want', 'VB'),\n",
       "  ('to', 'TO'),\n",
       "  ('eat', 'VB'),\n",
       "  ('more', 'JJR'),\n",
       "  ('!', '.'),\n",
       "  ('(', '('),\n",
       "  ('I', 'PRP'),\n",
       "  ('can', 'MD'),\n",
       "  ('finish', 'VB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('all', 'DT'),\n",
       "  ('myself', 'PRP'),\n",
       "  ('!', '.'),\n",
       "  ('I', 'PRP'),\n",
       "  ('do', 'VBP'),\n",
       "  (\"n't\", 'RB'),\n",
       "  ('want', 'VB'),\n",
       "  ('to', 'TO'),\n",
       "  ('share', 'NN'),\n",
       "  ('!', '.'),\n",
       "  ('I', 'PRP'),\n",
       "  ('want', 'VBP'),\n",
       "  ('one', 'CD'),\n",
       "  ('all', 'DT'),\n",
       "  ('for', 'IN'),\n",
       "  ('myself', 'PRP'),\n",
       "  ('next', 'JJ'),\n",
       "  ('time', 'NN'),\n",
       "  ('!', '.'),\n",
       "  (')', ')'),\n",
       "  ('The', 'DT'),\n",
       "  ('kimchi', 'NN'),\n",
       "  ('fried', 'VBD'),\n",
       "  ('rice', 'NN'),\n",
       "  ('..', 'NNP'),\n",
       "  ('hmmmmm', 'NN'),\n",
       "  ('not', 'RB'),\n",
       "  ('good', 'JJ'),\n",
       "  ('!', '.'),\n",
       "  ('A', 'DT'),\n",
       "  ('little', 'JJ'),\n",
       "  ('on', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('oily', 'JJ'),\n",
       "  ('side', 'NN'),\n",
       "  ('.', '.'),\n",
       "  ('There', 'EX'),\n",
       "  ('are', 'VBP'),\n",
       "  ('not', 'RB'),\n",
       "  ('much', 'JJ'),\n",
       "  ('taste', 'NN'),\n",
       "  (',', ','),\n",
       "  ('not', 'RB'),\n",
       "  ('spicy', 'VB'),\n",
       "  ('enough', 'RB'),\n",
       "  ('?', '.'),\n",
       "  ('We', 'PRP'),\n",
       "  ('could', 'MD'),\n",
       "  ('not', 'RB'),\n",
       "  ('finish', 'VB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('and', 'CC'),\n",
       "  ('end', 'VB'),\n",
       "  ('up', 'RB'),\n",
       "  ('have', 'VBP'),\n",
       "  ('to', 'TO'),\n",
       "  ('pack', 'VB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('all', 'DT'),\n",
       "  ('to', 'TO'),\n",
       "  ('go', 'VB'),\n",
       "  ('...', ':'),\n",
       "  ('(', '('),\n",
       "  ('not', 'RB'),\n",
       "  ('even', 'RB'),\n",
       "  ('sure', 'JJ'),\n",
       "  ('I', 'PRP'),\n",
       "  ('will', 'MD'),\n",
       "  ('eat', 'VB'),\n",
       "  ('it', 'PRP'),\n",
       "  (',', ','),\n",
       "  ('but', 'CC'),\n",
       "  ('can', 'MD'),\n",
       "  ('not', 'RB'),\n",
       "  ('just', 'RB'),\n",
       "  ('let', 'VB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('all', 'DT'),\n",
       "  ('go', 'VBP'),\n",
       "  ('to', 'TO'),\n",
       "  ('waste', 'NN'),\n",
       "  (')', ')'),\n",
       "  ('The', 'DT'),\n",
       "  ('dumplings', 'NNS'),\n",
       "  ('arrived', 'VBD'),\n",
       "  ('last', 'JJ'),\n",
       "  ('!', '.'),\n",
       "  ('But', 'CC'),\n",
       "  ('it', 'PRP'),\n",
       "  ('really', 'RB'),\n",
       "  ('worth', 'VBZ'),\n",
       "  ('the', 'DT'),\n",
       "  ('wait', 'NN'),\n",
       "  ('!', '.'),\n",
       "  ('14', 'CD'),\n",
       "  ('big', 'JJ'),\n",
       "  ('fat', 'NN'),\n",
       "  ('hot', 'JJ'),\n",
       "  ('dumplings', 'NNS'),\n",
       "  ('filled', 'VBN'),\n",
       "  ('up', 'RP'),\n",
       "  ('the', 'DT'),\n",
       "  ('whole', 'JJ'),\n",
       "  ('steamer', 'NN'),\n",
       "  ('!', '.'),\n",
       "  ('Yes', 'UH'),\n",
       "  ('I', 'PRP'),\n",
       "  ('counted', 'VBD'),\n",
       "  ('them', 'PRP'),\n",
       "  ('14', 'CD'),\n",
       "  ('of', 'IN'),\n",
       "  ('them', 'PRP'),\n",
       "  ('for', 'IN'),\n",
       "  ('$', '$'),\n",
       "  ('4.99', 'CD'),\n",
       "  ('.', '.'),\n",
       "  ('They', 'PRP'),\n",
       "  ('are', 'VBP'),\n",
       "  ('all', 'DT'),\n",
       "  ('freshly', 'RB'),\n",
       "  ('made', 'VBN'),\n",
       "  (',', ','),\n",
       "  ('freshly', 'RB'),\n",
       "  ('steamed', 'VBN'),\n",
       "  ('!', '.'),\n",
       "  ('The', 'DT'),\n",
       "  ('skin', 'NN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('nice', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('thin', 'JJ'),\n",
       "  (',', ','),\n",
       "  ('not', 'RB'),\n",
       "  ('chewy', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('thick', 'JJ'),\n",
       "  ('!', '.'),\n",
       "  ('Oh', 'NNP'),\n",
       "  ('so', 'RB'),\n",
       "  ('delicious', 'JJ'),\n",
       "  ('!', '.'),\n",
       "  ('One', 'CD'),\n",
       "  ('bite', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('all', 'PDT'),\n",
       "  ('the', 'DT'),\n",
       "  ('soup', 'NN'),\n",
       "  ('are', 'VBP'),\n",
       "  ('ozzing', 'VBG'),\n",
       "  ('out', 'RP'),\n",
       "  ('!', '.'),\n",
       "  ('But', 'CC'),\n",
       "  ('if', 'IN'),\n",
       "  ('they', 'PRP'),\n",
       "  ('are', 'VBP'),\n",
       "  ('not', 'RB'),\n",
       "  ('burning', 'VBG'),\n",
       "  ('hot', 'JJ'),\n",
       "  (',', ','),\n",
       "  ('you', 'PRP'),\n",
       "  ('can', 'MD'),\n",
       "  ('just', 'RB'),\n",
       "  ('stuff', 'VB'),\n",
       "  ('the', 'DT'),\n",
       "  ('whole', 'JJ'),\n",
       "  ('thing', 'NN'),\n",
       "  ('into', 'IN'),\n",
       "  ('your', 'PRP$'),\n",
       "  ('mouth', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('let', 'VB'),\n",
       "  ('the', 'DT'),\n",
       "  ('soup', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('favour', 'NN'),\n",
       "  ('just', 'RB'),\n",
       "  ('explosed', 'VBN'),\n",
       "  ('in', 'IN'),\n",
       "  ('your', 'PRP$'),\n",
       "  ('mouth', 'NN'),\n",
       "  ('.', '.'),\n",
       "  ('Just', 'VB'),\n",
       "  ('a', 'DT'),\n",
       "  ('warning', 'NN'),\n",
       "  ('.', '.'),\n",
       "  ('If', 'IN'),\n",
       "  ('you', 'PRP'),\n",
       "  ('going', 'VBG'),\n",
       "  ('out', 'RP'),\n",
       "  ('on', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('date', 'NN'),\n",
       "  (',', ','),\n",
       "  ('please', 'VB'),\n",
       "  ('do', 'VBP'),\n",
       "  (\"n't\", 'RB'),\n",
       "  ('come', 'VB'),\n",
       "  ('here', 'RB'),\n",
       "  ('.', '.'),\n",
       "  ('Even', 'RB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('a', 'DT'),\n",
       "  ('good', 'JJ'),\n",
       "  ('place', 'NN'),\n",
       "  ('for', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('cheap', 'JJ'),\n",
       "  ('date', 'NN'),\n",
       "  (',', ','),\n",
       "  ('our', 'PRP$'),\n",
       "  ('bill', 'NN'),\n",
       "  ('was', 'VBD'),\n",
       "  ('$', '$'),\n",
       "  ('18', 'CD'),\n",
       "  ('for', 'IN'),\n",
       "  ('2', 'CD'),\n",
       "  ('and', 'CC'),\n",
       "  ('we', 'PRP'),\n",
       "  ('were', 'VBD'),\n",
       "  ('full', 'JJ'),\n",
       "  ('!', '.'),\n",
       "  ('But', 'CC'),\n",
       "  ('the', 'DT'),\n",
       "  ('place', 'NN'),\n",
       "  ('can', 'MD'),\n",
       "  ('be', 'VB'),\n",
       "  ('noisy', 'RB'),\n",
       "  (',', ','),\n",
       "  ('the', 'DT'),\n",
       "  ('food', 'NN'),\n",
       "  ('too', 'RB'),\n",
       "  ('good', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('your', 'PRP$'),\n",
       "  ('date', 'NN'),\n",
       "  ('will', 'MD'),\n",
       "  ('be', 'VB'),\n",
       "  ('too', 'RB'),\n",
       "  ('busy', 'JJ'),\n",
       "  ('eating', 'VBG'),\n",
       "  ('and', 'CC'),\n",
       "  ('just', 'RB'),\n",
       "  ('ignore', 'VB'),\n",
       "  ('you', 'PRP'),\n",
       "  ('!', '.'),\n",
       "  ('Or', 'CC'),\n",
       "  ('you', 'PRP'),\n",
       "  ('will', 'MD'),\n",
       "  ('keep', 'VB'),\n",
       "  ('eating', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('eating', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('you', 'PRP'),\n",
       "  ('freak', 'VBP'),\n",
       "  ('all', 'DT'),\n",
       "  ('your', 'PRP$'),\n",
       "  ('friends', 'NNS'),\n",
       "  ('out', 'RP'),\n",
       "  ('!', '.'),\n",
       "  ('The', 'DT'),\n",
       "  ('services', 'NNS'),\n",
       "  ('here', 'RB'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('cold', 'JJ'),\n",
       "  ('but', 'CC'),\n",
       "  ('efficient', 'JJ'),\n",
       "  ('.', '.'),\n",
       "  ('We', 'PRP'),\n",
       "  ('were', 'VBD'),\n",
       "  ('given', 'VBN'),\n",
       "  ('extra', 'JJ'),\n",
       "  ('napkins', 'NNS'),\n",
       "  ('without', 'IN'),\n",
       "  ('requesting', 'VBG'),\n",
       "  ('...', ':'),\n",
       "  ('Maybe', 'RB'),\n",
       "  ('we', 'PRP'),\n",
       "  ('looked', 'VBD'),\n",
       "  ('really', 'RB'),\n",
       "  ('messy', 'VBN'),\n",
       "  ('?', '.'),\n",
       "  ('?', '.'),\n",
       "  ('Cash', 'NNP'),\n",
       "  ('only', 'RB'),\n",
       "  ('!', '.')],\n",
       " [('best', 'JJS'),\n",
       "  ('pizza', 'NN'),\n",
       "  ('in', 'IN'),\n",
       "  ('south', 'JJ'),\n",
       "  ('side', 'NN'),\n",
       "  ('.', '.'),\n",
       "  ('huge', 'JJ'),\n",
       "  ('drink', 'NN'),\n",
       "  ('selection', 'NN'),\n",
       "  ('.', '.'),\n",
       "  ('awesome', 'VB'),\n",
       "  ('atmosphere', 'RB'),\n",
       "  ('.', '.'),\n",
       "  ('$', '$'),\n",
       "  ('4', 'CD'),\n",
       "  ('for', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('slice', 'NN'),\n",
       "  ('that', 'WDT'),\n",
       "  ('could', 'MD'),\n",
       "  ('easily', 'RB'),\n",
       "  ('feed', 'VB'),\n",
       "  ('2', 'CD'),\n",
       "  ('people', 'NNS'),\n",
       "  ('!', '.')]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_tagged = []\n",
    "for sentence in random_sentences:\n",
    "    nltk_tagged.append((nltk.pos_tag(word_tokenize(sentence))))\n",
    "nltk_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d874c6c-1f0f-4232-b819-693f49a971a2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Que      PROPN \n",
      "ce       PROPN \n",
      "soit     ADJ   \n",
      "pour     NOUN  \n",
      "leurs    VERB  \n",
      "délicieux NOUN  \n",
      "bubbles  NOUN  \n",
      "tea      NOUN  \n",
      "/        SYM   \n",
      "smooties NOUN  \n",
      ",        PUNCT \n",
      "leurs    VERB  \n",
      "''       PUNCT \n",
      "Bánh     PROPN \n",
      "mì       INTJ  \n",
      "''       PUNCT \n",
      ",        PUNCT \n",
      "leurs    NOUN  \n",
      "petits   VERB  \n",
      "snacks   NOUN  \n",
      "(        PUNCT \n",
      "viennoiseries NOUN  \n",
      ",        PUNCT \n",
      "tapioca  INTJ  \n",
      ",        PUNCT \n",
      "...      PUNCT \n",
      ")        PUNCT \n",
      ",        PUNCT \n",
      "on       ADP   \n",
      "adore    PROPN \n",
      "Vua      PROPN \n",
      "et       PROPN \n",
      "aussi    PROPN \n",
      "leurs    VERB  \n",
      "prix     NOUN  \n",
      "très     ADJ   \n",
      "abordables NOUN  \n",
      ".        PUNCT \n",
      "On       ADP   \n",
      "y        PROPN \n",
      "retourne VERB  \n",
      "lorsqu'on PROPN \n",
      "est      PROPN \n",
      "dans     PROPN \n",
      "le       X     \n",
      "Quartier PROPN \n",
      "Latin    PROPN \n",
      "!        PUNCT \n",
      "As       ADP   \n",
      "I        PRON  \n",
      "'ve      AUX   \n",
      "said     VERB  \n",
      "previously ADV   \n",
      "...      PUNCT \n",
      "we've    PROPN \n",
      "been     AUX   \n",
      "coming   VERB  \n",
      "to       ADP   \n",
      "LMAH     PROPN \n",
      "for      ADP   \n",
      "over     ADP   \n",
      "10       NUM   \n",
      "years    NOUN  \n",
      ".        PUNCT \n",
      "At       ADV   \n",
      "least    ADJ   \n",
      "15       NUM   \n",
      ".        PUNCT \n",
      "And      CCONJ \n",
      "we       PRON  \n",
      "'ve      AUX   \n",
      "ALWAYS   ADV   \n",
      "seen     VERB  \n",
      "Dr.      PROPN \n",
      "White    PROPN \n",
      ".        PUNCT \n",
      "\n",
      "        SPACE \n",
      "I        PRON  \n",
      "had      VERB  \n",
      "to       PART  \n",
      "bring    VERB  \n",
      "my       PRON  \n",
      "cat      NOUN  \n",
      "in       ADP   \n",
      "to       PART  \n",
      "have     VERB  \n",
      "a        DET   \n",
      "urine    NOUN  \n",
      "sample   NOUN  \n",
      "done     VERB  \n",
      ".        PUNCT \n",
      "While    SCONJ \n",
      "being    AUX   \n",
      "done     VERB  \n",
      ",        PUNCT \n",
      "my       PRON  \n",
      "cat      NOUN  \n",
      "pee'd    ADV   \n",
      "on       ADP   \n",
      "himself  PRON  \n",
      ".        PUNCT \n",
      "The      DET   \n",
      "vet      NOUN  \n",
      "or       CCONJ \n",
      "staff    NOUN  \n",
      "only     ADV   \n",
      "tried    VERB  \n",
      "to       PART  \n",
      "clean    VERB  \n",
      "it       PRON  \n",
      "off      ADP   \n",
      "of       ADP   \n",
      "him      PRON  \n",
      "with     ADP   \n",
      "alcohol  NOUN  \n",
      ".        PUNCT \n",
      "They     PRON  \n",
      "did      AUX   \n",
      "n't      PART  \n",
      "try      VERB  \n",
      "to       PART  \n",
      "actually ADV   \n",
      "get      VERB  \n",
      "it       PRON  \n",
      "off      ADP   \n",
      "of       ADP   \n",
      "him      PRON  \n",
      ".        PUNCT \n",
      "They     PRON  \n",
      "did      AUX   \n",
      "n't      PART  \n",
      "even     ADV   \n",
      "TELL     VERB  \n",
      "ME       PRON  \n",
      "that     SCONJ \n",
      "he       PRON  \n",
      "pee'd    VERB  \n",
      "all      ADV   \n",
      "over     ADP   \n",
      "his      PRON  \n",
      "stomach  NOUN  \n",
      "and      CCONJ \n",
      "legs     NOUN  \n",
      ".        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "So       ADV   \n",
      "now      ADV   \n",
      "I        PRON  \n",
      "e        VERB  \n",
      "had      VERB  \n",
      "to       PART  \n",
      "give     VERB  \n",
      "my       PRON  \n",
      "cat      NOUN  \n",
      "a        DET   \n",
      "bath     NOUN  \n",
      "because  SCONJ \n",
      "they     PRON  \n",
      "ca       AUX   \n",
      "n't      PART  \n",
      "take     VERB  \n",
      "a        DET   \n",
      "urine    NOUN  \n",
      "sample   NOUN  \n",
      "properly ADV   \n",
      ".        PUNCT \n",
      "I        PRON  \n",
      "am       AUX   \n",
      "LIVID    PROPN \n",
      ".        PUNCT \n",
      "Pretty   ADV   \n",
      "decent   ADJ   \n",
      "but      CCONJ \n",
      "so       ADV   \n",
      "spacious ADJ   \n",
      "!        PUNCT \n",
      "         SPACE \n",
      "Very     ADV   \n",
      "good     ADJ   \n",
      "for      ADP   \n",
      "kids     NOUN  \n",
      "and      CCONJ \n",
      "you      PRON  \n",
      "can      AUX   \n",
      "order    VERB  \n",
      "dim      NOUN  \n",
      "sum      NOUN  \n",
      "!        PUNCT \n",
      "They     PRON  \n",
      "'re      VERB  \n",
      "open     ADJ   \n",
      "!        PUNCT \n",
      "!        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "Free     ADJ   \n",
      "wifi     NOUN  \n",
      "and      CCONJ \n",
      "awesome  ADJ   \n",
      ":)       PUNCT \n",
      "Dumpling PROPN \n",
      "Village  PROPN \n",
      "really   ADV   \n",
      "suffering VERB  \n",
      "from     ADP   \n",
      "identity NOUN  \n",
      "crisis   NOUN  \n",
      "!        PUNCT \n",
      "!        PUNCT \n",
      "Is       AUX   \n",
      "it       PRON  \n",
      "a        DET   \n",
      "Korean   PROPN \n",
      "Restaurant PROPN \n",
      ",        PUNCT \n",
      "not      PART  \n",
      "really   ADV   \n",
      ".        PUNCT \n",
      "There    PRON  \n",
      "are      AUX   \n",
      "mostly   ADV   \n",
      "Northern ADJ   \n",
      "Chinese  ADJ   \n",
      "items    NOUN  \n",
      "on       ADP   \n",
      "the      DET   \n",
      "menu     NOUN  \n",
      "like     ADP   \n",
      "dumplings NOUN  \n",
      ".        PUNCT \n",
      "Is       AUX   \n",
      "it       PRON  \n",
      "a        DET   \n",
      "Northern ADJ   \n",
      "Chinese  ADJ   \n",
      "restaurant NOUN  \n",
      ",        PUNCT \n",
      "not      PART  \n",
      "really   ADV   \n",
      "There    PRON  \n",
      "are      AUX   \n",
      "a        DET   \n",
      "lot      NOUN  \n",
      "of       ADP   \n",
      "Korean   ADJ   \n",
      "dishes   NOUN  \n",
      "         SPACE \n",
      "in       ADP   \n",
      "the      DET   \n",
      "menu     NOUN  \n",
      "like     ADP   \n",
      "pork     NOUN  \n",
      "bone     NOUN  \n",
      "soup     NOUN  \n",
      ",        PUNCT \n",
      "cold     ADJ   \n",
      "wheat    NOUN  \n",
      "bucknoodle NOUN  \n",
      "soup     NOUN  \n",
      ",        PUNCT \n",
      "kimchi   PROPN \n",
      "and      CCONJ \n",
      "bean     NOUN  \n",
      "sprout   NOUN  \n",
      "as       ADP   \n",
      "appetitizers NOUN  \n",
      ".        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "The      DET   \n",
      "only     ADJ   \n",
      "Korean   ADJ   \n",
      "characters NOUN  \n",
      "are      AUX   \n",
      "the      DET   \n",
      "3        NUM   \n",
      "on       ADP   \n",
      "their    PRON  \n",
      "business NOUN  \n",
      "sign     NOUN  \n",
      "in       ADP   \n",
      "the      DET   \n",
      "front    NOUN  \n",
      "..       PUNCT \n",
      "and      CCONJ \n",
      "all      DET   \n",
      "the      DET   \n",
      "rest     NOUN  \n",
      "are      VERB  \n",
      "in       ADP   \n",
      "Chinese  PROPN \n",
      "and      CCONJ \n",
      "English  PROPN \n",
      ".        PUNCT \n",
      "All      DET   \n",
      "the      DET   \n",
      "wait     ADJ   \n",
      "staffs   NOUN  \n",
      "here     ADV   \n",
      "speak    VERB  \n",
      "Mandarian PROPN \n",
      "and      CCONJ \n",
      "even     ADV   \n",
      "most     ADJ   \n",
      "of       ADP   \n",
      "the      DET   \n",
      "patrons  NOUN  \n",
      "are      VERB  \n",
      "Chinese  ADJ   \n",
      ".        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "It       PRON  \n",
      "is       AUX   \n",
      "located  VERB  \n",
      "in       ADP   \n",
      "a        DET   \n",
      "really   ADV   \n",
      "tiny     ADJ   \n",
      "strip    NOUN  \n",
      "mall     NOUN  \n",
      "..       PUNCT \n",
      "with     ADP   \n",
      "limited  ADJ   \n",
      "parkings NOUN  \n",
      "!        PUNCT \n",
      "To       PART  \n",
      "tell     VERB  \n",
      "you      PRON  \n",
      "the      DET   \n",
      "truth    NOUN  \n",
      "I        PRON  \n",
      "am       VERB  \n",
      "in       ADP   \n",
      "the      DET   \n",
      "area     NOUN  \n",
      "for      ADP   \n",
      "over     ADP   \n",
      "10       NUM   \n",
      "years    NOUN  \n",
      "I        PRON  \n",
      "never    ADV   \n",
      "notice   VERB  \n",
      "it       PRON  \n",
      "until    ADP   \n",
      "I        PRON  \n",
      "read     VERB  \n",
      "the      DET   \n",
      "reviews  NOUN  \n",
      "on       ADP   \n",
      "yelp     NOUN  \n",
      "!        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "We       PRON  \n",
      "arrived  VERB  \n",
      "around   ADV   \n",
      "6        NUM   \n",
      "pm       NOUN  \n",
      "on       ADP   \n",
      "a        DET   \n",
      "Saturday PROPN \n",
      ".        PUNCT \n",
      "The      DET   \n",
      "restaurant NOUN  \n",
      "was      AUX   \n",
      "almost   ADV   \n",
      "full     ADJ   \n",
      ".        PUNCT \n",
      "         SPACE \n",
      "The      DET   \n",
      "tables   NOUN  \n",
      "are      AUX   \n",
      "not      PART  \n",
      "really   ADV   \n",
      "packed   VERB  \n",
      "together ADV   \n",
      ",        PUNCT \n",
      "so       ADV   \n",
      "you      PRON  \n",
      "still    ADV   \n",
      "have     VERB  \n",
      "a        DET   \n",
      "certain  ADJ   \n",
      "degree   NOUN  \n",
      "of       ADP   \n",
      "privacy  NOUN  \n",
      "at       ADP   \n",
      "least    ADJ   \n",
      "I        PRON  \n",
      "can      AUX   \n",
      "not      PART  \n",
      "tell     VERB  \n",
      "what     PRON  \n",
      "the      DET   \n",
      "table    NOUN  \n",
      "next     ADV   \n",
      "to       ADP   \n",
      "me       PRON  \n",
      "were     AUX   \n",
      "eating   VERB  \n",
      ".        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "We       PRON  \n",
      "decided  VERB  \n",
      "on       ADP   \n",
      "my       PRON  \n",
      "favourite ADJ   \n",
      "chives   NOUN  \n",
      "and      CCONJ \n",
      "pork     NOUN  \n",
      "dumplings NOUN  \n",
      ",        PUNCT \n",
      "kimchi   PROPN \n",
      "fried    VERB  \n",
      "rice     NOUN  \n",
      "and      CCONJ \n",
      "Korean   ADJ   \n",
      "cold     ADJ   \n",
      "bucknoodle NOUN  \n",
      "soup     NOUN  \n",
      ".        PUNCT \n",
      "They     PRON  \n",
      "are      AUX   \n",
      "all      ADV   \n",
      "$        SYM   \n",
      "4.99     NUM   \n",
      ".        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "The      DET   \n",
      "cold     ADJ   \n",
      "noodle   NOUN  \n",
      "soup     NOUN  \n",
      "is       AUX   \n",
      "so       ADV   \n",
      "so       ADV   \n",
      "good     ADJ   \n",
      "!        PUNCT \n",
      "Nice     ADJ   \n",
      "and      CCONJ \n",
      "refreshing ADJ   \n",
      "!        PUNCT \n",
      "and      CCONJ \n",
      "the      DET   \n",
      "soup     NOUN  \n",
      "based    VERB  \n",
      "is       AUX   \n",
      "a        DET   \n",
      "little   ADJ   \n",
      "sour     ADJ   \n",
      "and      CCONJ \n",
      "it       PRON  \n",
      "really   ADV   \n",
      "stimulate VERB  \n",
      "your     PRON  \n",
      "tastebuds NOUN  \n",
      "and      CCONJ \n",
      "just     ADV   \n",
      "make     VERB  \n",
      "you      PRON  \n",
      "want     VERB  \n",
      "to       PART  \n",
      "eat      VERB  \n",
      "more     ADJ   \n",
      "!        PUNCT \n",
      "(        PUNCT \n",
      "I        PRON  \n",
      "can      AUX   \n",
      "finish   VERB  \n",
      "it       PRON  \n",
      "all      DET   \n",
      "myself   PRON  \n",
      "!        PUNCT \n",
      "I        PRON  \n",
      "do       AUX   \n",
      "n't      PART  \n",
      "want     VERB  \n",
      "to       PART  \n",
      "share    VERB  \n",
      "!        PUNCT \n",
      "I        PRON  \n",
      "want     VERB  \n",
      "one      NUM   \n",
      "all      DET   \n",
      "for      ADP   \n",
      "myself   PRON  \n",
      "next     ADJ   \n",
      "time     NOUN  \n",
      "!        PUNCT \n",
      ")        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "The      DET   \n",
      "kimchi   PROPN \n",
      "fried    VERB  \n",
      "rice     NOUN  \n",
      "..       PUNCT \n",
      "hmmmmm   ADV   \n",
      "not      PART  \n",
      "good     ADJ   \n",
      "!        PUNCT \n",
      "A        DET   \n",
      "little   ADJ   \n",
      "on       ADP   \n",
      "the      DET   \n",
      "oily     ADJ   \n",
      "side     NOUN  \n",
      ".        PUNCT \n",
      "There    PRON  \n",
      "are      AUX   \n",
      "not      PART  \n",
      "much     ADJ   \n",
      "taste    NOUN  \n",
      ",        PUNCT \n",
      "not      PART  \n",
      "spicy    ADJ   \n",
      "enough   ADV   \n",
      "?        PUNCT \n",
      "We       PRON  \n",
      "could    AUX   \n",
      "not      PART  \n",
      "finish   VERB  \n",
      "it       PRON  \n",
      "and      CCONJ \n",
      "end      VERB  \n",
      "up       ADP   \n",
      "have     VERB  \n",
      "to       PART  \n",
      "pack     VERB  \n",
      "it       PRON  \n",
      "all      DET   \n",
      "to       PART  \n",
      "go       VERB  \n",
      "...      PUNCT \n",
      "(not     INTJ  \n",
      "even     ADV   \n",
      "sure     ADJ   \n",
      "I        PRON  \n",
      "will     AUX   \n",
      "eat      VERB  \n",
      "it       PRON  \n",
      ",        PUNCT \n",
      "but      CCONJ \n",
      "can      AUX   \n",
      "not      PART  \n",
      "just     ADV   \n",
      "let      VERB  \n",
      "it       PRON  \n",
      "all      DET   \n",
      "go       VERB  \n",
      "to       AUX   \n",
      "waste    VERB  \n",
      ")        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "The      DET   \n",
      "dumplings NOUN  \n",
      "arrived  VERB  \n",
      "last     ADJ   \n",
      "!        PUNCT \n",
      "But      CCONJ \n",
      "it       PRON  \n",
      "really   ADV   \n",
      "worth    ADJ   \n",
      "the      DET   \n",
      "wait     NOUN  \n",
      "!        PUNCT \n",
      "14       NUM   \n",
      "big      ADJ   \n",
      "fat      ADJ   \n",
      "hot      ADJ   \n",
      "dumplings NOUN  \n",
      "filled   VERB  \n",
      "up       ADP   \n",
      "the      DET   \n",
      "whole    ADJ   \n",
      "steamer  NOUN  \n",
      "!        PUNCT \n",
      "Yes      INTJ  \n",
      "I        PRON  \n",
      "counted  VERB  \n",
      "them     PRON  \n",
      "14       NUM   \n",
      "of       ADP   \n",
      "them     PRON  \n",
      "for      ADP   \n",
      "$        SYM   \n",
      "4.99     NUM   \n",
      ".        PUNCT \n",
      "They     PRON  \n",
      "are      AUX   \n",
      "all      DET   \n",
      "freshly  ADV   \n",
      "made     VERB  \n",
      ",        PUNCT \n",
      "freshly  ADV   \n",
      "steamed  ADJ   \n",
      "!        PUNCT \n",
      "The      DET   \n",
      "skin     NOUN  \n",
      "is       AUX   \n",
      "nice     ADJ   \n",
      "and      CCONJ \n",
      "thin     ADJ   \n",
      ",        PUNCT \n",
      "not      PART  \n",
      "chewy    NOUN  \n",
      "and      CCONJ \n",
      "thick    ADJ   \n",
      "!        PUNCT \n",
      "Oh       INTJ  \n",
      "so       ADV   \n",
      "delicious ADJ   \n",
      "!        PUNCT \n",
      "One      NUM   \n",
      "bite     NOUN  \n",
      "and      CCONJ \n",
      "all      DET   \n",
      "the      DET   \n",
      "soup     NOUN  \n",
      "are      AUX   \n",
      "ozzing   VERB  \n",
      "out      ADP   \n",
      "!        PUNCT \n",
      "But      CCONJ \n",
      "if       SCONJ \n",
      "they     PRON  \n",
      "are      AUX   \n",
      "not      PART  \n",
      "burning  VERB  \n",
      "hot      ADJ   \n",
      ",        PUNCT \n",
      "you      PRON  \n",
      "can      AUX   \n",
      "just     ADV   \n",
      "stuff    VERB  \n",
      "the      DET   \n",
      "whole    ADJ   \n",
      "thing    NOUN  \n",
      "into     ADP   \n",
      "your     PRON  \n",
      "mouth    NOUN  \n",
      "and      CCONJ \n",
      "let      VERB  \n",
      "the      DET   \n",
      "soup     NOUN  \n",
      "and      CCONJ \n",
      "favour   NOUN  \n",
      "just     ADV   \n",
      "explosed VERB  \n",
      "in       ADP   \n",
      "your     PRON  \n",
      "mouth    NOUN  \n",
      ".        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "Just     ADV   \n",
      "a        DET   \n",
      "warning  NOUN  \n",
      ".        PUNCT \n",
      "If       SCONJ \n",
      "you      PRON  \n",
      "going    VERB  \n",
      "out      ADP   \n",
      "on       ADP   \n",
      "a        DET   \n",
      "date     NOUN  \n",
      ",        PUNCT \n",
      "please   INTJ  \n",
      "do       AUX   \n",
      "n't      PART  \n",
      "come     VERB  \n",
      "here     ADV   \n",
      ".        PUNCT \n",
      "Even     ADV   \n",
      "it       PRON  \n",
      "is       VERB  \n",
      "a        DET   \n",
      "good     ADJ   \n",
      "place    NOUN  \n",
      "for      ADP   \n",
      "a        DET   \n",
      "cheap    ADJ   \n",
      "date     NOUN  \n",
      ",        PUNCT \n",
      "our      PRON  \n",
      "bill     NOUN  \n",
      "was      AUX   \n",
      "$        SYM   \n",
      "18       NUM   \n",
      "for      ADP   \n",
      "2        NUM   \n",
      "and      CCONJ \n",
      "we       PRON  \n",
      "were     VERB  \n",
      "full     ADJ   \n",
      "!        PUNCT \n",
      "But      CCONJ \n",
      "the      DET   \n",
      "place    NOUN  \n",
      "can      AUX   \n",
      "be       VERB  \n",
      "noisy    ADJ   \n",
      ",        PUNCT \n",
      "the      DET   \n",
      "food     NOUN  \n",
      "too      ADV   \n",
      "good     ADJ   \n",
      "and      CCONJ \n",
      "your     PRON  \n",
      "date     NOUN  \n",
      "will     AUX   \n",
      "be       VERB  \n",
      "too      ADV   \n",
      "busy     ADJ   \n",
      "eating   VERB  \n",
      "and      CCONJ \n",
      "just     ADV   \n",
      "ignore   VERB  \n",
      "you      PRON  \n",
      "!        PUNCT \n",
      "Or       CCONJ \n",
      "you      PRON  \n",
      "will     AUX   \n",
      "keep     VERB  \n",
      "eating   VERB  \n",
      "and      CCONJ \n",
      "eating   VERB  \n",
      "and      CCONJ \n",
      "you      PRON  \n",
      "freak    VERB  \n",
      "all      DET   \n",
      "your     PRON  \n",
      "friends  NOUN  \n",
      "out      ADP   \n",
      "!        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "The      DET   \n",
      "services NOUN  \n",
      "here     ADV   \n",
      "is       AUX   \n",
      "cold     ADJ   \n",
      "but      CCONJ \n",
      "efficient ADJ   \n",
      ".        PUNCT \n",
      "We       PRON  \n",
      "were     AUX   \n",
      "given    VERB  \n",
      "extra    ADJ   \n",
      "napkins  NOUN  \n",
      "without  ADP   \n",
      "requesting VERB  \n",
      "...      PUNCT \n",
      "Maybe    ADV   \n",
      "we       PRON  \n",
      "looked   VERB  \n",
      "really   ADV   \n",
      "messy    ADJ   \n",
      "?        PUNCT \n",
      "?        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "Cash     VERB  \n",
      "only     ADV   \n",
      "!        PUNCT \n",
      "best     ADJ   \n",
      "pizza    NOUN  \n",
      "in       ADP   \n",
      "south    ADJ   \n",
      "side     NOUN  \n",
      ".        PUNCT \n",
      "huge     ADJ   \n",
      "drink    NOUN  \n",
      "selection NOUN  \n",
      ".        PUNCT \n",
      "awesome  ADJ   \n",
      "atmosphere NOUN  \n",
      ".        PUNCT \n",
      "$        SYM   \n",
      "4        NUM   \n",
      "for      ADP   \n",
      "a        DET   \n",
      "slice    NOUN  \n",
      "that     DET   \n",
      "could    AUX   \n",
      "easily   ADV   \n",
      "feed     VERB  \n",
      "2        NUM   \n",
      "people   NOUN  \n",
      "!        PUNCT \n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "spacy_tagged = []\n",
    "for sentence in random_sentences:\n",
    "    spacy_tagged.append(nlp(sentence))\n",
    "for tagged in spacy_tagged:\n",
    "    for token in tagged:\n",
    "        print(f'{token.text:{8}} {token.pos_:{6}}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3627839e",
   "metadata": {},
   "source": [
    "# WORK COMPLETED UP TILL HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f44ab",
   "metadata": {},
   "source": [
    "### Writing Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57662d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSOFurl():\n",
    "    while(True):\n",
    "        ip0 = 'stackoverflow'\n",
    "        ip1 = 'com'\n",
    "        ip2 = 'questions'\n",
    "        ip3 = str(random.randint(0, 100000000))\n",
    "        url = 'https://' + ip0 + '.' + ip1 + '/'+ ip2 + '/'+ ip3\n",
    "        try:\n",
    "            urlContent = urlopen(url).read()\n",
    "            if urlContent:\n",
    "                break\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "    print(\"Found URL: \" + url)\n",
    "    page1 = requests.get(url)\n",
    "    soup1 = BeautifulSoup(page1.content, \"html.parser\")\n",
    "    text = list(soup1.find_all(\"p\"))\n",
    "    sof_text = [txt.get_text() for txt in text]\n",
    "   \n",
    "    return sof_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ba56e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHWZurl():\n",
    "    url = 'https://www.hardwarezone.com.sg/home'\n",
    "    reqs = requests.get(url)\n",
    "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "\n",
    "    urls = []\n",
    "    for link in soup.find_all('a'):\n",
    "        urls.append(link.get('href'))\n",
    "    random.shuffle(urls)\n",
    "    while(True):\n",
    "        for url in urls:\n",
    "            print(url)\n",
    "            try:\n",
    "                url = 'https://www.hardwarezone.com.sg' + url\n",
    "                urlContent = urlopen(url).read()\n",
    "                page1 = requests.get(url)\n",
    "                soup1 = BeautifulSoup(page1.content, \"html.parser\")\n",
    "                text = list(soup1.find_all(\"p\"))\n",
    "                hwz_text = [txt.get_text() for txt in text]\n",
    "                if urlContent and len(hwz_text)>10:\n",
    "                    break\n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "        break\n",
    "    print(\"Found URL: \" + url)\n",
    "    return hwz_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aebd797",
   "metadata": {},
   "source": [
    "#### getting random CNA urls\n",
    "## TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e33da49",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/1080411/retrieve-links-from-web-page-using-python-and-beautifulsoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "380f0b1c-e1d2-4e2e-a744-d92781fa7cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, urljoin\n",
    "def getCNAurl():\n",
    "    url = 'https://www.channelnewsasia.com/'\n",
    "    reqs = requests.get(url)\n",
    "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "\n",
    "    linked_urls = set()\n",
    "\n",
    "    def get_all_links(url):\n",
    "        urls = set()\n",
    "        domain_name = urlparse(url).netloc\n",
    "        soup = BeautifulSoup(requests.get(url).content, \"html.parser\")\n",
    "        for a_tag in soup.findAll(\"a\"):\n",
    "            href = a_tag.attrs.get(\"href\")\n",
    "            if href == \"\" or href is None:\n",
    "                # href empty tag\n",
    "                continue\n",
    "            href = urljoin(url, href)\n",
    "            parsed_href = urlparse(href)\n",
    "            # remove URL GET parameters, URL fragments, etc.\n",
    "            href = parsed_href.scheme + \"://\" + parsed_href.netloc + parsed_href.path\n",
    "            if href in urls:\n",
    "                # already in the set\n",
    "                continue\n",
    "            if domain_name not in href:\n",
    "                # external link\n",
    "                continue\n",
    "            if len(href) > 60:\n",
    "                urls.add(href)\n",
    "        return urls\n",
    "    \n",
    "    urls_cna = get_all_links('https://www.channelnewsasia.com/')\n",
    "    \n",
    "    url = random.sample(urls_cna, 1)\n",
    "    print(\"Found URL: \", url[0])\n",
    "\n",
    "    page1 = requests.get(url[0])\n",
    "    soup1 = BeautifulSoup(page1.content, \"html.parser\")\n",
    "    text = list(soup1.find_all(\"p\"))\n",
    "    cna_text = [txt.get_text() for txt in text]\n",
    "   \n",
    "    return cna_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d0d1bf7f-855a-4c4e-b4e7-a07b76d7aecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colot\\AppData\\Local\\Temp/ipykernel_19696/2998851450.py:34: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  url = random.sample(urls_cna, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found URL:  https://www.channelnewsasia.com/singapore/overseas-singaporeans-covid-19-vaccination-dedicated-channels-stay-home-notice-2171251\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19696/2231812654.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcna_text1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetCNAurl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19696/2998851450.py\u001b[0m in \u001b[0;36mgetCNAurl\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Found URL: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0murlContent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mpage1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0msoup1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"html.parser\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cz4045-2\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cz4045-2\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cz4045-2\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m             response = self.parent.error(\n\u001b[0m\u001b[0;32m    633\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cz4045-2\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m \u001b[1;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cz4045-2\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cz4045-2\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "cna_text1 = getCNAurl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876803ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cna_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68030f2-ea56-43d0-910b-ae0d17070a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# why not you push just one line then you push and i can fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f938d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    ip0 = 'https://www.channelnewsasia.com/'\n",
    "    for url in urls:\n",
    "        url2 = ip0 + url\n",
    "        try:\n",
    "            urlContent = urlopen(url2).read()\n",
    "            if urlContent:\n",
    "                break\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            pass\n",
    "    break\n",
    "\n",
    "print(\"Found URL: \" + url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb97780",
   "metadata": {},
   "source": [
    "#### Cleaning text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0b4c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sof_text1 = getSOFurl()\n",
    "sof_text2 = getSOFurl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2104397",
   "metadata": {},
   "outputs": [],
   "source": [
    "hwz_text1 = getHWZurl()\n",
    "hwz_text2 = getHWZurl()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eee8a1e",
   "metadata": {},
   "source": [
    "##### Cleaning SOF text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabf88ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sof_text1 = sof_text1[4:]\n",
    "sof_text1 = sof_text1[:-10]\n",
    "temp_list = []\n",
    "for line in sof_text1:\n",
    "    temp_list += sent_tokenize(line)\n",
    "sof_text1 = temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be9617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sof_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0f4293",
   "metadata": {},
   "outputs": [],
   "source": [
    "sof_text2 = sof_text2[4:]\n",
    "sof_text2 = sof_text2[:-10]\n",
    "temp_list = []\n",
    "for line in sof_text2:\n",
    "    temp_list += sent_tokenize(line)\n",
    "sof_text2 = temp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0fb7f9",
   "metadata": {},
   "source": [
    "##### Cleaning CNA text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626d0987",
   "metadata": {},
   "source": [
    "##### Cleaning HWZ text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c822fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hwz_text1 = hwz_text1[:-5]\n",
    "temp_list = []\n",
    "for line in hwz_text1:\n",
    "    temp_list += sent_tokenize(line)\n",
    "hwz_text1 = temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96f688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hwz_text2 = hwz_text2[:-5]\n",
    "temp_list = []\n",
    "for line in hwz_text2:\n",
    "    temp_list += sent_tokenize(line)\n",
    "hwz_text2 = temp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11179763",
   "metadata": {},
   "source": [
    "##### First word in sentence capitalized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93702e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "uppercount=0\n",
    "for sent in sof_text1:\n",
    "    if sent[0].isupper():\n",
    "        uppercount+=1\n",
    "    count+=1\n",
    "print(\"Fraction of first letter being capitalised for sof_text1: \", uppercount/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ebe5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "uppercount=0\n",
    "for sent in sof_text2:\n",
    "    if sent[0].isupper():\n",
    "        uppercount+=1\n",
    "    count+=1\n",
    "print(\"Fraction of first letter being capitalised for sof_text2: \", uppercount/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913e6519",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "uppercount=0\n",
    "for sent in hwz_text1:\n",
    "    if sent[0].isupper():\n",
    "        uppercount+=1\n",
    "    count+=1\n",
    "print(\"Fraction of first letter being capitalised for hwz_text1: \", uppercount/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80943eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "uppercount=0\n",
    "for sent in hwz_text2:\n",
    "    if sent[0].isupper():\n",
    "        uppercount+=1\n",
    "    count+=1\n",
    "print(\"Fraction of first letter being capitalised for hwz_text2: \", uppercount/count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e31e9b",
   "metadata": {},
   "source": [
    "##### Length of articles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1137d9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No of sentences in sof_text1: \", len(sof_text1))\n",
    "print(\"No of sentences in sof_text2: \", len(sof_text2))\n",
    "print(\"No of sentences in hwz_text1: \", len(hwz_text1))\n",
    "print(\"No of sentences in hwz_text2: \", len(hwz_text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90754d4",
   "metadata": {},
   "source": [
    "##### Proper nouns capitalised?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5c0f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = []\n",
    "uppercount = 0\n",
    "count = 0\n",
    "for sentence in sof_text1:\n",
    "    tagged.append(nlp(sentence))\n",
    "for tag in tagged:\n",
    "    for token in tag:\n",
    "        if token.pos_ == 'PROPN':\n",
    "            if token.text[0].isupper():\n",
    "                uppercount += 1\n",
    "            count += 1\n",
    "print('Fraction of proper nouns capitalised in sof_text1: ', uppercount/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0d3f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = []\n",
    "uppercount = 0\n",
    "count = 0\n",
    "for sentence in sof_text2:\n",
    "    tagged.append(nlp(sentence))\n",
    "for tag in tagged:\n",
    "    for token in tag:\n",
    "        if token.pos_ == 'PROPN':\n",
    "            if token.text[0].isupper():\n",
    "                uppercount += 1\n",
    "            count += 1\n",
    "print('Fraction of proper nouns capitalised in sof_text2: ', uppercount/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a68814",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = []\n",
    "uppercount = 0\n",
    "count = 0\n",
    "for sentence in hwz_text1:\n",
    "    tagged.append(nlp(sentence))\n",
    "for tag in tagged:\n",
    "    for token in tag:\n",
    "        if token.pos_ == 'PROPN':\n",
    "            if token.text[0].isupper():\n",
    "                uppercount += 1\n",
    "            count += 1\n",
    "print('Fraction of proper nouns capitalised in hwz_text1: ', uppercount/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adda956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = []\n",
    "uppercount = 0\n",
    "count = 0\n",
    "for sentence in hwz_text2:\n",
    "    tagged.append(nlp(sentence))\n",
    "for tag in tagged:\n",
    "    for token in tag:\n",
    "        if token.pos_ == 'PROPN':\n",
    "            if token.text[0].isupper():\n",
    "                uppercount += 1\n",
    "            count += 1\n",
    "print('Fraction of proper nouns capitalised in hwz_text2: ', uppercount/count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac262786",
   "metadata": {},
   "source": [
    "##### Good grammar?\n",
    "1. Tense matching\n",
    "2. Subject-verb agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3b53a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
