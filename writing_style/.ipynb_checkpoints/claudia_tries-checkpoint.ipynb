{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "97e6fb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries needed\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from collections import Counter\n",
    "# import httplib2\n",
    "import itertools\n",
    "import matplotlib as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd \n",
    "import random\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.lang.en import English\n",
    "import urllib.request\n",
    "from urllib.request import urlopen, Request\n",
    "import random\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "bc45d509-90f8-4db6-a063-13e17fad1c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e70f63a",
   "metadata": {},
   "source": [
    "## Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "c2790af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_json('../data/reviewSelected100.json', encoding='ISO-8859-1', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1e12df",
   "metadata": {},
   "source": [
    "## 3.2 Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14711fd",
   "metadata": {},
   "source": [
    "### Tokenisation and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "78f7f863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>GqwphH1Qi-8mJMEYAW_5vQ</td>\n",
       "      <td>X_526DZfpSriocKu9IJfWQ</td>\n",
       "      <td>AEx2SYEUJmTxVVB18LlCwA</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Small bologna and salami sandwich, toasted wit...</td>\n",
       "      <td>2013-12-28 20:36:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>xd5cNOzx4jbWSgeIzJ_tVQ</td>\n",
       "      <td>vGohRKrqPgCJak3Jp6nGMA</td>\n",
       "      <td>AEx2SYEUJmTxVVB18LlCwA</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>After a late breakfast at Faberge , decided to...</td>\n",
       "      <td>2014-07-28 02:10:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>j7UP4zWrucADImEPVh4Brw</td>\n",
       "      <td>TYxVMGgyQR8SpXzdMZ_usQ</td>\n",
       "      <td>AEx2SYEUJmTxVVB18LlCwA</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Classic place. Been around for 60+ years. Best...</td>\n",
       "      <td>2016-05-31 04:35:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>XgC63yPcorK-M2KvxoytTw</td>\n",
       "      <td>0C_kTzETOV_1m-fSeYGuJQ</td>\n",
       "      <td>AEx2SYEUJmTxVVB18LlCwA</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>As the simple sandwich and egg creme soda goes...</td>\n",
       "      <td>2018-06-26 18:56:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>MuYQSNxUFqlaLeR5w2TAUA</td>\n",
       "      <td>fpfidtaJqKlSeBASjJUsyQ</td>\n",
       "      <td>AEx2SYEUJmTxVVB18LlCwA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Damn this place is so great. The decor is very...</td>\n",
       "      <td>2017-06-17 19:08:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   review_id                 user_id             business_id  \\\n",
       "1805  GqwphH1Qi-8mJMEYAW_5vQ  X_526DZfpSriocKu9IJfWQ  AEx2SYEUJmTxVVB18LlCwA   \n",
       "1806  xd5cNOzx4jbWSgeIzJ_tVQ  vGohRKrqPgCJak3Jp6nGMA  AEx2SYEUJmTxVVB18LlCwA   \n",
       "1815  j7UP4zWrucADImEPVh4Brw  TYxVMGgyQR8SpXzdMZ_usQ  AEx2SYEUJmTxVVB18LlCwA   \n",
       "1818  XgC63yPcorK-M2KvxoytTw  0C_kTzETOV_1m-fSeYGuJQ  AEx2SYEUJmTxVVB18LlCwA   \n",
       "1820  MuYQSNxUFqlaLeR5w2TAUA  fpfidtaJqKlSeBASjJUsyQ  AEx2SYEUJmTxVVB18LlCwA   \n",
       "\n",
       "      stars  useful  funny  cool  \\\n",
       "1805      4       0      0     0   \n",
       "1806      4       2      0     2   \n",
       "1815      5       0      0     0   \n",
       "1818      5       0      0     1   \n",
       "1820      5       1      0     1   \n",
       "\n",
       "                                                   text                date  \n",
       "1805  Small bologna and salami sandwich, toasted wit... 2013-12-28 20:36:26  \n",
       "1806  After a late breakfast at Faberge , decided to... 2014-07-28 02:10:34  \n",
       "1815  Classic place. Been around for 60+ years. Best... 2016-05-31 04:35:46  \n",
       "1818  As the simple sandwich and egg creme soda goes... 2018-06-26 18:56:05  \n",
       "1820  Damn this place is so great. The decor is very... 2017-06-17 19:08:10  "
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get reviews for a random business \n",
    "random_business = reviews.sample()\n",
    "random_business_id = random_business.iloc[0]['business_id']\n",
    "small_business_dataset = reviews.loc[reviews['business_id'] == random_business_id]\n",
    "small_business_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "c91d93e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_business_dataset_reviews = list(small_business_dataset['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "0669b8f6-714b-4708-840b-2c65c03f97eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the reviews into a concatenated string \n",
    "b1_review = ''.join(small_business_dataset_reviews)\n",
    "clean_review = re.sub(r\"[^A-Za-z0-9\\s]+\", \"\", b1_review)\n",
    "b1_review = nlp(clean_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "deaa0847-5dec-4317-b9f5-ece17562bfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 394), ('and', 315), ('a', 281), ('is', 180), ('to', 175), ('I', 175), ('of', 154), ('in', 124), ('you', 122), ('it', 120)]\n"
     ]
    }
   ],
   "source": [
    "# removed punctuation and get the top 10 most common words (including stopwords)\n",
    "b1_review_words = [token.text for token in b1_review if token.is_alpha == True] \n",
    "b1_word_freq = Counter(b1_review_words)\n",
    "common_words = b1_word_freq.most_common(10)\n",
    "print(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "ede74a1b-4e6c-4436-8c3b-df2f479aad26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sandwich', 90), ('place', 84), ('nt', 77), ('mustard', 50), ('special', 41), ('like', 40), ('soda', 36), ('bologna', 35), ('cheese', 35), ('Montreal', 35)]\n"
     ]
    }
   ],
   "source": [
    "# removed punctuation and get the top 10 most common words (excluding stopwords)\n",
    "b1_review_words = [token.text for token in b1_review if token.is_stop != True and token.is_alpha == True] \n",
    "b1_word_freq = Counter(b1_review_words)\n",
    "common_words = b1_word_freq.most_common(10)\n",
    "print(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "82e4306f-2536-450b-ba7d-cc0f073dfef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: plot log graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "eeb35a0e-7b64-4e9a-9d53-e89a299e51ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we do some stemming after removing the stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "porter_st = PorterStemmer()\n",
    "lancaster_st = LancasterStemmer()\n",
    "snow_st = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "bfe90886-30ac-4282-978f-f66739952d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sandwich', 108), ('place', 89), ('nt', 77), ('special', 76), ('wilenski', 64), ('mustard', 51), ('soda', 48), ('order', 45), ('de', 42), ('like', 41)]\n"
     ]
    }
   ],
   "source": [
    "# Using Porter Stemmer\n",
    "porter_stemmed_words = [porter_st.stem(word) for word in b1_review_words]\n",
    "porter_freq = Counter(porter_stemmed_words)\n",
    "porter_common = porter_freq.most_common(10)\n",
    "print(porter_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "993edaec-02a4-4bef-9a21-c61302974a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sandwich', 108), ('plac', 89), ('nt', 77), ('spec', 76), ('wilensky', 63), ('mustard', 51), ('ord', 45), ('mont', 43), ('bologn', 41), ('lik', 41)]\n"
     ]
    }
   ],
   "source": [
    "# Using Lancaster Stemmer\n",
    "lancaster_stemmed_words = [lancaster_st.stem(word) for word in b1_review_words]\n",
    "lancaster_freq = Counter(lancaster_stemmed_words)\n",
    "lancaster_common = lancaster_freq.most_common(10)\n",
    "print(lancaster_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "32ce69f4-074a-4ab0-ae2d-d6e466205781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sandwich', 108), ('place', 89), ('nt', 77), ('special', 76), ('wilenski', 64), ('mustard', 51), ('soda', 48), ('order', 45), ('like', 41), ('bologna', 38)]\n"
     ]
    }
   ],
   "source": [
    "# Using Snowball Stemmer\n",
    "snow_stemmed_words = [snow_st.stem(word) for word in b1_review_words]\n",
    "snow_freq = Counter(snow_stemmed_words)\n",
    "snow_common = snow_freq.most_common(10)\n",
    "print(snow_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603d6c54",
   "metadata": {},
   "source": [
    "### POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "d4c24448",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sentences = reviews.sample(5, random_state=42)\n",
    "random_sentences = list(random_sentences['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "c81cc594-a486-47fa-91bf-0f4043a6cd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Que ce soit pour leurs délicieux bubbles tea/smooties, leurs ''Bánh mì'' , leurs petits snacks (viennoiseries, tapioca, ...), on adore Vua et aussi leurs prix très abordables. On y retourne lorsqu'on est dans le Quartier Latin !\""
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "c8155e95-94cb-490a-bbff-2db99e5b7cf0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Que', 'NNP'),\n",
       "  ('ce', 'NN'),\n",
       "  ('soit', 'VBD'),\n",
       "  ('pour', 'JJ'),\n",
       "  ('leurs', 'NNS'),\n",
       "  ('délicieux', 'VBP'),\n",
       "  ('bubbles', 'NNS'),\n",
       "  ('tea/smooties', 'NNS'),\n",
       "  (',', ','),\n",
       "  ('leurs', 'VBZ'),\n",
       "  ('``', '``'),\n",
       "  ('Bánh', 'NNP'),\n",
       "  ('mì', 'NN'),\n",
       "  (\"''\", \"''\"),\n",
       "  (',', ','),\n",
       "  ('leurs', 'VBZ'),\n",
       "  ('petits', 'NNS'),\n",
       "  ('snacks', 'NNS'),\n",
       "  ('(', '('),\n",
       "  ('viennoiseries', 'NNS'),\n",
       "  (',', ','),\n",
       "  ('tapioca', 'NN'),\n",
       "  (',', ','),\n",
       "  ('...', ':'),\n",
       "  (')', ')'),\n",
       "  (',', ','),\n",
       "  ('on', 'IN'),\n",
       "  ('adore', 'IN'),\n",
       "  ('Vua', 'NNP'),\n",
       "  ('et', 'CC'),\n",
       "  ('aussi', 'JJ'),\n",
       "  ('leurs', 'NNS'),\n",
       "  ('prix', 'VBP'),\n",
       "  ('très', 'JJ'),\n",
       "  ('abordables', 'NNS'),\n",
       "  ('.', '.'),\n",
       "  ('On', 'IN'),\n",
       "  ('y', 'JJ'),\n",
       "  ('retourne', 'JJ'),\n",
       "  (\"lorsqu'on\", 'NN'),\n",
       "  ('est', 'JJS'),\n",
       "  ('dans', 'NNS'),\n",
       "  ('le', 'VBP'),\n",
       "  ('Quartier', 'NNP'),\n",
       "  ('Latin', 'NNP'),\n",
       "  ('!', '.')],\n",
       " [('As', 'IN'),\n",
       "  ('I', 'PRP'),\n",
       "  (\"'ve\", 'VBP'),\n",
       "  ('said', 'VBD'),\n",
       "  ('previously', 'RB'),\n",
       "  ('...', ':'),\n",
       "  ('we', 'PRP'),\n",
       "  (\"'ve\", 'VBP'),\n",
       "  ('been', 'VBN'),\n",
       "  ('coming', 'VBG'),\n",
       "  ('to', 'TO'),\n",
       "  ('LMAH', 'NNP'),\n",
       "  ('for', 'IN'),\n",
       "  ('over', 'IN'),\n",
       "  ('10', 'CD'),\n",
       "  ('years', 'NNS'),\n",
       "  ('.', '.'),\n",
       "  ('At', 'IN'),\n",
       "  ('least', 'JJS'),\n",
       "  ('15', 'CD'),\n",
       "  ('.', '.'),\n",
       "  ('And', 'CC'),\n",
       "  ('we', 'PRP'),\n",
       "  (\"'ve\", 'VBP'),\n",
       "  ('ALWAYS', 'NNP'),\n",
       "  ('seen', 'VBN'),\n",
       "  ('Dr.', 'NNP'),\n",
       "  ('White', 'NNP'),\n",
       "  ('.', '.'),\n",
       "  ('I', 'PRP'),\n",
       "  ('had', 'VBD'),\n",
       "  ('to', 'TO'),\n",
       "  ('bring', 'VB'),\n",
       "  ('my', 'PRP$'),\n",
       "  ('cat', 'NN'),\n",
       "  ('in', 'IN'),\n",
       "  ('to', 'TO'),\n",
       "  ('have', 'VB'),\n",
       "  ('a', 'DT'),\n",
       "  ('urine', 'JJ'),\n",
       "  ('sample', 'NN'),\n",
       "  ('done', 'VBN'),\n",
       "  ('.', '.'),\n",
       "  ('While', 'IN'),\n",
       "  ('being', 'VBG'),\n",
       "  ('done', 'VBN'),\n",
       "  (',', ','),\n",
       "  ('my', 'PRP$'),\n",
       "  ('cat', 'NN'),\n",
       "  ('pee', 'NN'),\n",
       "  (\"'d\", 'MD'),\n",
       "  ('on', 'IN'),\n",
       "  ('himself', 'PRP'),\n",
       "  ('.', '.'),\n",
       "  ('The', 'DT'),\n",
       "  ('vet', 'NN'),\n",
       "  ('or', 'CC'),\n",
       "  ('staff', 'NN'),\n",
       "  ('only', 'RB'),\n",
       "  ('tried', 'VBD'),\n",
       "  ('to', 'TO'),\n",
       "  ('clean', 'VB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('off', 'IN'),\n",
       "  ('of', 'IN'),\n",
       "  ('him', 'PRP'),\n",
       "  ('with', 'IN'),\n",
       "  ('alcohol', 'NN'),\n",
       "  ('.', '.'),\n",
       "  ('They', 'PRP'),\n",
       "  ('did', 'VBD'),\n",
       "  (\"n't\", 'RB'),\n",
       "  ('try', 'VB'),\n",
       "  ('to', 'TO'),\n",
       "  ('actually', 'RB'),\n",
       "  ('get', 'VB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('off', 'IN'),\n",
       "  ('of', 'IN'),\n",
       "  ('him', 'PRP'),\n",
       "  ('.', '.'),\n",
       "  ('They', 'PRP'),\n",
       "  ('did', 'VBD'),\n",
       "  (\"n't\", 'RB'),\n",
       "  ('even', 'RB'),\n",
       "  ('TELL', 'VB'),\n",
       "  ('ME', 'NNP'),\n",
       "  ('that', 'IN'),\n",
       "  ('he', 'PRP'),\n",
       "  ('pee', 'VBZ'),\n",
       "  (\"'d\", 'MD'),\n",
       "  ('all', 'DT'),\n",
       "  ('over', 'IN'),\n",
       "  ('his', 'PRP$'),\n",
       "  ('stomach', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('legs', 'NN'),\n",
       "  ('.', '.'),\n",
       "  ('So', 'RB'),\n",
       "  ('now', 'RB'),\n",
       "  ('I', 'PRP'),\n",
       "  ('e', 'VBP'),\n",
       "  ('had', 'VBD'),\n",
       "  ('to', 'TO'),\n",
       "  ('give', 'VB'),\n",
       "  ('my', 'PRP$'),\n",
       "  ('cat', 'NN'),\n",
       "  ('a', 'DT'),\n",
       "  ('bath', 'NN'),\n",
       "  ('because', 'IN'),\n",
       "  ('they', 'PRP'),\n",
       "  ('ca', 'MD'),\n",
       "  (\"n't\", 'RB'),\n",
       "  ('take', 'VB'),\n",
       "  ('a', 'DT'),\n",
       "  ('urine', 'JJ'),\n",
       "  ('sample', 'NN'),\n",
       "  ('properly', 'RB'),\n",
       "  ('.', '.'),\n",
       "  ('I', 'PRP'),\n",
       "  ('am', 'VBP'),\n",
       "  ('LIVID', 'NNP'),\n",
       "  ('.', '.')],\n",
       " [('Pretty', 'NNP'),\n",
       "  ('decent', 'NN'),\n",
       "  ('but', 'CC'),\n",
       "  ('so', 'RB'),\n",
       "  ('spacious', 'JJ'),\n",
       "  ('!', '.'),\n",
       "  ('Very', 'RB'),\n",
       "  ('good', 'JJ'),\n",
       "  ('for', 'IN'),\n",
       "  ('kids', 'NNS'),\n",
       "  ('and', 'CC'),\n",
       "  ('you', 'PRP'),\n",
       "  ('can', 'MD'),\n",
       "  ('order', 'NN'),\n",
       "  ('dim', 'VB'),\n",
       "  ('sum', 'NN'),\n",
       "  ('!', '.'),\n",
       "  ('They', 'PRP'),\n",
       "  (\"'re\", 'VBP'),\n",
       "  ('open', 'JJ'),\n",
       "  ('!', '.'),\n",
       "  ('!', '.'),\n",
       "  ('Free', 'JJ'),\n",
       "  ('wifi', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('awesome', 'JJ'),\n",
       "  (':', ':'),\n",
       "  (')', ')')],\n",
       " [('Dumpling', 'VBG'),\n",
       "  ('Village', 'NNP'),\n",
       "  ('really', 'RB'),\n",
       "  ('suffering', 'VBG'),\n",
       "  ('from', 'IN'),\n",
       "  ('identity', 'NN'),\n",
       "  ('crisis', 'NN'),\n",
       "  ('!', '.'),\n",
       "  ('!', '.'),\n",
       "  ('Is', 'VBZ'),\n",
       "  ('it', 'PRP'),\n",
       "  ('a', 'DT'),\n",
       "  ('Korean', 'JJ'),\n",
       "  ('Restaurant', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('not', 'RB'),\n",
       "  ('really', 'RB'),\n",
       "  ('.', '.'),\n",
       "  ('There', 'EX'),\n",
       "  ('are', 'VBP'),\n",
       "  ('mostly', 'RB'),\n",
       "  ('Northern', 'NNP'),\n",
       "  ('Chinese', 'NNP'),\n",
       "  ('items', 'NNS'),\n",
       "  ('on', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('menu', 'NN'),\n",
       "  ('like', 'IN'),\n",
       "  ('dumplings', 'NNS'),\n",
       "  ('.', '.'),\n",
       "  ('Is', 'VBZ'),\n",
       "  ('it', 'PRP'),\n",
       "  ('a', 'DT'),\n",
       "  ('Northern', 'NNP'),\n",
       "  ('Chinese', 'NNP'),\n",
       "  ('restaurant', 'NN'),\n",
       "  (',', ','),\n",
       "  ('not', 'RB'),\n",
       "  ('really', 'RB'),\n",
       "  ('There', 'EX'),\n",
       "  ('are', 'VBP'),\n",
       "  ('a', 'DT'),\n",
       "  ('lot', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('Korean', 'JJ'),\n",
       "  ('dishes', 'NNS'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('menu', 'NN'),\n",
       "  ('like', 'IN'),\n",
       "  ('pork', 'NN'),\n",
       "  ('bone', 'NN'),\n",
       "  ('soup', 'NN'),\n",
       "  (',', ','),\n",
       "  ('cold', 'JJ'),\n",
       "  ('wheat', 'NN'),\n",
       "  ('bucknoodle', 'NN'),\n",
       "  ('soup', 'NN'),\n",
       "  (',', ','),\n",
       "  ('kimchi', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('bean', 'NN'),\n",
       "  ('sprout', 'NN'),\n",
       "  ('as', 'IN'),\n",
       "  ('appetitizers', 'NNS'),\n",
       "  ('.', '.'),\n",
       "  ('The', 'DT'),\n",
       "  ('only', 'JJ'),\n",
       "  ('Korean', 'JJ'),\n",
       "  ('characters', 'NNS'),\n",
       "  ('are', 'VBP'),\n",
       "  ('the', 'DT'),\n",
       "  ('3', 'CD'),\n",
       "  ('on', 'IN'),\n",
       "  ('their', 'PRP$'),\n",
       "  ('business', 'NN'),\n",
       "  ('sign', 'NN'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('front', 'NN'),\n",
       "  ('..', 'NNP'),\n",
       "  ('and', 'CC'),\n",
       "  ('all', 'PDT'),\n",
       "  ('the', 'DT'),\n",
       "  ('rest', 'NN'),\n",
       "  ('are', 'VBP'),\n",
       "  ('in', 'IN'),\n",
       "  ('Chinese', 'NNP'),\n",
       "  ('and', 'CC'),\n",
       "  ('English', 'NNP'),\n",
       "  ('.', '.'),\n",
       "  ('All', 'PDT'),\n",
       "  ('the', 'DT'),\n",
       "  ('wait', 'NN'),\n",
       "  ('staffs', 'NNS'),\n",
       "  ('here', 'RB'),\n",
       "  ('speak', 'VBP'),\n",
       "  ('Mandarian', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('even', 'RB'),\n",
       "  ('most', 'JJS'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('patrons', 'NNS'),\n",
       "  ('are', 'VBP'),\n",
       "  ('Chinese', 'JJ'),\n",
       "  ('.', '.'),\n",
       "  ('It', 'PRP'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('located', 'VBN'),\n",
       "  ('in', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('really', 'RB'),\n",
       "  ('tiny', 'JJ'),\n",
       "  ('strip', 'NN'),\n",
       "  ('mall', 'NN'),\n",
       "  ('..', 'NN'),\n",
       "  ('with', 'IN'),\n",
       "  ('limited', 'JJ'),\n",
       "  ('parkings', 'NNS'),\n",
       "  ('!', '.'),\n",
       "  ('To', 'TO'),\n",
       "  ('tell', 'VB'),\n",
       "  ('you', 'PRP'),\n",
       "  ('the', 'DT'),\n",
       "  ('truth', 'NN'),\n",
       "  ('I', 'PRP'),\n",
       "  ('am', 'VBP'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('area', 'NN'),\n",
       "  ('for', 'IN'),\n",
       "  ('over', 'IN'),\n",
       "  ('10', 'CD'),\n",
       "  ('years', 'NNS'),\n",
       "  ('I', 'PRP'),\n",
       "  ('never', 'RB'),\n",
       "  ('notice', 'VBP'),\n",
       "  ('it', 'PRP'),\n",
       "  ('until', 'IN'),\n",
       "  ('I', 'PRP'),\n",
       "  ('read', 'VBP'),\n",
       "  ('the', 'DT'),\n",
       "  ('reviews', 'NNS'),\n",
       "  ('on', 'IN'),\n",
       "  ('yelp', 'NN'),\n",
       "  ('!', '.'),\n",
       "  ('We', 'PRP'),\n",
       "  ('arrived', 'VBD'),\n",
       "  ('around', 'RB'),\n",
       "  ('6', 'CD'),\n",
       "  ('pm', 'NN'),\n",
       "  ('on', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('Saturday', 'NNP'),\n",
       "  ('.', '.'),\n",
       "  ('The', 'DT'),\n",
       "  ('restaurant', 'NN'),\n",
       "  ('was', 'VBD'),\n",
       "  ('almost', 'RB'),\n",
       "  ('full', 'JJ'),\n",
       "  ('.', '.'),\n",
       "  ('The', 'DT'),\n",
       "  ('tables', 'NNS'),\n",
       "  ('are', 'VBP'),\n",
       "  ('not', 'RB'),\n",
       "  ('really', 'RB'),\n",
       "  ('packed', 'VBN'),\n",
       "  ('together', 'RB'),\n",
       "  (',', ','),\n",
       "  ('so', 'IN'),\n",
       "  ('you', 'PRP'),\n",
       "  ('still', 'RB'),\n",
       "  ('have', 'VBP'),\n",
       "  ('a', 'DT'),\n",
       "  ('certain', 'JJ'),\n",
       "  ('degree', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('privacy', 'NN'),\n",
       "  ('at', 'IN'),\n",
       "  ('least', 'JJS'),\n",
       "  ('I', 'PRP'),\n",
       "  ('can', 'MD'),\n",
       "  ('not', 'RB'),\n",
       "  ('tell', 'VB'),\n",
       "  ('what', 'WP'),\n",
       "  ('the', 'DT'),\n",
       "  ('table', 'NN'),\n",
       "  ('next', 'JJ'),\n",
       "  ('to', 'TO'),\n",
       "  ('me', 'PRP'),\n",
       "  ('were', 'VBD'),\n",
       "  ('eating', 'VBG'),\n",
       "  ('.', '.'),\n",
       "  ('We', 'PRP'),\n",
       "  ('decided', 'VBD'),\n",
       "  ('on', 'IN'),\n",
       "  ('my', 'PRP$'),\n",
       "  ('favourite', 'JJ'),\n",
       "  ('chives', 'NNS'),\n",
       "  ('and', 'CC'),\n",
       "  ('pork', 'NN'),\n",
       "  ('dumplings', 'NNS'),\n",
       "  (',', ','),\n",
       "  ('kimchi', 'NNS'),\n",
       "  ('fried', 'VBD'),\n",
       "  ('rice', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('Korean', 'NNP'),\n",
       "  ('cold', 'VBD'),\n",
       "  ('bucknoodle', 'JJ'),\n",
       "  ('soup', 'NN'),\n",
       "  ('.', '.'),\n",
       "  ('They', 'PRP'),\n",
       "  ('are', 'VBP'),\n",
       "  ('all', 'DT'),\n",
       "  ('$', '$'),\n",
       "  ('4.99', 'CD'),\n",
       "  ('.', '.'),\n",
       "  ('The', 'DT'),\n",
       "  ('cold', 'JJ'),\n",
       "  ('noodle', 'JJ'),\n",
       "  ('soup', 'NN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('so', 'RB'),\n",
       "  ('so', 'RB'),\n",
       "  ('good', 'JJ'),\n",
       "  ('!', '.'),\n",
       "  ('Nice', 'NNP'),\n",
       "  ('and', 'CC'),\n",
       "  ('refreshing', 'VBG'),\n",
       "  ('!', '.'),\n",
       "  ('and', 'CC'),\n",
       "  ('the', 'DT'),\n",
       "  ('soup', 'NN'),\n",
       "  ('based', 'VBN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('a', 'DT'),\n",
       "  ('little', 'JJ'),\n",
       "  ('sour', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('it', 'PRP'),\n",
       "  ('really', 'RB'),\n",
       "  ('stimulate', 'VB'),\n",
       "  ('your', 'PRP$'),\n",
       "  ('tastebuds', 'NNS'),\n",
       "  ('and', 'CC'),\n",
       "  ('just', 'RB'),\n",
       "  ('make', 'VB'),\n",
       "  ('you', 'PRP'),\n",
       "  ('want', 'VB'),\n",
       "  ('to', 'TO'),\n",
       "  ('eat', 'VB'),\n",
       "  ('more', 'JJR'),\n",
       "  ('!', '.'),\n",
       "  ('(', '('),\n",
       "  ('I', 'PRP'),\n",
       "  ('can', 'MD'),\n",
       "  ('finish', 'VB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('all', 'DT'),\n",
       "  ('myself', 'PRP'),\n",
       "  ('!', '.'),\n",
       "  ('I', 'PRP'),\n",
       "  ('do', 'VBP'),\n",
       "  (\"n't\", 'RB'),\n",
       "  ('want', 'VB'),\n",
       "  ('to', 'TO'),\n",
       "  ('share', 'NN'),\n",
       "  ('!', '.'),\n",
       "  ('I', 'PRP'),\n",
       "  ('want', 'VBP'),\n",
       "  ('one', 'CD'),\n",
       "  ('all', 'DT'),\n",
       "  ('for', 'IN'),\n",
       "  ('myself', 'PRP'),\n",
       "  ('next', 'JJ'),\n",
       "  ('time', 'NN'),\n",
       "  ('!', '.'),\n",
       "  (')', ')'),\n",
       "  ('The', 'DT'),\n",
       "  ('kimchi', 'NN'),\n",
       "  ('fried', 'VBD'),\n",
       "  ('rice', 'NN'),\n",
       "  ('..', 'NNP'),\n",
       "  ('hmmmmm', 'NN'),\n",
       "  ('not', 'RB'),\n",
       "  ('good', 'JJ'),\n",
       "  ('!', '.'),\n",
       "  ('A', 'DT'),\n",
       "  ('little', 'JJ'),\n",
       "  ('on', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('oily', 'JJ'),\n",
       "  ('side', 'NN'),\n",
       "  ('.', '.'),\n",
       "  ('There', 'EX'),\n",
       "  ('are', 'VBP'),\n",
       "  ('not', 'RB'),\n",
       "  ('much', 'JJ'),\n",
       "  ('taste', 'NN'),\n",
       "  (',', ','),\n",
       "  ('not', 'RB'),\n",
       "  ('spicy', 'VB'),\n",
       "  ('enough', 'RB'),\n",
       "  ('?', '.'),\n",
       "  ('We', 'PRP'),\n",
       "  ('could', 'MD'),\n",
       "  ('not', 'RB'),\n",
       "  ('finish', 'VB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('and', 'CC'),\n",
       "  ('end', 'VB'),\n",
       "  ('up', 'RB'),\n",
       "  ('have', 'VBP'),\n",
       "  ('to', 'TO'),\n",
       "  ('pack', 'VB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('all', 'DT'),\n",
       "  ('to', 'TO'),\n",
       "  ('go', 'VB'),\n",
       "  ('...', ':'),\n",
       "  ('(', '('),\n",
       "  ('not', 'RB'),\n",
       "  ('even', 'RB'),\n",
       "  ('sure', 'JJ'),\n",
       "  ('I', 'PRP'),\n",
       "  ('will', 'MD'),\n",
       "  ('eat', 'VB'),\n",
       "  ('it', 'PRP'),\n",
       "  (',', ','),\n",
       "  ('but', 'CC'),\n",
       "  ('can', 'MD'),\n",
       "  ('not', 'RB'),\n",
       "  ('just', 'RB'),\n",
       "  ('let', 'VB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('all', 'DT'),\n",
       "  ('go', 'VBP'),\n",
       "  ('to', 'TO'),\n",
       "  ('waste', 'NN'),\n",
       "  (')', ')'),\n",
       "  ('The', 'DT'),\n",
       "  ('dumplings', 'NNS'),\n",
       "  ('arrived', 'VBD'),\n",
       "  ('last', 'JJ'),\n",
       "  ('!', '.'),\n",
       "  ('But', 'CC'),\n",
       "  ('it', 'PRP'),\n",
       "  ('really', 'RB'),\n",
       "  ('worth', 'VBZ'),\n",
       "  ('the', 'DT'),\n",
       "  ('wait', 'NN'),\n",
       "  ('!', '.'),\n",
       "  ('14', 'CD'),\n",
       "  ('big', 'JJ'),\n",
       "  ('fat', 'NN'),\n",
       "  ('hot', 'JJ'),\n",
       "  ('dumplings', 'NNS'),\n",
       "  ('filled', 'VBN'),\n",
       "  ('up', 'RP'),\n",
       "  ('the', 'DT'),\n",
       "  ('whole', 'JJ'),\n",
       "  ('steamer', 'NN'),\n",
       "  ('!', '.'),\n",
       "  ('Yes', 'UH'),\n",
       "  ('I', 'PRP'),\n",
       "  ('counted', 'VBD'),\n",
       "  ('them', 'PRP'),\n",
       "  ('14', 'CD'),\n",
       "  ('of', 'IN'),\n",
       "  ('them', 'PRP'),\n",
       "  ('for', 'IN'),\n",
       "  ('$', '$'),\n",
       "  ('4.99', 'CD'),\n",
       "  ('.', '.'),\n",
       "  ('They', 'PRP'),\n",
       "  ('are', 'VBP'),\n",
       "  ('all', 'DT'),\n",
       "  ('freshly', 'RB'),\n",
       "  ('made', 'VBN'),\n",
       "  (',', ','),\n",
       "  ('freshly', 'RB'),\n",
       "  ('steamed', 'VBN'),\n",
       "  ('!', '.'),\n",
       "  ('The', 'DT'),\n",
       "  ('skin', 'NN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('nice', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('thin', 'JJ'),\n",
       "  (',', ','),\n",
       "  ('not', 'RB'),\n",
       "  ('chewy', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('thick', 'JJ'),\n",
       "  ('!', '.'),\n",
       "  ('Oh', 'NNP'),\n",
       "  ('so', 'RB'),\n",
       "  ('delicious', 'JJ'),\n",
       "  ('!', '.'),\n",
       "  ('One', 'CD'),\n",
       "  ('bite', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('all', 'PDT'),\n",
       "  ('the', 'DT'),\n",
       "  ('soup', 'NN'),\n",
       "  ('are', 'VBP'),\n",
       "  ('ozzing', 'VBG'),\n",
       "  ('out', 'RP'),\n",
       "  ('!', '.'),\n",
       "  ('But', 'CC'),\n",
       "  ('if', 'IN'),\n",
       "  ('they', 'PRP'),\n",
       "  ('are', 'VBP'),\n",
       "  ('not', 'RB'),\n",
       "  ('burning', 'VBG'),\n",
       "  ('hot', 'JJ'),\n",
       "  (',', ','),\n",
       "  ('you', 'PRP'),\n",
       "  ('can', 'MD'),\n",
       "  ('just', 'RB'),\n",
       "  ('stuff', 'VB'),\n",
       "  ('the', 'DT'),\n",
       "  ('whole', 'JJ'),\n",
       "  ('thing', 'NN'),\n",
       "  ('into', 'IN'),\n",
       "  ('your', 'PRP$'),\n",
       "  ('mouth', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('let', 'VB'),\n",
       "  ('the', 'DT'),\n",
       "  ('soup', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('favour', 'NN'),\n",
       "  ('just', 'RB'),\n",
       "  ('explosed', 'VBN'),\n",
       "  ('in', 'IN'),\n",
       "  ('your', 'PRP$'),\n",
       "  ('mouth', 'NN'),\n",
       "  ('.', '.'),\n",
       "  ('Just', 'VB'),\n",
       "  ('a', 'DT'),\n",
       "  ('warning', 'NN'),\n",
       "  ('.', '.'),\n",
       "  ('If', 'IN'),\n",
       "  ('you', 'PRP'),\n",
       "  ('going', 'VBG'),\n",
       "  ('out', 'RP'),\n",
       "  ('on', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('date', 'NN'),\n",
       "  (',', ','),\n",
       "  ('please', 'VB'),\n",
       "  ('do', 'VBP'),\n",
       "  (\"n't\", 'RB'),\n",
       "  ('come', 'VB'),\n",
       "  ('here', 'RB'),\n",
       "  ('.', '.'),\n",
       "  ('Even', 'RB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('a', 'DT'),\n",
       "  ('good', 'JJ'),\n",
       "  ('place', 'NN'),\n",
       "  ('for', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('cheap', 'JJ'),\n",
       "  ('date', 'NN'),\n",
       "  (',', ','),\n",
       "  ('our', 'PRP$'),\n",
       "  ('bill', 'NN'),\n",
       "  ('was', 'VBD'),\n",
       "  ('$', '$'),\n",
       "  ('18', 'CD'),\n",
       "  ('for', 'IN'),\n",
       "  ('2', 'CD'),\n",
       "  ('and', 'CC'),\n",
       "  ('we', 'PRP'),\n",
       "  ('were', 'VBD'),\n",
       "  ('full', 'JJ'),\n",
       "  ('!', '.'),\n",
       "  ('But', 'CC'),\n",
       "  ('the', 'DT'),\n",
       "  ('place', 'NN'),\n",
       "  ('can', 'MD'),\n",
       "  ('be', 'VB'),\n",
       "  ('noisy', 'RB'),\n",
       "  (',', ','),\n",
       "  ('the', 'DT'),\n",
       "  ('food', 'NN'),\n",
       "  ('too', 'RB'),\n",
       "  ('good', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('your', 'PRP$'),\n",
       "  ('date', 'NN'),\n",
       "  ('will', 'MD'),\n",
       "  ('be', 'VB'),\n",
       "  ('too', 'RB'),\n",
       "  ('busy', 'JJ'),\n",
       "  ('eating', 'VBG'),\n",
       "  ('and', 'CC'),\n",
       "  ('just', 'RB'),\n",
       "  ('ignore', 'VB'),\n",
       "  ('you', 'PRP'),\n",
       "  ('!', '.'),\n",
       "  ('Or', 'CC'),\n",
       "  ('you', 'PRP'),\n",
       "  ('will', 'MD'),\n",
       "  ('keep', 'VB'),\n",
       "  ('eating', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('eating', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('you', 'PRP'),\n",
       "  ('freak', 'VBP'),\n",
       "  ('all', 'DT'),\n",
       "  ('your', 'PRP$'),\n",
       "  ('friends', 'NNS'),\n",
       "  ('out', 'RP'),\n",
       "  ('!', '.'),\n",
       "  ('The', 'DT'),\n",
       "  ('services', 'NNS'),\n",
       "  ('here', 'RB'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('cold', 'JJ'),\n",
       "  ('but', 'CC'),\n",
       "  ('efficient', 'JJ'),\n",
       "  ('.', '.'),\n",
       "  ('We', 'PRP'),\n",
       "  ('were', 'VBD'),\n",
       "  ('given', 'VBN'),\n",
       "  ('extra', 'JJ'),\n",
       "  ('napkins', 'NNS'),\n",
       "  ('without', 'IN'),\n",
       "  ('requesting', 'VBG'),\n",
       "  ('...', ':'),\n",
       "  ('Maybe', 'RB'),\n",
       "  ('we', 'PRP'),\n",
       "  ('looked', 'VBD'),\n",
       "  ('really', 'RB'),\n",
       "  ('messy', 'VBN'),\n",
       "  ('?', '.'),\n",
       "  ('?', '.'),\n",
       "  ('Cash', 'NNP'),\n",
       "  ('only', 'RB'),\n",
       "  ('!', '.')],\n",
       " [('best', 'JJS'),\n",
       "  ('pizza', 'NN'),\n",
       "  ('in', 'IN'),\n",
       "  ('south', 'JJ'),\n",
       "  ('side', 'NN'),\n",
       "  ('.', '.'),\n",
       "  ('huge', 'JJ'),\n",
       "  ('drink', 'NN'),\n",
       "  ('selection', 'NN'),\n",
       "  ('.', '.'),\n",
       "  ('awesome', 'VB'),\n",
       "  ('atmosphere', 'RB'),\n",
       "  ('.', '.'),\n",
       "  ('$', '$'),\n",
       "  ('4', 'CD'),\n",
       "  ('for', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('slice', 'NN'),\n",
       "  ('that', 'WDT'),\n",
       "  ('could', 'MD'),\n",
       "  ('easily', 'RB'),\n",
       "  ('feed', 'VB'),\n",
       "  ('2', 'CD'),\n",
       "  ('people', 'NNS'),\n",
       "  ('!', '.')]]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_tagged = []\n",
    "for sentence in random_sentences:\n",
    "    nltk_tagged.append((nltk.pos_tag(word_tokenize(sentence))))\n",
    "nltk_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "5d874c6c-1f0f-4232-b819-693f49a971a2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Que      PROPN \n",
      "ce       PROPN \n",
      "soit     ADJ   \n",
      "pour     NOUN  \n",
      "leurs    VERB  \n",
      "délicieux NOUN  \n",
      "bubbles  NOUN  \n",
      "tea      NOUN  \n",
      "/        SYM   \n",
      "smooties NOUN  \n",
      ",        PUNCT \n",
      "leurs    VERB  \n",
      "''       PUNCT \n",
      "Bánh     PROPN \n",
      "mì       INTJ  \n",
      "''       PUNCT \n",
      ",        PUNCT \n",
      "leurs    NOUN  \n",
      "petits   VERB  \n",
      "snacks   NOUN  \n",
      "(        PUNCT \n",
      "viennoiseries NOUN  \n",
      ",        PUNCT \n",
      "tapioca  INTJ  \n",
      ",        PUNCT \n",
      "...      PUNCT \n",
      ")        PUNCT \n",
      ",        PUNCT \n",
      "on       ADP   \n",
      "adore    PROPN \n",
      "Vua      PROPN \n",
      "et       PROPN \n",
      "aussi    PROPN \n",
      "leurs    VERB  \n",
      "prix     NOUN  \n",
      "très     ADJ   \n",
      "abordables NOUN  \n",
      ".        PUNCT \n",
      "On       ADP   \n",
      "y        PROPN \n",
      "retourne VERB  \n",
      "lorsqu'on PROPN \n",
      "est      PROPN \n",
      "dans     PROPN \n",
      "le       X     \n",
      "Quartier PROPN \n",
      "Latin    PROPN \n",
      "!        PUNCT \n",
      "As       ADP   \n",
      "I        PRON  \n",
      "'ve      AUX   \n",
      "said     VERB  \n",
      "previously ADV   \n",
      "...      PUNCT \n",
      "we've    PROPN \n",
      "been     AUX   \n",
      "coming   VERB  \n",
      "to       ADP   \n",
      "LMAH     PROPN \n",
      "for      ADP   \n",
      "over     ADP   \n",
      "10       NUM   \n",
      "years    NOUN  \n",
      ".        PUNCT \n",
      "At       ADV   \n",
      "least    ADJ   \n",
      "15       NUM   \n",
      ".        PUNCT \n",
      "And      CCONJ \n",
      "we       PRON  \n",
      "'ve      AUX   \n",
      "ALWAYS   ADV   \n",
      "seen     VERB  \n",
      "Dr.      PROPN \n",
      "White    PROPN \n",
      ".        PUNCT \n",
      "\n",
      "        SPACE \n",
      "I        PRON  \n",
      "had      VERB  \n",
      "to       PART  \n",
      "bring    VERB  \n",
      "my       PRON  \n",
      "cat      NOUN  \n",
      "in       ADP   \n",
      "to       PART  \n",
      "have     VERB  \n",
      "a        DET   \n",
      "urine    NOUN  \n",
      "sample   NOUN  \n",
      "done     VERB  \n",
      ".        PUNCT \n",
      "While    SCONJ \n",
      "being    AUX   \n",
      "done     VERB  \n",
      ",        PUNCT \n",
      "my       PRON  \n",
      "cat      NOUN  \n",
      "pee'd    ADV   \n",
      "on       ADP   \n",
      "himself  PRON  \n",
      ".        PUNCT \n",
      "The      DET   \n",
      "vet      NOUN  \n",
      "or       CCONJ \n",
      "staff    NOUN  \n",
      "only     ADV   \n",
      "tried    VERB  \n",
      "to       PART  \n",
      "clean    VERB  \n",
      "it       PRON  \n",
      "off      ADP   \n",
      "of       ADP   \n",
      "him      PRON  \n",
      "with     ADP   \n",
      "alcohol  NOUN  \n",
      ".        PUNCT \n",
      "They     PRON  \n",
      "did      AUX   \n",
      "n't      PART  \n",
      "try      VERB  \n",
      "to       PART  \n",
      "actually ADV   \n",
      "get      VERB  \n",
      "it       PRON  \n",
      "off      ADP   \n",
      "of       ADP   \n",
      "him      PRON  \n",
      ".        PUNCT \n",
      "They     PRON  \n",
      "did      AUX   \n",
      "n't      PART  \n",
      "even     ADV   \n",
      "TELL     VERB  \n",
      "ME       PRON  \n",
      "that     SCONJ \n",
      "he       PRON  \n",
      "pee'd    VERB  \n",
      "all      ADV   \n",
      "over     ADP   \n",
      "his      PRON  \n",
      "stomach  NOUN  \n",
      "and      CCONJ \n",
      "legs     NOUN  \n",
      ".        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "So       ADV   \n",
      "now      ADV   \n",
      "I        PRON  \n",
      "e        VERB  \n",
      "had      VERB  \n",
      "to       PART  \n",
      "give     VERB  \n",
      "my       PRON  \n",
      "cat      NOUN  \n",
      "a        DET   \n",
      "bath     NOUN  \n",
      "because  SCONJ \n",
      "they     PRON  \n",
      "ca       AUX   \n",
      "n't      PART  \n",
      "take     VERB  \n",
      "a        DET   \n",
      "urine    NOUN  \n",
      "sample   NOUN  \n",
      "properly ADV   \n",
      ".        PUNCT \n",
      "I        PRON  \n",
      "am       AUX   \n",
      "LIVID    PROPN \n",
      ".        PUNCT \n",
      "Pretty   ADV   \n",
      "decent   ADJ   \n",
      "but      CCONJ \n",
      "so       ADV   \n",
      "spacious ADJ   \n",
      "!        PUNCT \n",
      "         SPACE \n",
      "Very     ADV   \n",
      "good     ADJ   \n",
      "for      ADP   \n",
      "kids     NOUN  \n",
      "and      CCONJ \n",
      "you      PRON  \n",
      "can      AUX   \n",
      "order    VERB  \n",
      "dim      NOUN  \n",
      "sum      NOUN  \n",
      "!        PUNCT \n",
      "They     PRON  \n",
      "'re      VERB  \n",
      "open     ADJ   \n",
      "!        PUNCT \n",
      "!        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "Free     ADJ   \n",
      "wifi     NOUN  \n",
      "and      CCONJ \n",
      "awesome  ADJ   \n",
      ":)       PUNCT \n",
      "Dumpling PROPN \n",
      "Village  PROPN \n",
      "really   ADV   \n",
      "suffering VERB  \n",
      "from     ADP   \n",
      "identity NOUN  \n",
      "crisis   NOUN  \n",
      "!        PUNCT \n",
      "!        PUNCT \n",
      "Is       AUX   \n",
      "it       PRON  \n",
      "a        DET   \n",
      "Korean   PROPN \n",
      "Restaurant PROPN \n",
      ",        PUNCT \n",
      "not      PART  \n",
      "really   ADV   \n",
      ".        PUNCT \n",
      "There    PRON  \n",
      "are      AUX   \n",
      "mostly   ADV   \n",
      "Northern ADJ   \n",
      "Chinese  ADJ   \n",
      "items    NOUN  \n",
      "on       ADP   \n",
      "the      DET   \n",
      "menu     NOUN  \n",
      "like     ADP   \n",
      "dumplings NOUN  \n",
      ".        PUNCT \n",
      "Is       AUX   \n",
      "it       PRON  \n",
      "a        DET   \n",
      "Northern ADJ   \n",
      "Chinese  ADJ   \n",
      "restaurant NOUN  \n",
      ",        PUNCT \n",
      "not      PART  \n",
      "really   ADV   \n",
      "There    PRON  \n",
      "are      AUX   \n",
      "a        DET   \n",
      "lot      NOUN  \n",
      "of       ADP   \n",
      "Korean   ADJ   \n",
      "dishes   NOUN  \n",
      "         SPACE \n",
      "in       ADP   \n",
      "the      DET   \n",
      "menu     NOUN  \n",
      "like     ADP   \n",
      "pork     NOUN  \n",
      "bone     NOUN  \n",
      "soup     NOUN  \n",
      ",        PUNCT \n",
      "cold     ADJ   \n",
      "wheat    NOUN  \n",
      "bucknoodle NOUN  \n",
      "soup     NOUN  \n",
      ",        PUNCT \n",
      "kimchi   PROPN \n",
      "and      CCONJ \n",
      "bean     NOUN  \n",
      "sprout   NOUN  \n",
      "as       ADP   \n",
      "appetitizers NOUN  \n",
      ".        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "The      DET   \n",
      "only     ADJ   \n",
      "Korean   ADJ   \n",
      "characters NOUN  \n",
      "are      AUX   \n",
      "the      DET   \n",
      "3        NUM   \n",
      "on       ADP   \n",
      "their    PRON  \n",
      "business NOUN  \n",
      "sign     NOUN  \n",
      "in       ADP   \n",
      "the      DET   \n",
      "front    NOUN  \n",
      "..       PUNCT \n",
      "and      CCONJ \n",
      "all      DET   \n",
      "the      DET   \n",
      "rest     NOUN  \n",
      "are      VERB  \n",
      "in       ADP   \n",
      "Chinese  PROPN \n",
      "and      CCONJ \n",
      "English  PROPN \n",
      ".        PUNCT \n",
      "All      DET   \n",
      "the      DET   \n",
      "wait     ADJ   \n",
      "staffs   NOUN  \n",
      "here     ADV   \n",
      "speak    VERB  \n",
      "Mandarian PROPN \n",
      "and      CCONJ \n",
      "even     ADV   \n",
      "most     ADJ   \n",
      "of       ADP   \n",
      "the      DET   \n",
      "patrons  NOUN  \n",
      "are      VERB  \n",
      "Chinese  ADJ   \n",
      ".        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "It       PRON  \n",
      "is       AUX   \n",
      "located  VERB  \n",
      "in       ADP   \n",
      "a        DET   \n",
      "really   ADV   \n",
      "tiny     ADJ   \n",
      "strip    NOUN  \n",
      "mall     NOUN  \n",
      "..       PUNCT \n",
      "with     ADP   \n",
      "limited  ADJ   \n",
      "parkings NOUN  \n",
      "!        PUNCT \n",
      "To       PART  \n",
      "tell     VERB  \n",
      "you      PRON  \n",
      "the      DET   \n",
      "truth    NOUN  \n",
      "I        PRON  \n",
      "am       VERB  \n",
      "in       ADP   \n",
      "the      DET   \n",
      "area     NOUN  \n",
      "for      ADP   \n",
      "over     ADP   \n",
      "10       NUM   \n",
      "years    NOUN  \n",
      "I        PRON  \n",
      "never    ADV   \n",
      "notice   VERB  \n",
      "it       PRON  \n",
      "until    ADP   \n",
      "I        PRON  \n",
      "read     VERB  \n",
      "the      DET   \n",
      "reviews  NOUN  \n",
      "on       ADP   \n",
      "yelp     NOUN  \n",
      "!        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "We       PRON  \n",
      "arrived  VERB  \n",
      "around   ADV   \n",
      "6        NUM   \n",
      "pm       NOUN  \n",
      "on       ADP   \n",
      "a        DET   \n",
      "Saturday PROPN \n",
      ".        PUNCT \n",
      "The      DET   \n",
      "restaurant NOUN  \n",
      "was      AUX   \n",
      "almost   ADV   \n",
      "full     ADJ   \n",
      ".        PUNCT \n",
      "         SPACE \n",
      "The      DET   \n",
      "tables   NOUN  \n",
      "are      AUX   \n",
      "not      PART  \n",
      "really   ADV   \n",
      "packed   VERB  \n",
      "together ADV   \n",
      ",        PUNCT \n",
      "so       ADV   \n",
      "you      PRON  \n",
      "still    ADV   \n",
      "have     VERB  \n",
      "a        DET   \n",
      "certain  ADJ   \n",
      "degree   NOUN  \n",
      "of       ADP   \n",
      "privacy  NOUN  \n",
      "at       ADP   \n",
      "least    ADJ   \n",
      "I        PRON  \n",
      "can      AUX   \n",
      "not      PART  \n",
      "tell     VERB  \n",
      "what     PRON  \n",
      "the      DET   \n",
      "table    NOUN  \n",
      "next     ADV   \n",
      "to       ADP   \n",
      "me       PRON  \n",
      "were     AUX   \n",
      "eating   VERB  \n",
      ".        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "We       PRON  \n",
      "decided  VERB  \n",
      "on       ADP   \n",
      "my       PRON  \n",
      "favourite ADJ   \n",
      "chives   NOUN  \n",
      "and      CCONJ \n",
      "pork     NOUN  \n",
      "dumplings NOUN  \n",
      ",        PUNCT \n",
      "kimchi   PROPN \n",
      "fried    VERB  \n",
      "rice     NOUN  \n",
      "and      CCONJ \n",
      "Korean   ADJ   \n",
      "cold     ADJ   \n",
      "bucknoodle NOUN  \n",
      "soup     NOUN  \n",
      ".        PUNCT \n",
      "They     PRON  \n",
      "are      AUX   \n",
      "all      ADV   \n",
      "$        SYM   \n",
      "4.99     NUM   \n",
      ".        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "The      DET   \n",
      "cold     ADJ   \n",
      "noodle   NOUN  \n",
      "soup     NOUN  \n",
      "is       AUX   \n",
      "so       ADV   \n",
      "so       ADV   \n",
      "good     ADJ   \n",
      "!        PUNCT \n",
      "Nice     ADJ   \n",
      "and      CCONJ \n",
      "refreshing ADJ   \n",
      "!        PUNCT \n",
      "and      CCONJ \n",
      "the      DET   \n",
      "soup     NOUN  \n",
      "based    VERB  \n",
      "is       AUX   \n",
      "a        DET   \n",
      "little   ADJ   \n",
      "sour     ADJ   \n",
      "and      CCONJ \n",
      "it       PRON  \n",
      "really   ADV   \n",
      "stimulate VERB  \n",
      "your     PRON  \n",
      "tastebuds NOUN  \n",
      "and      CCONJ \n",
      "just     ADV   \n",
      "make     VERB  \n",
      "you      PRON  \n",
      "want     VERB  \n",
      "to       PART  \n",
      "eat      VERB  \n",
      "more     ADJ   \n",
      "!        PUNCT \n",
      "(        PUNCT \n",
      "I        PRON  \n",
      "can      AUX   \n",
      "finish   VERB  \n",
      "it       PRON  \n",
      "all      DET   \n",
      "myself   PRON  \n",
      "!        PUNCT \n",
      "I        PRON  \n",
      "do       AUX   \n",
      "n't      PART  \n",
      "want     VERB  \n",
      "to       PART  \n",
      "share    VERB  \n",
      "!        PUNCT \n",
      "I        PRON  \n",
      "want     VERB  \n",
      "one      NUM   \n",
      "all      DET   \n",
      "for      ADP   \n",
      "myself   PRON  \n",
      "next     ADJ   \n",
      "time     NOUN  \n",
      "!        PUNCT \n",
      ")        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "The      DET   \n",
      "kimchi   PROPN \n",
      "fried    VERB  \n",
      "rice     NOUN  \n",
      "..       PUNCT \n",
      "hmmmmm   ADV   \n",
      "not      PART  \n",
      "good     ADJ   \n",
      "!        PUNCT \n",
      "A        DET   \n",
      "little   ADJ   \n",
      "on       ADP   \n",
      "the      DET   \n",
      "oily     ADJ   \n",
      "side     NOUN  \n",
      ".        PUNCT \n",
      "There    PRON  \n",
      "are      AUX   \n",
      "not      PART  \n",
      "much     ADJ   \n",
      "taste    NOUN  \n",
      ",        PUNCT \n",
      "not      PART  \n",
      "spicy    ADJ   \n",
      "enough   ADV   \n",
      "?        PUNCT \n",
      "We       PRON  \n",
      "could    AUX   \n",
      "not      PART  \n",
      "finish   VERB  \n",
      "it       PRON  \n",
      "and      CCONJ \n",
      "end      VERB  \n",
      "up       ADP   \n",
      "have     VERB  \n",
      "to       PART  \n",
      "pack     VERB  \n",
      "it       PRON  \n",
      "all      DET   \n",
      "to       PART  \n",
      "go       VERB  \n",
      "...      PUNCT \n",
      "(not     INTJ  \n",
      "even     ADV   \n",
      "sure     ADJ   \n",
      "I        PRON  \n",
      "will     AUX   \n",
      "eat      VERB  \n",
      "it       PRON  \n",
      ",        PUNCT \n",
      "but      CCONJ \n",
      "can      AUX   \n",
      "not      PART  \n",
      "just     ADV   \n",
      "let      VERB  \n",
      "it       PRON  \n",
      "all      DET   \n",
      "go       VERB  \n",
      "to       AUX   \n",
      "waste    VERB  \n",
      ")        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "The      DET   \n",
      "dumplings NOUN  \n",
      "arrived  VERB  \n",
      "last     ADJ   \n",
      "!        PUNCT \n",
      "But      CCONJ \n",
      "it       PRON  \n",
      "really   ADV   \n",
      "worth    ADJ   \n",
      "the      DET   \n",
      "wait     NOUN  \n",
      "!        PUNCT \n",
      "14       NUM   \n",
      "big      ADJ   \n",
      "fat      ADJ   \n",
      "hot      ADJ   \n",
      "dumplings NOUN  \n",
      "filled   VERB  \n",
      "up       ADP   \n",
      "the      DET   \n",
      "whole    ADJ   \n",
      "steamer  NOUN  \n",
      "!        PUNCT \n",
      "Yes      INTJ  \n",
      "I        PRON  \n",
      "counted  VERB  \n",
      "them     PRON  \n",
      "14       NUM   \n",
      "of       ADP   \n",
      "them     PRON  \n",
      "for      ADP   \n",
      "$        SYM   \n",
      "4.99     NUM   \n",
      ".        PUNCT \n",
      "They     PRON  \n",
      "are      AUX   \n",
      "all      DET   \n",
      "freshly  ADV   \n",
      "made     VERB  \n",
      ",        PUNCT \n",
      "freshly  ADV   \n",
      "steamed  ADJ   \n",
      "!        PUNCT \n",
      "The      DET   \n",
      "skin     NOUN  \n",
      "is       AUX   \n",
      "nice     ADJ   \n",
      "and      CCONJ \n",
      "thin     ADJ   \n",
      ",        PUNCT \n",
      "not      PART  \n",
      "chewy    NOUN  \n",
      "and      CCONJ \n",
      "thick    ADJ   \n",
      "!        PUNCT \n",
      "Oh       INTJ  \n",
      "so       ADV   \n",
      "delicious ADJ   \n",
      "!        PUNCT \n",
      "One      NUM   \n",
      "bite     NOUN  \n",
      "and      CCONJ \n",
      "all      DET   \n",
      "the      DET   \n",
      "soup     NOUN  \n",
      "are      AUX   \n",
      "ozzing   VERB  \n",
      "out      ADP   \n",
      "!        PUNCT \n",
      "But      CCONJ \n",
      "if       SCONJ \n",
      "they     PRON  \n",
      "are      AUX   \n",
      "not      PART  \n",
      "burning  VERB  \n",
      "hot      ADJ   \n",
      ",        PUNCT \n",
      "you      PRON  \n",
      "can      AUX   \n",
      "just     ADV   \n",
      "stuff    VERB  \n",
      "the      DET   \n",
      "whole    ADJ   \n",
      "thing    NOUN  \n",
      "into     ADP   \n",
      "your     PRON  \n",
      "mouth    NOUN  \n",
      "and      CCONJ \n",
      "let      VERB  \n",
      "the      DET   \n",
      "soup     NOUN  \n",
      "and      CCONJ \n",
      "favour   NOUN  \n",
      "just     ADV   \n",
      "explosed VERB  \n",
      "in       ADP   \n",
      "your     PRON  \n",
      "mouth    NOUN  \n",
      ".        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "Just     ADV   \n",
      "a        DET   \n",
      "warning  NOUN  \n",
      ".        PUNCT \n",
      "If       SCONJ \n",
      "you      PRON  \n",
      "going    VERB  \n",
      "out      ADP   \n",
      "on       ADP   \n",
      "a        DET   \n",
      "date     NOUN  \n",
      ",        PUNCT \n",
      "please   INTJ  \n",
      "do       AUX   \n",
      "n't      PART  \n",
      "come     VERB  \n",
      "here     ADV   \n",
      ".        PUNCT \n",
      "Even     ADV   \n",
      "it       PRON  \n",
      "is       VERB  \n",
      "a        DET   \n",
      "good     ADJ   \n",
      "place    NOUN  \n",
      "for      ADP   \n",
      "a        DET   \n",
      "cheap    ADJ   \n",
      "date     NOUN  \n",
      ",        PUNCT \n",
      "our      PRON  \n",
      "bill     NOUN  \n",
      "was      AUX   \n",
      "$        SYM   \n",
      "18       NUM   \n",
      "for      ADP   \n",
      "2        NUM   \n",
      "and      CCONJ \n",
      "we       PRON  \n",
      "were     VERB  \n",
      "full     ADJ   \n",
      "!        PUNCT \n",
      "But      CCONJ \n",
      "the      DET   \n",
      "place    NOUN  \n",
      "can      AUX   \n",
      "be       VERB  \n",
      "noisy    ADJ   \n",
      ",        PUNCT \n",
      "the      DET   \n",
      "food     NOUN  \n",
      "too      ADV   \n",
      "good     ADJ   \n",
      "and      CCONJ \n",
      "your     PRON  \n",
      "date     NOUN  \n",
      "will     AUX   \n",
      "be       VERB  \n",
      "too      ADV   \n",
      "busy     ADJ   \n",
      "eating   VERB  \n",
      "and      CCONJ \n",
      "just     ADV   \n",
      "ignore   VERB  \n",
      "you      PRON  \n",
      "!        PUNCT \n",
      "Or       CCONJ \n",
      "you      PRON  \n",
      "will     AUX   \n",
      "keep     VERB  \n",
      "eating   VERB  \n",
      "and      CCONJ \n",
      "eating   VERB  \n",
      "and      CCONJ \n",
      "you      PRON  \n",
      "freak    VERB  \n",
      "all      DET   \n",
      "your     PRON  \n",
      "friends  NOUN  \n",
      "out      ADP   \n",
      "!        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "The      DET   \n",
      "services NOUN  \n",
      "here     ADV   \n",
      "is       AUX   \n",
      "cold     ADJ   \n",
      "but      CCONJ \n",
      "efficient ADJ   \n",
      ".        PUNCT \n",
      "We       PRON  \n",
      "were     AUX   \n",
      "given    VERB  \n",
      "extra    ADJ   \n",
      "napkins  NOUN  \n",
      "without  ADP   \n",
      "requesting VERB  \n",
      "...      PUNCT \n",
      "Maybe    ADV   \n",
      "we       PRON  \n",
      "looked   VERB  \n",
      "really   ADV   \n",
      "messy    ADJ   \n",
      "?        PUNCT \n",
      "?        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "Cash     VERB  \n",
      "only     ADV   \n",
      "!        PUNCT \n",
      "best     ADJ   \n",
      "pizza    NOUN  \n",
      "in       ADP   \n",
      "south    ADJ   \n",
      "side     NOUN  \n",
      ".        PUNCT \n",
      "huge     ADJ   \n",
      "drink    NOUN  \n",
      "selection NOUN  \n",
      ".        PUNCT \n",
      "awesome  ADJ   \n",
      "atmosphere NOUN  \n",
      ".        PUNCT \n",
      "$        SYM   \n",
      "4        NUM   \n",
      "for      ADP   \n",
      "a        DET   \n",
      "slice    NOUN  \n",
      "that     DET   \n",
      "could    AUX   \n",
      "easily   ADV   \n",
      "feed     VERB  \n",
      "2        NUM   \n",
      "people   NOUN  \n",
      "!        PUNCT \n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "spacy_tagged = []\n",
    "for sentence in random_sentences:\n",
    "    spacy_tagged.append(nlp(sentence))\n",
    "for tagged in spacy_tagged:\n",
    "    for token in tagged:\n",
    "        print(f'{token.text:{8}} {token.pos_:{6}}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3627839e",
   "metadata": {},
   "source": [
    "# WORK COMPLETED UP TILL HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f44ab",
   "metadata": {},
   "source": [
    "### Writing Style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63e1a01",
   "metadata": {},
   "source": [
    "#### Getting SOF article data (originally random, source code in get_urls.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "46d9ac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "page1 = requests.get('https://stackoverflow.com/questions/41306813')\n",
    "soup1 = BeautifulSoup(page1.content, \"html.parser\")\n",
    "text = list(soup1.find_all(\"p\"))\n",
    "sof_text1 = [txt.get_text() for txt in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "61b6bcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "page1 = requests.get('https://stackoverflow.com/questions/16498749')\n",
    "soup1 = BeautifulSoup(page1.content, \"html.parser\")\n",
    "text = list(soup1.find_all(\"p\"))\n",
    "sof_text2 = [txt.get_text() for txt in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed25252d",
   "metadata": {},
   "source": [
    "#### Getting HWZ article data (originally random, source code in get_urls.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "c41958bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "page1 = requests.get('https://www.hardwarezone.com.sg/tech-news-shang-chi-legend-ten-rings-available-streaming-disney-plus-day')\n",
    "soup1 = BeautifulSoup(page1.content, \"html.parser\")\n",
    "text = list(soup1.find_all(\"p\"))\n",
    "hwz_text1 = [txt.get_text() for txt in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "0f5fff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "page1 = requests.get('https://www.hardwarezone.com.sg/feature-apple-iphone-13-iphone-13-pro-2021-review-singapore-price-specs')\n",
    "soup1 = BeautifulSoup(page1.content, \"html.parser\")\n",
    "text = list(soup1.find_all(\"p\"))\n",
    "hwz_text2 = [txt.get_text() for txt in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8878be3",
   "metadata": {},
   "source": [
    "#### Getting CNA article data (originally random, source code in get_urls.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "02e20518",
   "metadata": {},
   "outputs": [],
   "source": [
    "page1 = requests.get('https://www.channelnewsasia.com/world/macron-tells-europe-stop-being-naive-after-france-signs-defence-deal-greece-2207351')\n",
    "soup1 = BeautifulSoup(page1.content, \"html.parser\")\n",
    "text = list(soup1.find_all(\"p\"))\n",
    "cna_text1 = [txt.get_text() for txt in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "90e4cff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "page1 = requests.get('https://www.channelnewsasia.com/singapore/de-beers-wong-tian-jun-sugar-daddy-appeal-sentence-2199481')\n",
    "soup1 = BeautifulSoup(page1.content, \"html.parser\")\n",
    "text = list(soup1.find_all(\"p\"))\n",
    "cna_text2 = [txt.get_text() for txt in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eee8a1e",
   "metadata": {},
   "source": [
    "##### Cleaning SOF text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "cabf88ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sof_text1 = sof_text1[4:]\n",
    "sof_text1 = sof_text1[:-10]\n",
    "temp_list = []\n",
    "for line in sof_text1:\n",
    "    temp_list += sent_tokenize(line)\n",
    "sof_text1 = temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "5be9617b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am using a BlueImp Gallery to add lightboxes to my image gallery.',\n",
       " 'So, when you click on an image thumbnail, it launches a lightbox with a larger version of the image etc.',\n",
       " 'I also want to add in alt attribute to larger lightbox image, but I am having trouble making it work.',\n",
       " \"It won't show the alt attributes that I have added in.\",\n",
       " \"Here's what I have so far;\",\n",
       " 'HTML:',\n",
       " 'CSS:',\n",
       " 'JS:',\n",
       " \"And in my body (gallery.js is the file where I've added the above JS):\",\n",
       " 'And some fiddle about this',\n",
       " 'http://jsfiddle.net/LXp76/70/',\n",
       " \"Any pointers on where I've gone wrong would be much appreciated!\",\n",
       " 'My question is similar with this topic:',\n",
       " 'Adding descriptions inside a blueimp gallery',\n",
       " 'but not exactly the same, because i dont want to add description, i want to add \"alt\" attribute to img.']"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sof_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "dc0f4293",
   "metadata": {},
   "outputs": [],
   "source": [
    "sof_text2 = sof_text2[4:]\n",
    "sof_text2 = sof_text2[:-10]\n",
    "temp_list = []\n",
    "for line in sof_text2:\n",
    "    temp_list += sent_tokenize(line)\n",
    "sof_text2 = temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "dfc1b995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I have several files for an app in image processing.',\n",
       " 'As the number of rows and colums for an image does not change while doing some image processing algorithm I was trying to put those values in constant memory.',\n",
       " 'My app looks like:',\n",
       " 'Imageproc.cuh',\n",
       " 'Imageproc.cu',\n",
       " 'It compiles well but when trying to run the program I get invalid device symbol cudaMemcpyToSymbol(&c_rows, &rows, sizeof(int))',\n",
       " \"Can't I put those variables in constant memory or what am I missing?\",\n",
       " 'If your symbol is declared like this:',\n",
       " 'then the correct call to cudaMemcpyToSymbol is just']"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sof_text2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0fb7f9",
   "metadata": {},
   "source": [
    "##### Cleaning CNA text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "6186128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cna_text1 = cna_text1[2:]\n",
    "cna_text1 = cna_text1[:-7]\n",
    "temp_list = []\n",
    "for line in cna_text1:\n",
    "    temp_list += sent_tokenize(line)\n",
    "cna_text1 = temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "df4cf0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['French President Emmanuel Macron gives a press conference with Greek Prime Minister during a signing ceremony of a new defence deal at The Elysee Palace in Paris, France September 28, 2021.',\n",
       " 'Ludovic Marin/Pool via REUTERS',\n",
       " 'PARIS: Europe needs to stop being naive when it comes to defending its interests and build its own military capacity, French President Emmanuel Macron said on Tuesday (Sep 28) after Greece sealed a deal for French frigates worth about €3 billion (US$3.51 billion).',\n",
       " 'France was plunged into an unprecedented diplomatic crisis with the United States, Australia and Britain earlier this month over a trilateral nuclear security deal which sank a multi-billion dollar French-designed submarine contract with Canberra.',\n",
       " 'That has caused much soul searching in Paris over its traditional alliances.',\n",
       " 'Speaking for the first time on the issue, Macron on Tuesday seized the opportunity to urge for more European autonomy as Washington increasingly reorientates its interests towards China and the Indo-Pacific.',\n",
       " '\"The Europeans must stop being naive.',\n",
       " 'When we are under pressure from powers, which at times harden (their stance) , we need to react and show that we have the power and capacity to defend ourselves.',\n",
       " 'Not escalating things, but protecting ourselves,\" Macron told a news conference with Greek Prime Minister Kyriakos Mitsotakis.',\n",
       " '\"This isn\\'t an alternative to the United States alliance.',\n",
       " 'It\\'s not a substitution, but to take responsibility of the European pillar within NATO and draw the conclusions that we are asked to take care of our own protection.\"',\n",
       " \"Under Tuesday's agreement Athens agreed to buy three frigates with an option to buy a fourth for about €3 billion, a Greek government source told Reuters.\",\n",
       " 'The accord, part of a broader strategic military and defence cooperation pact, comes after Athens had already ordered around 24 Dassault-made Rafale fighter jets this year, making it the first European Union country to buy the fighter jet.',\n",
       " '\"This will tie us for decades,\" Mitsotakis said.',\n",
       " '\"This opens the door to the Europe of tomorrow that is strong and autonomous, capable of defending its interests.\"',\n",
       " 'When asked whether this deal risked raising tensions in the eastern Mediterranean, Macron said the accord did not target a country specifically, but Greece, as the outer border of the European Union needed to be protected.']"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cna_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "c2baa4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cna_text2 = cna_text2[2:]\n",
    "cna_text2 = cna_text2[:-8]\n",
    "temp_list = []\n",
    "for line in cna_text2:\n",
    "    temp_list += sent_tokenize(line)\n",
    "cna_text2 = temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "c1c5d16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cna_text2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626d0987",
   "metadata": {},
   "source": [
    "##### Cleaning HWZ text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "5c822fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hwz_text1 = hwz_text1[:-5]\n",
    "temp_list = []\n",
    "for line in hwz_text1:\n",
    "    temp_list += sent_tokenize(line)\n",
    "hwz_text1 = temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "08d6154d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['On 12 November, The Walt Disney Company will host Disney+ Day, a global celebration that will also see\\xa0subscribers in Singapore being\\xa0treated to new content releases across the service’s brands, Disney, Pixar, Marvel, Star Wars, National Geographic, and Star, along with a special presentation on Disney+ with sneak peeks into what’s to come.',\n",
       " 'In a press release, Disney also revealed that subscribers will have access to promotions and experiences across the Company.',\n",
       " 'For instance, Disney Parks and Resorts around the world and Disney Cruise Line will \"roll out the blue carpet\" for Disney+ fans with some surprise and delight moments including photo opportunities, character moments and more.',\n",
       " \"Obviously, these won't be available to Singapore-based subscribers\\xa0unless you happen to be in the US, Paris or Tokyo, where the theme parks and resorts are available.\",\n",
       " 'Disney, however, did say that more localised details will be shared in the coming weeks.',\n",
       " '“This day of appreciation brings to life our mission to entertain, inform, and inspire fans and families around the globe through the power of unparalleled storytelling, and will become an annual tentpole event to be amplified across our global businesses.\"',\n",
       " 'said Bob Chapek, Chief Executive Officer, The Walt Disney Company.',\n",
       " 'Perhaps the most exciting part of Disney+ Day for all subscribers are the content premieres from all of its brands on service, including:',\n",
       " '●\\xa0\\xa0 \\xa0The streaming premiere of Marvel Studios’ “Shang-Chi and The Legend of The Ten Rings”\\xa0\\r\\n●\\xa0\\xa0 \\xa0The Disney family-friendly adventure film “Jungle Cruise,” available to all subscribers\\r\\n●\\xa0\\xa0 \\xa0The new Disney+ Original movie “Home Sweet Home Alone,” a reimagining of the popular holiday franchise\\r\\n●\\xa0\\xa0 \\xa0An all-new original series of shorts from Walt Disney Animation Studios called “Olaf Presents,” which sees Frozen’s beloved snowman retelling several classic Disney tales as only he can\\xa0\\r\\n●\\xa0\\xa0 \\xa0An animated short film “Ciao Alberto” from Pixar, featuring characters from this summer’s animated hit breakout film “Luca”\\xa0\\r\\n●\\xa0\\xa0 \\xa0A new short from The Simpsons that pays tribute to Disney+’s marquee brands\\r\\n●\\xa0\\xa0 \\xa0The first five episodes from season 2 of “The World According to Jeff Goldblum” from National Geographic\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the origins and legacy of Star Wars’ legendary bounty hunter, Boba Fett\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the Marvel Cinematic Universe on Disney+ with an exciting look towards the future\\r\\n●\\xa0\\xa0 \\xa0“Dopesick,” an original series starring Michael Keaton, which will be released in international markets as part of the Star general entertainment content offering',\n",
       " 'Subscribers can also look forward to the inaugural Disney+ Day fan celebration on Disney+, which will include breaking news, first looks, new trailers, exclusive clips, and appearances from Disney+ creators and stars.',\n",
       " 'Additionally,\\xa0Disney also announced that Disney+ will expand into new Asia-Pacific markets, making its\\xa0debut in South Korea and Taiwan on 12 November, and in Hong Kong on 16 November.',\n",
       " 'Find out how Aftershock stays ahead of the custom PC curve!']"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hwz_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "d96f688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hwz_text2 = hwz_text2[:-5]\n",
    "temp_list = []\n",
    "for line in hwz_text2:\n",
    "    temp_list += sent_tokenize(line)\n",
    "hwz_text2 = temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "4b659cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Note: This review was first published on 21 September 2021 and it's republished now because the new iPhones are available in retail.\",\n",
       " 'Despite reservations about the name, Apple has stuck with what’s sensible and went with the number 13 for their latest iPhones.',\n",
       " 'You might have already heard, Apple’s newest iPhones are the iPhone 13 and iPhone 13 Mini, and the iPhone 13 Pro and iPhone 13 Pro Max .',\n",
       " 'No surprises, there.',\n",
       " 'However, there are some profound changes compared to last year’s lineup and that could affect your purchasing decision.',\n",
       " 'Sit down, grab a cuppa, this is a long one.',\n",
       " 'Last year’s iPhones\\xa0got\\xa0a major redesign so we knew we weren’t going to be getting phones that look drastically different this year.',\n",
       " 'The basic recipe for this year’s iPhones is nearly identical to last year’s models.',\n",
       " 'In fact, unless you know what to look out for, you’d be hard-pressed to tell the difference between this year’s models and last year’s.',\n",
       " 'They all have flat sides and the iPhone 13 and 13 Mini have aluminium bodies while the iPhone 13 Pro and 13 Pro Max have stainless steel bodies.',\n",
       " 'The sides of the iPhone 13 and 13 Mini are matte, whereas the iPhone 13 Pro and 13 Pro Max have highly polished sides that are fingerprint and dirt magnets.',\n",
       " 'Round the back, the regular iPhones continue to have clear glossy glass backs while the Pro iPhones have matte glass backs.',\n",
       " 'Speaking of glass, the front of the phones are protected by Ceramic Shield, a glass that was developed with Corning to be the strongest smartphone glass ever – again, the same as last year’s models.',\n",
       " 'And since we are on the topic of protection, the IP ratings of the phones are unchanged, so all of this year’s iPhones are rated IP68 which means they can stay submerged in up to six metres of water for up to 30 minutes.',\n",
       " 'Buttons and ports are also all carried over, which means the Lightning port\\xa0is sticking around for another year.',\n",
       " 'Now, I have strong thoughts about the Lightning port.',\n",
       " 'At this point, the Lightning port should make way for USB-C.',\n",
       " 'Previously, a point could be made for compatibility but since all new Macs and nearly all new\\xa0iPads rely on USB-C, it’s time that iPhones do the same.',\n",
       " 'USB-C not only enables faster charging, it also transfers data quicker, and works with a greater variety of accessories.',\n",
       " 'It’s funny because Apple talks about all the benefits of USB-C in its Mac and iPad events and yet puts Lightning ports on their phones.',\n",
       " 'Alright, rant over.',\n",
       " 'Overall dimensions are slightly different.',\n",
       " 'Heights and widths are identical but the new iPhones all gain 0.25mm in thickness.',\n",
       " 'This is to accommodate the larger battery.',\n",
       " 'And because there’s a larger battery inside, the weight has gone up a bit.',\n",
       " 'Is it noticeable?',\n",
       " 'Sure, but only if you hold them next to each other.',\n",
       " 'Readers who have invested in expensive phone cases, however, should note that the camera bump is larger to put up the new sensors and lenses (more on this in the photography section).',\n",
       " 'So yes, if you are upgrading from last year’s phones to this year’s, these differences are enough that you will need new cases for these phones, even if you think they can stretch to accommodate the extra thickness.',\n",
       " 'Another minor difference is the notch on the display.',\n",
       " 'The TrueDepth camera system is unchanged and continues to take great 12-megapixel photos and offer Face ID authentication, but Apple has shrunk the system so the notch is 20% smaller.',\n",
       " 'Honestly, I didn’t really notice the difference until I placed it next to an older iPhone.',\n",
       " 'There are new colours to choose from.',\n",
       " 'The iPhone 13 and 13 Mini are available five colours: PRODUCT(RED), Starlight, Midnight, Blue, and Pink.',\n",
       " 'The units I have are the iPhone 13 in Pink and the iPhone 13 Mini in Midnight.',\n",
       " 'Pink is a very lovely soft shade of pink that I think can be more accurately described as pastel pink.',\n",
       " 'Midnight, on the other hand, can be easily passed off as black.',\n",
       " 'Unfortunately, I couldn’t get to see the entire lineup so I can’t comment on the other colours.',\n",
       " 'The iPhone 13 Pro and 13 Pro Max are available in four colours.',\n",
       " 'Graphite, Gold, and Silver make their return and joining them this year is the new Sierra Blue finish.',\n",
       " 'Like last year’s models, the highly polished finish is achieved using a physical vapour deposition process (PVD).',\n",
       " 'And according to Apple, the Sierra Blue model required an entirely new process that involves placing multiple layers of nanometer-scale metallic ceramics to achieve the colour.',\n",
       " 'As for the Pro iPhones, the units I have are the iPhone 13 Pro in Gold and the iPhone 13 Pro Max in Sierra Blue.',\n",
       " \"This year’s Gold finish is slightly different from last year's.\",\n",
       " \"The polished sides are indistinguishable from one another but the glass back of this year's model is a richer darker shade of gold.\",\n",
       " \"As for Sierra Blue, it appears to be a lighter shade of last year's Pacific Blue.\",\n",
       " 'Overall, fans of last year’s new design will love this year’s phones.',\n",
       " 'But even if you don’t fancy the squared-off edges and flat sides, the outstanding build quality of these phones is undeniable.',\n",
       " 'Yes, these phones are expensive but they most definitely look and feel every bit as much as they cost.',\n",
       " 'Have feedback on the article for the editorial team?',\n",
       " 'You can reach out to them here.',\n",
       " 'Find out how Aftershock stays ahead of the custom PC curve!']"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hwz_text2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11179763",
   "metadata": {},
   "source": [
    "##### First word in sentence capitalized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "93702e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of first letter being capitalised for sof_text1:  0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "uppercount=0\n",
    "for sent in sof_text1:\n",
    "    if sent[0].isupper():\n",
    "        uppercount+=1\n",
    "    count+=1\n",
    "print(\"Fraction of first letter being capitalised for sof_text1: \", uppercount/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "b7ebe5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of first letter being capitalised for sof_text2:  0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "uppercount=0\n",
    "for sent in sof_text2:\n",
    "    if sent[0].isupper():\n",
    "        uppercount+=1\n",
    "    count+=1\n",
    "print(\"Fraction of first letter being capitalised for sof_text2: \", uppercount/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "913e6519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of first letter being capitalised for hwz_text1:  0.75\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "uppercount=0\n",
    "for sent in hwz_text1:\n",
    "    if sent[0].isupper():\n",
    "        uppercount+=1\n",
    "    count+=1\n",
    "print(\"Fraction of first letter being capitalised for hwz_text1: \", uppercount/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "d80943eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of first letter being capitalised for hwz_text2:  1.0\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "uppercount=0\n",
    "for sent in hwz_text2:\n",
    "    if sent[0].isupper():\n",
    "        uppercount+=1\n",
    "    count+=1\n",
    "print(\"Fraction of first letter being capitalised for hwz_text2: \", uppercount/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "20b0680a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of first letter being capitalised for cna_text1:  0.75\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "uppercount=0\n",
    "for sent in cna_text1:\n",
    "    if sent[0].isupper():\n",
    "        uppercount+=1\n",
    "    count+=1\n",
    "print(\"Fraction of first letter being capitalised for cna_text1: \", uppercount/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "2a4bcc3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24116/1962085332.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0muppercount\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mcount\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fraction of first letter being capitalised for cna_text2: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muppercount\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "uppercount=0\n",
    "for sent in cna_text2:\n",
    "    if sent[0].isupper():\n",
    "        uppercount+=1\n",
    "    count+=1\n",
    "print(\"Fraction of first letter being capitalised for cna_text2: \", uppercount/count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e31e9b",
   "metadata": {},
   "source": [
    "##### Length of articles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1137d9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No of sentences in sof_text1: \", len(sof_text1))\n",
    "print(\"No of sentences in sof_text2: \", len(sof_text2))\n",
    "print(\"No of sentences in hwz_text1: \", len(hwz_text1))\n",
    "print(\"No of sentences in hwz_text2: \", len(hwz_text2))\n",
    "print(\"No of sentences in cna_text1: \", len(cna_text1))\n",
    "print(\"No of sentences in cna_text2: \", len(cna_text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90754d4",
   "metadata": {},
   "source": [
    "##### Proper nouns capitalised?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5c0f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = []\n",
    "uppercount = 0\n",
    "count = 0\n",
    "for sentence in sof_text1:\n",
    "    tagged.append(nlp(sentence))\n",
    "for tag in tagged:\n",
    "    for token in tag:\n",
    "        if token.pos_ == 'PROPN':\n",
    "            if token.text[0].isupper():\n",
    "                uppercount += 1\n",
    "            count += 1\n",
    "print('Fraction of proper nouns capitalised in sof_text1: ', uppercount/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0d3f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = []\n",
    "uppercount = 0\n",
    "count = 0\n",
    "for sentence in sof_text2:\n",
    "    tagged.append(nlp(sentence))\n",
    "for tag in tagged:\n",
    "    for token in tag:\n",
    "        if token.pos_ == 'PROPN':\n",
    "            if token.text[0].isupper():\n",
    "                uppercount += 1\n",
    "            count += 1\n",
    "print('Fraction of proper nouns capitalised in sof_text2: ', uppercount/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a68814",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = []\n",
    "uppercount = 0\n",
    "count = 0\n",
    "for sentence in hwz_text1:\n",
    "    tagged.append(nlp(sentence))\n",
    "for tag in tagged:\n",
    "    for token in tag:\n",
    "        if token.pos_ == 'PROPN':\n",
    "            if token.text[0].isupper():\n",
    "                uppercount += 1\n",
    "            count += 1\n",
    "print('Fraction of proper nouns capitalised in hwz_text1: ', uppercount/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adda956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = []\n",
    "uppercount = 0\n",
    "count = 0\n",
    "for sentence in hwz_text2:\n",
    "    tagged.append(nlp(sentence))\n",
    "for tag in tagged:\n",
    "    for token in tag:\n",
    "        if token.pos_ == 'PROPN':\n",
    "            if token.text[0].isupper():\n",
    "                uppercount += 1\n",
    "            count += 1\n",
    "print('Fraction of proper nouns capitalised in hwz_text2: ', uppercount/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37fd7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = []\n",
    "uppercount = 0\n",
    "count = 0\n",
    "for sentence in cna_text1:\n",
    "    tagged.append(nlp(sentence))\n",
    "for tag in tagged:\n",
    "    for token in tag:\n",
    "        if token.pos_ == 'PROPN':\n",
    "            if token.text[0].isupper():\n",
    "                uppercount += 1\n",
    "            count += 1\n",
    "print('Fraction of proper nouns capitalised in cna_text1: ', uppercount/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176ff7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = []\n",
    "uppercount = 0\n",
    "count = 0\n",
    "for sentence in cna_text2:\n",
    "    tagged.append(nlp(sentence))\n",
    "for tag in tagged:\n",
    "    for token in tag:\n",
    "        if token.pos_ == 'PROPN':\n",
    "            if token.text[0].isupper():\n",
    "                uppercount += 1\n",
    "            count += 1\n",
    "print('Fraction of proper nouns capitalised in cna_text2: ', uppercount/count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7828fc9",
   "metadata": {},
   "source": [
    "###### What kind of proper nouns used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9214571",
   "metadata": {},
   "source": [
    "1. Stack Overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d27c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sof_tagged = []\n",
    "sof_noun_dict = {}\n",
    "for sentence in sof_text1:\n",
    "    sof_tagged.append(nlp(sentence))\n",
    "for sentence in sof_text2:\n",
    "    sof_tagged.append(nlp(sentence))\n",
    "for tagged in sof_tagged:\n",
    "    for token in tagged:\n",
    "        if token.pos_ in (\"PROPN\", \"NOUN\"):\n",
    "            if token.text in sof_noun_dict.keys():\n",
    "                sof_noun_dict[token.text] += 1\n",
    "            else:\n",
    "                sof_noun_dict[token.text] = 1\n",
    "\n",
    "sof_noun_dict_sorted = sorted(sof_noun_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i in sof_noun_dict_sorted:\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbdc5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hwz_tagged = []\n",
    "hwz_noun_dict = {}\n",
    "for sentence in hwz_text1:\n",
    "    hwz_tagged.append(nlp(sentence))\n",
    "for sentence in hwz_text2:\n",
    "    hwz_tagged.append(nlp(sentence))\n",
    "for tagged in hwz_tagged:\n",
    "    for token in tagged:\n",
    "        if token.pos_ in (\"PROPN\", \"NOUN\"):\n",
    "            if token.text in hwz_noun_dict.keys():\n",
    "                hwz_noun_dict[token.text] += 1\n",
    "            else:\n",
    "                hwz_noun_dict[token.text] = 1\n",
    "\n",
    "hwz_noun_dict_sorted = sorted(hwz_noun_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i in hwz_noun_dict_sorted:\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b3b95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cna_tagged = []\n",
    "cna_noun_dict = {}\n",
    "for sentence in cna_text1:\n",
    "    cna_tagged.append(nlp(sentence))\n",
    "for sentence in cna_text2:\n",
    "    cna_tagged.append(nlp(sentence))\n",
    "for tagged in cna_tagged:\n",
    "    for token in tagged:\n",
    "        if token.pos_ in (\"PROPN\", \"NOUN\"):\n",
    "            if token.text in cna_noun_dict.keys():\n",
    "                cna_noun_dict[token.text] += 1\n",
    "            else:\n",
    "                cna_noun_dict[token.text] = 1\n",
    "\n",
    "cna_noun_dict_sorted = sorted(cna_noun_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i in cna_noun_dict_sorted:\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac262786",
   "metadata": {},
   "source": [
    "##### Good grammar?\n",
    "1. Subject-verb agreement\n",
    "2. Tense matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c91989b",
   "metadata": {},
   "source": [
    "#### Subject-verb agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a097237d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "def is_passive(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    dict1 = {'DEP': 'nsubjpass'}\n",
    "    dict2 = {'DEP': 'aux', 'OP': '*'}\n",
    "    dict3 = {'DEP': 'auxpass'}\n",
    "    dict4 = {'TAG': 'VBN'}\n",
    "    passive_rule = [dict1, dict2, dict3, dict4]\n",
    "    matcher.add(\"Passive\", [passive_rule])\n",
    "    matches = matcher(doc)\n",
    "    if matches:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d8894a",
   "metadata": {},
   "source": [
    "https://github.com/armsp/active_or_passive/blob/master/spacy_voices.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff55e652",
   "metadata": {},
   "source": [
    "### Short break to count the % of passive sentences in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503a3e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sof_text1_passivecounts = 0\n",
    "sof_text2_passivecounts = 0 \n",
    "\n",
    "for sent in sof_text1:\n",
    "    if is_passive(sent):\n",
    "        sof_text1_passivecounts += 1\n",
    "for sent in sof_text2:\n",
    "    if is_passive(sent):\n",
    "        sof_text2_passivecounts += 1\n",
    "\n",
    "print(\"% of passive sentences in sof_text1: \", sof_text1_passivecounts/len(sof_text1))\n",
    "print(\"% of passive sentences in sof_text2: \", sof_text2_passivecounts/len(sof_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d474e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "hwz_text1_passivecounts = 0\n",
    "hwz_text2_passivecounts = 0 \n",
    "\n",
    "for sent in hwz_text1:\n",
    "    if is_passive(sent):\n",
    "        hwz_text1_passivecounts += 1\n",
    "for sent in hwz_text2:\n",
    "    if is_passive(sent):\n",
    "        hwz_text2_passivecounts += 1\n",
    "\n",
    "print(\"% of passive sentences in hwz_text1: \", hwz_text1_passivecounts/len(hwz_text1))\n",
    "print(\"% of passive sentences in hwz_text2: \", hwz_text2_passivecounts/len(hwz_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2f9dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cna_text1_passivecounts = 0\n",
    "cna_text2_passivecounts = 0 \n",
    "\n",
    "for sent in cna_text1:\n",
    "    if is_passive(sent):\n",
    "        cna_text1_passivecounts += 1\n",
    "for sent in cna_text2:\n",
    "    if is_passive(sent):\n",
    "        cna_text2_passivecounts += 1\n",
    "\n",
    "print(\"% of passive sentences in cna_text1: \", cna_text1_passivecounts/len(cna_text1))\n",
    "print(\"% of passive sentences in cna_text2: \", cna_text2_passivecounts/len(cna_text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043af22c",
   "metadata": {},
   "source": [
    "# Ok back to business"
   ]
  },
  {
   "cell_type": "raw",
   "id": "620f74cf",
   "metadata": {},
   "source": [
    "for sent in sof_text1:\n",
    "    if not is_passive(sent):\n",
    "        sent_tagged = nlp(sent)\n",
    "        for word, tag in sent_tagged:\n",
    "            if tag == 'NNS' or tag == 'AUX':\n",
    "                \n",
    "        \n",
    "for sent in sof_text2:\n",
    "    if is_passive(sent):\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ffa9de",
   "metadata": {},
   "source": [
    "# I'm gonna see the percentage of short sentences first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078c01fe",
   "metadata": {},
   "source": [
    "## 1. Avg length of sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab469c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = 0\n",
    "for sent in sof_text1:\n",
    "    total_words += len(sent)\n",
    "print(\"Average length of sentences in sof_text1: \", total_words/len(sof_text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e812d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = 0\n",
    "for sent in sof_text2:\n",
    "    total_words += len(sent)\n",
    "print(\"Average length of sentences in sof_text2: \", total_words/len(sof_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3740f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = 0\n",
    "for sent in hwz_text1:\n",
    "    total_words += len(sent)\n",
    "print(\"Average length of sentences in hwz_text1: \", total_words/len(hwz_text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bb00f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = 0\n",
    "for sent in hwz_text2:\n",
    "    total_words += len(sent)\n",
    "print(\"Average length of sentences in hwz_text2: \", total_words/len(hwz_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe4a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = 0\n",
    "for sent in cna_text1:\n",
    "    total_words += len(sent)\n",
    "print(\"Average length of sentences in cna_text1: \", total_words/len(cna_text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd6a4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = 0\n",
    "for sent in cna_text2:\n",
    "    total_words += len(sent)\n",
    "print(\"Average length of sentences in cna_text2: \", total_words/len(cna_text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4166e5e",
   "metadata": {},
   "source": [
    "2. Short sentences in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212ae6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for sent in sof_text1:\n",
    "    if len(sent) < 20:\n",
    "        count += 1\n",
    "print(\"Count of short sentences in sof_text1: \", count)\n",
    "print(\"Total no of sentences in sof_text1: \", len(sof_text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb40d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for sent in sof_text2:\n",
    "    if len(sent) < 20:\n",
    "        count += 1\n",
    "print(\"Count of short sentences in sof_text2: \", count)\n",
    "print(\"Total no of sentences in sof_text2: \", len(sof_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf32b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for sent in hwz_text1:\n",
    "    if len(sent) < 20:\n",
    "        count += 1\n",
    "print(\"Count of short sentences in hwz_text1: \", count)\n",
    "print(\"Total no of sentences in hwz_text1: \", len(hwz_text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0071c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for sent in hwz_text2:\n",
    "    if len(sent) < 20:\n",
    "        count += 1\n",
    "print(\"Count of short sentences in hwz_text2: \", count)\n",
    "print(\"Total no of sentences in hwz_text2: \", len(hwz_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98347bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for sent in cna_text1:\n",
    "    if len(sent) < 20:\n",
    "        count += 1\n",
    "print(\"Count of short sentences in cna_text1: \", count)\n",
    "print(\"Total no of sentences in cna_text1: \", len(cna_text1))\n",
    "print(cna_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2916f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for sent in cna_text2:\n",
    "    if len(sent) < 20:\n",
    "        count += 1\n",
    "print(\"Count of short sentences in cna_text2: \", count)\n",
    "print(\"Total no of sentences in cna_text2: \", len(cna_text2))\n",
    "print(cna_text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584df9b9",
   "metadata": {},
   "source": [
    "#### Trying this package (language_tool_python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "193fa8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading LanguageTool: 100%|█████████████████████████████████████████████████████| 203M/203M [00:22<00:00, 9.17MB/s]\n",
      "Unzipping C:\\Users\\colot\\AppData\\Local\\Temp\\tmprlqli8ip.zip to C:\\Users\\colot\\.cache\\language_tool_python.\n",
      "Downloaded https://www.languagetool.org/download/LanguageTool-5.4.zip to C:\\Users\\colot\\.cache\\language_tool_python.\n"
     ]
    }
   ],
   "source": [
    "import language_tool_python\n",
    "tool = language_tool_python.LanguageTool('en-US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "8547e0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['Blimp', 'Blueish'], 'offsetInContext': 13, 'context': 'I am using a BlueImp Gallery to add lightboxes to my image g...', 'offset': 13, 'errorLength': 7, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'I am using a BlueImp Gallery to add lightboxes to my image gallery.'}), Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['light boxes'], 'offsetInContext': 36, 'context': 'I am using a BlueImp Gallery to add lightboxes to my image gallery.', 'offset': 36, 'errorLength': 10, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'I am using a BlueImp Gallery to add lightboxes to my image gallery.'}), Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['light box'], 'offsetInContext': 43, 'context': '...ck on an image thumbnail, it launches a lightbox with a larger version of the image etc....', 'offset': 56, 'errorLength': 8, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'So, when you click on an image thumbnail, it launches a lightbox with a larger version of the image etc.'}), Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['light box'], 'offsetInContext': 43, 'context': '... want to add in alt attribute to larger lightbox image, but I am having trouble making i...', 'offset': 46, 'errorLength': 8, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'I also want to add in alt attribute to larger lightbox image, but I am having trouble making it work.'}), Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['blue imp'], 'offsetInContext': 29, 'context': 'Adding descriptions inside a blueimp gallery', 'offset': 29, 'errorLength': 7, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'Adding descriptions inside a blueimp gallery'}), Match({'ruleId': 'UPPERCASE_SENTENCE_START', 'message': 'This sentence does not start with an uppercase letter.', 'replacements': ['But'], 'offsetInContext': 0, 'context': 'but not exactly the same, because i dont wa...', 'offset': 0, 'errorLength': 3, 'category': 'CASING', 'ruleIssueType': 'typographical', 'sentence': 'but not exactly the same, because i dont want to add description, i want to add \"alt\" attribute to img.'}), Match({'ruleId': 'EN_CONTRACTION_SPELLING', 'message': 'Possible spelling mistake found', 'replacements': [\"don't\"], 'offsetInContext': 36, 'context': 'but not exactly the same, because i dont want to add description, i want to add ...', 'offset': 36, 'errorLength': 4, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'but not exactly the same, because i dont want to add description, i want to add \"alt\" attribute to img.'}), Match({'ruleId': 'I_LOWERCASE', 'message': 'The personal pronoun “I” should be uppercase.', 'replacements': ['I'], 'offsetInContext': 43, 'context': '...because i dont want to add description, i want to add \"alt\" attribute to img.', 'offset': 66, 'errorLength': 1, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'but not exactly the same, because i dont want to add description, i want to add \"alt\" attribute to img.'}), Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['IMG', 'BMG', 'IMF', 'CMG', 'IMO', 'DMG', 'GMG', 'IMA', 'IMC', 'IMT', 'IMU', 'SMG', 'imp', 'IDG', 'mg', 'AMG', 'FMG', 'IAG', 'IEG', 'ILG', 'IMAG', 'IMB', 'IMD', 'IME', 'IMH', 'IMK', 'IMN', 'IMP', 'IMS', 'IMV', 'ING', 'IPG', 'IRG', 'ISG', 'IVG', 'MG', 'Mg', 'OMG', 'PMG', 'TMG', 'i mg', 'IG', 'IM', 'IMs', 'in', 'is', 'I', 'it', 'him', 'me', 'time', 'if', 'its', 'my', 'km', 'King', 'image', 'king', 'mid', 'wing', 'FM', 'Mr', 'am', 'big', 'cm', 'dog', 'ice', 'leg', 'mm', 'ring', 'IBM', 'Jim', 'aims', 'kg', 'mix', 'sing', 'tag', 'BMW', 'IRA', 'MA', 'PM', 'bag', 'egg', 'ill', 'ink', 'ion', 'log', 'pm', 'rim', 'ICT', 'ID', 'IDF', 'IOC', 'IQ', 'RPG', 'SG', 'XML', 'bug', 'dig', 'dug', 'fog', 'gag', 'gig', 'id', 'inn', 'limb', 'lime', 'min', 'pig', 'rig', 'BMT', 'DM', 'GMT', 'ICU', 'IEC', 'IIT', 'INS', 'IPA', 'IPO', 'IRS', 'ISP', 'ITF', 'ITU', 'Lima', 'MV', 'Ming', 'Mk', 'NMR', 'RMS', 'SMS', 'amp', 'beg', 'bog', 'dim', 'fig', 'icy', 'ire', 'lag', 'ma', 'ml', 'tug', 'wig', 'AEG', 'AIG', 'AMX', 'APG', 'Aug', 'BMC', 'BMP', 'CMA', 'CME', 'CNG', 'DG', 'DMC', 'DMS', 'DMZ', 'ECG', 'EMT', 'IAS', 'IAU', 'ICL', 'ICP', 'IDs', 'IFA', 'IFC', 'IPC', 'IPS', 'IRL', 'ITC', 'ITT', 'JMA', 'LMA', 'LNG', 'LPG', 'MCG', 'MF', 'MMP', 'MX', 'Meg', 'Mimi', 'PNG', 'Sims', 'VM', 'VMS', 'WMD', 'avg', 'dime', 'hog', 'hug', 'imam', 'ivy', 'jug', 'limp', 'lug', 'mic', 'mil', 'mime', 'ms', 'mug', 'peg', 'ping', 'rag', 'rims', 'rug', 'smog', 'um', 'BMA', 'BMD', 'BMO', 'BMS', 'CCG', 'CMB', 'CMF', 'CMU', 'CSG', 'DME', 'DMK', 'DRG', 'EMB', 'EPG', 'FMC', 'HMC', 'IAA', 'IAC', 'IAP', 'ICM', 'ICR', 'IDC', 'IEA', 'IED', 'IEP', 'IFL', 'IFP', 'IFR', 'IGA', 'IH', 'IHS', 'IOM', 'IPN', 'IPP', 'IPR', 'IVB', 'IVs', 'Iago', 'Imus', 'Inge', 'Irma', 'JM', 'LMP', 'MMR', 'MMS', 'MMU', 'MMX', 'Mme', 'NRG', 'OMA', 'PMA', 'PMC', 'PMI', 'PMR', 'PMS', 'PSG', 'RMA', 'RMC', 'RMI', 'SME', 'TNG', 'Ting', 'VG', 'VMA', 'cog', 'deg', 'ding', 'emo', 'emu', 'hag', 'jig', 'jog', 'keg', 'limo', 'mag', 'mpg', 'sag', 'ACG', 'BIM', 'BME', 'BMR', 'DMD', 'DMP', 'DMV', 'EKG', 'EMR', 'FMA', 'GGG', 'GMB', 'GMD', 'GMO', 'HMI', 'HMO', 'IAB', 'IBP', 'ICN', 'ICO', 'IDL', 'IMSI', 'IPI', 'ITE', 'IUD', 'Ina', 'Iva', 'JMS', 'SMF', 'SMI', 'USG', 'aim', 'amt', 'emf', 'gm', 'ilk', 'imps', 'inf', 'jag', 'mp', 'nag', 'pug', 'reg', 'smug', 'ting', 'wag', 'CLG', 'DWG', 'GMI', 'IOU', 'IRQ', 'MTG', 'RMM', 'RNG', 'gimp', 'ifs', 'imago', 'isms', 'lg', 'wimp', 'BRG', 'PMs', 'dims', 'iamb', 'limy', 'neg', 'pkg', 'vim', 'zing', 'GBG', 'IMHO', 'Ind', 'ems', 'irk', 'mfg', 'AMC', 'Amy', 'CHG', 'GM', 'HMS', 'ICC', 'IP', 'ITV', 'Kim', 'MD', 'MW', 'Tim', 'oms', 'biog', 'limn', '1G', '2G', '3G', '4G', '5G', 'AAG', 'ABG', 'ADG', 'AEMG', 'AFG', 'AG', 'AGG', 'AHG', 'AIM', 'AIMF', 'AJG', 'AKG', 'ALG', 'AM', 'AMA', 'AMD', 'AMDG', 'AME', 'AMF', 'AMGE', 'AMH', 'AMJ', 'AMK', 'AML', 'AMM', 'AMN', 'AMO', 'AMP', 'AMQ', 'AMR', 'AMS', 'AMT', 'AMU', 'AMV', 'AMW', 'AMY', 'AMZ', 'ANG', 'AOG', 'AQG', 'ASG', 'ATG', 'AUG', 'AVG', 'AWG', 'AXG', 'AYG', 'Ag', 'Am', 'B2G', 'BBG', 'BCG', 'BDG', 'BFG', 'BGG', 'BHG', 'BLG', 'BM', 'BMB', 'BMF', 'BMI', 'BMJ', 'BMK', 'BML', 'BMM', 'BMN', 'BMQ', 'BMU', 'BMV', 'BMX', 'BMZ', 'BNG', 'BOG', 'BPG', 'BPMG', 'BSG', 'BTG', 'BVG', 'BWG', 'BXG', 'BYG', 'BZG', 'C0G', 'CAG', 'CBG', 'CDG', 'CEG', 'CFG', 'CG', 'CGG', 'CIM', 'CM', 'CMC', 'CMD', 'CMGR', 'CMI', 'CMJ', 'CMK', 'CML', 'CMM', 'CMO', 'CMP', 'CMR', 'CMS', 'CMT', 'CMV', 'CMW', 'CMX', 'COG', 'CPG', 'CQG', 'CRG', 'CUG', 'CVG', 'Cm', 'DEG', 'DFG', 'DIMM', 'DJG', 'DLG', 'DMF', 'DMGT', 'DMI', 'DMM', 'DMO', 'DMR', 'DSG', 'EEG', 'EG', 'EIG', 'EM', 'EMA', 'EMC', 'EMD', 'EME', 'EMF', 'EMI', 'EML', 'EMM', 'EMN', 'EMP', 'EMU', 'ENG', 'EOG', 'EWG', 'Eng', 'FAG', 'FBG', 'FCG', 'FFG', 'FG', 'FIG', 'FIM', 'FIMU', 'FMH', 'FMI', 'FMJ', 'FMM', 'FMO', 'FMP', 'FMS', 'FMT', 'FMV', 'FMs', 'FNG', 'FRG', 'FSG', 'FTG', 'Fm', 'G', 'GAG', 'GCG', 'GG', 'GKG', 'GMF', 'GML', 'GMP', 'GMR', 'GMS', 'GMU', 'GPG', 'GTG', 'GUG', 'GWG', 'Gog', 'HCG', 'HKG', 'HM', 'HMD', 'HMP', 'HMV', 'HUG', 'HVG', 'Hg', 'I10', 'I11', 'I12', 'I15', 'I16', 'I19', 'I20', 'I21', 'I22', 'I24', 'I25', 'I26', 'I27', 'I29', 'I30', 'I35', 'I37', 'I39', 'I3P', 'I40', 'I42', 'I43', 'I44', 'I45', 'I49', 'I53', 'I64', 'I65', 'I66', 'I68', 'I69', 'I70', 'I71', 'I72', 'I73', 'I74', 'I77', 'I78', 'I79', 'I80', 'I81', 'I82', 'I83', 'I84', 'I85', 'I86', 'I87', 'I88', 'I89', 'I95', 'I97', 'I99', 'IA', 'IA4', 'IA8', 'IAD', 'IAE', 'IAF', 'IAGA', 'IAH', 'IAI', 'IAMT', 'IAN', 'IAO', 'IAV', 'IB1', 'IBA', 'IBB', 'IBC', 'IBE', 'IBL', 'IBO', 'IBR', 'ICA', 'ICB', 'ICD', 'ICE', 'ICGA', 'ICGG', 'ICH', 'ICI', 'ID3', 'IDE', 'IDH', 'IDK', 'IDM', 'IDMS', 'IDN', 'IDR', 'IDS', 'IDT', 'IE', 'IEAG', 'IEF', 'IEM', 'IEMN', 'IES', 'IF', 'IFD', 'IFF', 'IFI', 'IFM', 'IFMA', 'IFMK', 'IFN', 'IFO', 'IFS', 'IFU', 'IGC', 'IGE', 'IGF', 'IGH', 'IGI', 'IGM', 'IGN', 'IGP', 'IGS', 'IHP', 'IHT', 'IIA', 'IIC', 'IIF', 'IIM', 'IIN', 'IIS', 'IJ', 'IJF', 'IJM', 'IKB', 'IL', 'IL2', 'ILC', 'ILGN', 'ILM', 'ILN', 'ILP', 'IMAF', 'IMAO', 'IMCC', 'IMEI', 'IMOC', 'IN', 'INA', 'INB', 'INC', 'INE', 'INF', 'INH', 'INM', 'INMA', 'INP', 'INR', 'INT', 'INTG', 'IOB', 'IOF', 'IOI', 'IOP', 'IOPG', 'IOR', 'IOS', 'IOT', 'IOV', 'IPAG', 'IPB', 'IPD', 'IPE', 'IPF', 'IPGP', 'IPJ', 'IPM', 'IPT', 'IPY', 'IR', 'IRB', 'IRC', 'IRD', 'IRE', 'IRI', 'IRM', 'IRN', 'IRP', 'IRR', 'IRT', 'IRU', 'IS', 'ISA', 'ISB', 'ISC', 'ISD', 'ISEG', 'ISF', 'ISGT', 'ISI', 'ISK', 'ISL', 'ISM', 'ISME', 'ISN', 'ISO', 'ISR', 'ISS', 'IST', 'ISV', 'IT', 'ITA', 'ITB', 'ITK', 'ITL', 'ITP', 'ITS', 'IUF', 'IUGG', 'IV', 'IVD', 'IVF', 'IVI', 'IVR', 'IWC', 'IWF', 'IWGA', 'IXC', 'IXV', 'IZ', 'Ia', 'Ian', 'Ibo', 'Ice', 'Ida', 'Ike', 'Ila', 'Ill', 'In', 'Inc', 'Io', 'Ir', 'Ira', 'It', 'Ito', 'Ivy', 'JAG', 'JDG', 'JIM', 'JMB', 'JMD', 'JME', 'JMF', 'JMJ', 'JMM', 'JMP', 'JUG', 'KDG', 'KG', 'KM', 'KMA', 'KMF', 'KMH', 'KMS', 'KWG', 'LBG', 'LG', 'LGG', 'LIM', 'LIRG', 'LLG', 'LMB', 'LMC', 'LMD', 'LME', 'LMK', 'LMS', 'LMU', 'LMV', 'LVG', 'M', 'MAG', 'MB', 'MC', 'MDG', 'ME', 'MEG', 'MGA', 'MGB', 'MGD', 'MGF', 'MGG', 'MGI', 'MGM', 'MGR', 'MGS', 'MGV', 'MH', 'MI', 'MIG', 'MIM', 'MIME', 'MIMO', 'MJ', 'MK', 'MKG', 'ML', 'MM', 'MMA', 'MMB', 'MMC', 'MMH', 'MMI', 'MMK', 'MML', 'MMM', 'MMT', 'MMZ', 'MN', 'MNG', 'MO', 'MP', 'MR', 'MRG', 'MS', 'MSG', 'MT', 'MU', 'MY', 'MZ', 'Mb', 'Md', 'Me', 'Mgr', 'MiG', 'Mn', 'Mo', 'Ms', 'Mt', 'NAG', 'NBG', 'NG', 'NIG', 'NJG', 'NLG', 'NM', 'NMA', 'NMF', 'NMI', 'NMM', 'NMT', 'NPG', 'OCG', 'ODG', 'OGG', 'OIM', 'OM', 'OMB', 'OMC', 'OMFG', 'OMI', 'OMM', 'OMN', 'OMO', 'OMP', 'OMR', 'OMS', 'OMT', 'ONG', 'OPG', 'OSG', 'OTG', 'PAG', 'PCG', 'PDG', 'PG', 'PIM', 'PIME', 'PLG', 'PMB', 'PME', 'PMF', 'PMH', 'PML', 'PMN', 'PMO', 'PMP', 'PMT', 'PMU', 'PMV', 'PRG', 'PTG', 'PUG', 'PVG', 'PWG', 'PYG', 'Peg', 'Pm', 'QAG', 'QG', 'QM', 'QMF', 'RAG', 'REG', 'RIM', 'RIMA', 'RIMM', 'RM', 'RMB', 'RME', 'RMF', 'RMN', 'RRG', 'RTG', 'RUG', 'SAG', 'SBG', 'SEG', 'SFG', 'SGG', 'SHG', 'SIG', 'SIM', 'SIMC', 'SIMM', 'SLG', 'SM', 'SMA', 'SMB', 'SMC', 'SMH', 'SMIG', 'SMK', 'SML', 'SMM', 'SMN', 'SMR', 'SMT', 'SNG', 'SPG', 'SSG', 'STG', 'SVG', 'Sm', 'TAG', 'TCG', 'TDG', 'TG', 'TIG', 'TIME', 'TM', 'TMA', 'TMB', 'TMC', 'TMD', 'TME', 'TMI', 'TMJ', 'TMN', 'TMP', 'TMS', 'TMT', 'TMV', 'TMX', 'TOG', 'TPG', 'TSG', 'TUG', 'Tm', 'UAG', 'UFG', 'UG', 'UGG', 'UIG', 'UIM', 'UIMM', 'ULG', 'UMA', 'UMB', 'UMD', 'UMF', 'UMH', 'UMI', 'UML', 'UMM', 'UMP', 'UMR', 'UMS', 'UMT', 'URG', 'UTG', 'UUG', 'VLG', 'VMC', 'VME', 'VMI', 'VMK', 'VML', 'VMM', 'VMO', 'VMP', 'VRG', 'VSG', 'WAG', 'WCG', 'WEG', 'WIM', 'WIMP', 'WLG', 'WMF', 'WML', 'WMS', 'WMW', 'Wm', 'XLG', 'XMP', 'XMS', 'YAG', 'YBG', 'YCG', 'YM', 'YMN', 'YMO', 'YUG', 'YYG', 'ZG', 'ZIM', 'ZMK', 'ZMP', 'ang', 'cg', 'chg', 'dag', 'em', 'erg', 'fag', 'fug', 'g', 'hims', 'hing', 'hmm', 'i', 'iOS', 'ids', 'ii', 'iii', 'inc', 'ind', 'ins', 'int', 'isl', 'ism', 'isn', 'ite', 'iv', 'ix', 'jg', 'ling', 'm', 'meg', 'mgr', 'mi', 'mo', 'mtg', 'mu', 'om', 'org', 'pg', 'pimp', 'rime', 'rm', 'sim', 'sims', 'tog', 'ump', 'veg', 'wog', '3M', 'AMI', 'BG', 'Bing', 'CIG', 'CTG', 'DMGs', 'DMT', 'DMX', 'DMs', 'EMS', 'ESG', 'FMCG', 'FMD', 'GHG', 'GMA', 'GMC', 'GMV', 'HMH', 'I&S', 'IAM', 'IAT', 'IB', 'IBD', 'IBS', 'IC', 'ICF', 'ICJ', 'ICMP', 'ICMR', 'ICS', 'IDB', 'IDP', 'IDQ', 'IGO', 'ILS', 'IMAP', 'IMAX', 'IMDB', 'IMDb', 'IND', 'INI', 'ION', 'IPs', 'IQR', 'IQs', 'ISU', 'ITN', 'IU', 'IXL', 'Iggy', 'Imgur', 'Ingo', 'IoT', 'JMH', 'JPG', 'Jimi', 'Jing', 'KPMG', 'LM', 'LMs', 'LTG', 'MMO', 'NMC', 'OG', 'Ogg', 'P&G', 'PKG', 'PMD', 'QMS', 'Qing', 'RBG', 'RMU', 'SDG', 'SIMs', 'SMP', 'SMU', 'TMZ', 'TTG', 'UMC', 'VMs', 'Vimo', 'XING', 'Xing', 'Ying', 'Zug', 'amu', 'cmd', 'dm', 'dms', 'hm', 'iMac', 'mL', 'mW', 'mcg', 'msg', 'nm', 'pms', 'tmp', 'umm', 'vm', 'vog', 'µm'], 'offsetInContext': 43, 'context': '...ption, i want to add \"alt\" attribute to img.', 'offset': 99, 'errorLength': 3, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'but not exactly the same, because i dont want to add description, i want to add \"alt\" attribute to img.'})]\n"
     ]
    }
   ],
   "source": [
    "matches_sof = []\n",
    "for sent in sof_text1:\n",
    "    matches_sof += tool.check(sent)\n",
    "print(matches_sof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "58972983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake. ‘localised’ is British English.', 'replacements': ['localized'], 'offsetInContext': 35, 'context': 'Disney, however, did say that more localised details will be shared in the coming we...', 'offset': 35, 'errorLength': 9, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'Disney, however, did say that more localised details will be shared in the coming weeks.'}), Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['tent pole'], 'offsetInContext': 43, 'context': '...storytelling, and will become an annual tentpole event to be amplified across our global...', 'offset': 196, 'errorLength': 8, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': '“This day of appreciation brings to life our mission to entertain, inform, and inspire fans and families around the globe through the power of unparalleled storytelling, and will become an annual tentpole event to be amplified across our global businesses.\"'}), Match({'ruleId': 'EN_UNPAIRED_BRACKETS', 'message': 'Unpaired symbol: ‘\"’ seems to be missing', 'replacements': [], 'offsetInContext': 43, 'context': '... amplified across our global businesses.\"', 'offset': 256, 'errorLength': 1, 'category': 'PUNCTUATION', 'ruleIssueType': 'typographical', 'sentence': '“This day of appreciation brings to life our mission to entertain, inform, and inspire fans and families around the globe through the power of unparalleled storytelling, and will become an annual tentpole event to be amplified across our global businesses.\"'}), Match({'ruleId': 'UPPERCASE_SENTENCE_START', 'message': 'This sentence does not start with an uppercase letter.', 'replacements': ['Said'], 'offsetInContext': 0, 'context': 'said Bob Chapek, Chief Executive Officer, Th...', 'offset': 0, 'errorLength': 4, 'category': 'CASING', 'ruleIssueType': 'typographical', 'sentence': 'said Bob Chapek, Chief Executive Officer, The Walt Disney Company.'}), Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['Chapel', 'Capek'], 'offsetInContext': 9, 'context': 'said Bob Chapek, Chief Executive Officer, The Walt Disn...', 'offset': 9, 'errorLength': 6, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'said Bob Chapek, Chief Executive Officer, The Walt Disney Company.'}), Match({'ruleId': 'WHITESPACE_RULE', 'message': 'Possible typo: you repeated a whitespace', 'replacements': ['\\xa0'], 'offsetInContext': 1, 'context': '●\\xa0\\xa0 \\xa0The streaming premiere of Marvel Studios...', 'offset': 1, 'errorLength': 4, 'category': 'TYPOGRAPHY', 'ruleIssueType': 'whitespace', 'sentence': \"●\\xa0\\xa0 \\xa0The streaming premiere of Marvel Studios’ “Shang-Chi and The Legend of The Ten Rings”\\xa0\\r\\n●\\xa0\\xa0 \\xa0The Disney family-friendly adventure film “Jungle Cruise,” available to all subscribers\\r\\n●\\xa0\\xa0 \\xa0The new Disney+ Original movie “Home Sweet Home Alone,” a reimagining of the popular holiday franchise\\r\\n●\\xa0\\xa0 \\xa0An all-new original series of shorts from Walt Disney Animation Studios called “Olaf Presents,” which sees Frozen's beloved snowman retelling several classic Disney tales as only he can\\xa0\\r\\n●\\xa0\\xa0 \\xa0An animated short film “Ciao Alberto” from Pixar, featuring characters from this summer's animated hit breakout film “Luca”\\xa0\\r\\n●\\xa0\\xa0 \\xa0A new short from The Simpsons that pays tribute to Disney+'s marquee brands\\r\\n●\\xa0\\xa0 \\xa0The first five episodes from season 2 of “The World According to Jeff Goldblum” from National Geographic\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the origins and legacy of Star Wars’ legendary bounty hunter, Boba Fett\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the Marvel Cinematic Universe on Disney+ with an exciting look towards the future\\r\\n●\\xa0\\xa0 \\xa0“Dopesick,” an original series starring Michael Keaton, which will be released in international markets as part of the Star general entertainment content offering\"}), Match({'ruleId': 'WHITESPACE_RULE', 'message': 'Possible typo: you repeated a whitespace', 'replacements': ['\\xa0'], 'offsetInContext': 43, 'context': '...Chi and The Legend of The Ten Rings”\\xa0\\r ●\\xa0\\xa0 \\xa0The Disney family-friendly adventure fil...', 'offset': 94, 'errorLength': 4, 'category': 'TYPOGRAPHY', 'ruleIssueType': 'whitespace', 'sentence': \"●\\xa0\\xa0 \\xa0The streaming premiere of Marvel Studios’ “Shang-Chi and The Legend of The Ten Rings”\\xa0\\r\\n●\\xa0\\xa0 \\xa0The Disney family-friendly adventure film “Jungle Cruise,” available to all subscribers\\r\\n●\\xa0\\xa0 \\xa0The new Disney+ Original movie “Home Sweet Home Alone,” a reimagining of the popular holiday franchise\\r\\n●\\xa0\\xa0 \\xa0An all-new original series of shorts from Walt Disney Animation Studios called “Olaf Presents,” which sees Frozen's beloved snowman retelling several classic Disney tales as only he can\\xa0\\r\\n●\\xa0\\xa0 \\xa0An animated short film “Ciao Alberto” from Pixar, featuring characters from this summer's animated hit breakout film “Luca”\\xa0\\r\\n●\\xa0\\xa0 \\xa0A new short from The Simpsons that pays tribute to Disney+'s marquee brands\\r\\n●\\xa0\\xa0 \\xa0The first five episodes from season 2 of “The World According to Jeff Goldblum” from National Geographic\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the origins and legacy of Star Wars’ legendary bounty hunter, Boba Fett\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the Marvel Cinematic Universe on Disney+ with an exciting look towards the future\\r\\n●\\xa0\\xa0 \\xa0“Dopesick,” an original series starring Michael Keaton, which will be released in international markets as part of the Star general entertainment content offering\"}), Match({'ruleId': 'WHITESPACE_RULE', 'message': 'Possible typo: you repeated a whitespace', 'replacements': ['\\xa0'], 'offsetInContext': 43, 'context': '...Cruise,” available to all subscribers\\r ●\\xa0\\xa0 \\xa0The new Disney+ Original movie “Home Swe...', 'offset': 188, 'errorLength': 4, 'category': 'TYPOGRAPHY', 'ruleIssueType': 'whitespace', 'sentence': \"●\\xa0\\xa0 \\xa0The streaming premiere of Marvel Studios’ “Shang-Chi and The Legend of The Ten Rings”\\xa0\\r\\n●\\xa0\\xa0 \\xa0The Disney family-friendly adventure film “Jungle Cruise,” available to all subscribers\\r\\n●\\xa0\\xa0 \\xa0The new Disney+ Original movie “Home Sweet Home Alone,” a reimagining of the popular holiday franchise\\r\\n●\\xa0\\xa0 \\xa0An all-new original series of shorts from Walt Disney Animation Studios called “Olaf Presents,” which sees Frozen's beloved snowman retelling several classic Disney tales as only he can\\xa0\\r\\n●\\xa0\\xa0 \\xa0An animated short film “Ciao Alberto” from Pixar, featuring characters from this summer's animated hit breakout film “Luca”\\xa0\\r\\n●\\xa0\\xa0 \\xa0A new short from The Simpsons that pays tribute to Disney+'s marquee brands\\r\\n●\\xa0\\xa0 \\xa0The first five episodes from season 2 of “The World According to Jeff Goldblum” from National Geographic\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the origins and legacy of Star Wars’ legendary bounty hunter, Boba Fett\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the Marvel Cinematic Universe on Disney+ with an exciting look towards the future\\r\\n●\\xa0\\xa0 \\xa0“Dopesick,” an original series starring Michael Keaton, which will be released in international markets as part of the Star general entertainment content offering\"}), Match({'ruleId': 'WHITESPACE_RULE', 'message': 'Possible typo: you repeated a whitespace', 'replacements': ['\\xa0'], 'offsetInContext': 43, 'context': '...ning of the popular holiday franchise\\r ●\\xa0\\xa0 \\xa0An all-new original series of shorts fro...', 'offset': 297, 'errorLength': 4, 'category': 'TYPOGRAPHY', 'ruleIssueType': 'whitespace', 'sentence': \"●\\xa0\\xa0 \\xa0The streaming premiere of Marvel Studios’ “Shang-Chi and The Legend of The Ten Rings”\\xa0\\r\\n●\\xa0\\xa0 \\xa0The Disney family-friendly adventure film “Jungle Cruise,” available to all subscribers\\r\\n●\\xa0\\xa0 \\xa0The new Disney+ Original movie “Home Sweet Home Alone,” a reimagining of the popular holiday franchise\\r\\n●\\xa0\\xa0 \\xa0An all-new original series of shorts from Walt Disney Animation Studios called “Olaf Presents,” which sees Frozen's beloved snowman retelling several classic Disney tales as only he can\\xa0\\r\\n●\\xa0\\xa0 \\xa0An animated short film “Ciao Alberto” from Pixar, featuring characters from this summer's animated hit breakout film “Luca”\\xa0\\r\\n●\\xa0\\xa0 \\xa0A new short from The Simpsons that pays tribute to Disney+'s marquee brands\\r\\n●\\xa0\\xa0 \\xa0The first five episodes from season 2 of “The World According to Jeff Goldblum” from National Geographic\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the origins and legacy of Star Wars’ legendary bounty hunter, Boba Fett\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the Marvel Cinematic Universe on Disney+ with an exciting look towards the future\\r\\n●\\xa0\\xa0 \\xa0“Dopesick,” an original series starring Michael Keaton, which will be released in international markets as part of the Star general entertainment content offering\"}), Match({'ruleId': 'WHITESPACE_RULE', 'message': 'Possible typo: you repeated a whitespace', 'replacements': ['\\xa0'], 'offsetInContext': 43, 'context': '... classic Disney tales as only he can\\xa0\\r ●\\xa0\\xa0 \\xa0An animated short film “Ciao Alberto” fr...', 'offset': 490, 'errorLength': 4, 'category': 'TYPOGRAPHY', 'ruleIssueType': 'whitespace', 'sentence': \"●\\xa0\\xa0 \\xa0The streaming premiere of Marvel Studios’ “Shang-Chi and The Legend of The Ten Rings”\\xa0\\r\\n●\\xa0\\xa0 \\xa0The Disney family-friendly adventure film “Jungle Cruise,” available to all subscribers\\r\\n●\\xa0\\xa0 \\xa0The new Disney+ Original movie “Home Sweet Home Alone,” a reimagining of the popular holiday franchise\\r\\n●\\xa0\\xa0 \\xa0An all-new original series of shorts from Walt Disney Animation Studios called “Olaf Presents,” which sees Frozen's beloved snowman retelling several classic Disney tales as only he can\\xa0\\r\\n●\\xa0\\xa0 \\xa0An animated short film “Ciao Alberto” from Pixar, featuring characters from this summer's animated hit breakout film “Luca”\\xa0\\r\\n●\\xa0\\xa0 \\xa0A new short from The Simpsons that pays tribute to Disney+'s marquee brands\\r\\n●\\xa0\\xa0 \\xa0The first five episodes from season 2 of “The World According to Jeff Goldblum” from National Geographic\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the origins and legacy of Star Wars’ legendary bounty hunter, Boba Fett\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the Marvel Cinematic Universe on Disney+ with an exciting look towards the future\\r\\n●\\xa0\\xa0 \\xa0“Dopesick,” an original series starring Michael Keaton, which will be released in international markets as part of the Star general entertainment content offering\"}), Match({'ruleId': 'WHITESPACE_RULE', 'message': 'Possible typo: you repeated a whitespace', 'replacements': ['\\xa0'], 'offsetInContext': 43, 'context': '...’s animated hit breakout film “Luca”\\xa0\\r ●\\xa0\\xa0 \\xa0A new short from The Simpsons that pays ...', 'offset': 621, 'errorLength': 4, 'category': 'TYPOGRAPHY', 'ruleIssueType': 'whitespace', 'sentence': \"●\\xa0\\xa0 \\xa0The streaming premiere of Marvel Studios’ “Shang-Chi and The Legend of The Ten Rings”\\xa0\\r\\n●\\xa0\\xa0 \\xa0The Disney family-friendly adventure film “Jungle Cruise,” available to all subscribers\\r\\n●\\xa0\\xa0 \\xa0The new Disney+ Original movie “Home Sweet Home Alone,” a reimagining of the popular holiday franchise\\r\\n●\\xa0\\xa0 \\xa0An all-new original series of shorts from Walt Disney Animation Studios called “Olaf Presents,” which sees Frozen's beloved snowman retelling several classic Disney tales as only he can\\xa0\\r\\n●\\xa0\\xa0 \\xa0An animated short film “Ciao Alberto” from Pixar, featuring characters from this summer's animated hit breakout film “Luca”\\xa0\\r\\n●\\xa0\\xa0 \\xa0A new short from The Simpsons that pays tribute to Disney+'s marquee brands\\r\\n●\\xa0\\xa0 \\xa0The first five episodes from season 2 of “The World According to Jeff Goldblum” from National Geographic\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the origins and legacy of Star Wars’ legendary bounty hunter, Boba Fett\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the Marvel Cinematic Universe on Disney+ with an exciting look towards the future\\r\\n●\\xa0\\xa0 \\xa0“Dopesick,” an original series starring Michael Keaton, which will be released in international markets as part of the Star general entertainment content offering\"}), Match({'ruleId': 'WHITESPACE_RULE', 'message': 'Possible typo: you repeated a whitespace', 'replacements': ['\\xa0'], 'offsetInContext': 43, 'context': '...s tribute to Disney+’s marquee brands\\r ●\\xa0\\xa0 \\xa0The first five episodes from season 2 of...', 'offset': 703, 'errorLength': 4, 'category': 'TYPOGRAPHY', 'ruleIssueType': 'whitespace', 'sentence': \"●\\xa0\\xa0 \\xa0The streaming premiere of Marvel Studios’ “Shang-Chi and The Legend of The Ten Rings”\\xa0\\r\\n●\\xa0\\xa0 \\xa0The Disney family-friendly adventure film “Jungle Cruise,” available to all subscribers\\r\\n●\\xa0\\xa0 \\xa0The new Disney+ Original movie “Home Sweet Home Alone,” a reimagining of the popular holiday franchise\\r\\n●\\xa0\\xa0 \\xa0An all-new original series of shorts from Walt Disney Animation Studios called “Olaf Presents,” which sees Frozen's beloved snowman retelling several classic Disney tales as only he can\\xa0\\r\\n●\\xa0\\xa0 \\xa0An animated short film “Ciao Alberto” from Pixar, featuring characters from this summer's animated hit breakout film “Luca”\\xa0\\r\\n●\\xa0\\xa0 \\xa0A new short from The Simpsons that pays tribute to Disney+'s marquee brands\\r\\n●\\xa0\\xa0 \\xa0The first five episodes from season 2 of “The World According to Jeff Goldblum” from National Geographic\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the origins and legacy of Star Wars’ legendary bounty hunter, Boba Fett\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the Marvel Cinematic Universe on Disney+ with an exciting look towards the future\\r\\n●\\xa0\\xa0 \\xa0“Dopesick,” an original series starring Michael Keaton, which will be released in international markets as part of the Star general entertainment content offering\"}), Match({'ruleId': 'WHITESPACE_RULE', 'message': 'Possible typo: you repeated a whitespace', 'replacements': ['\\xa0'], 'offsetInContext': 43, 'context': '...ff Goldblum” from National Geographic\\r ●\\xa0\\xa0 \\xa0A special celebrating the origins and le...', 'offset': 814, 'errorLength': 4, 'category': 'TYPOGRAPHY', 'ruleIssueType': 'whitespace', 'sentence': \"●\\xa0\\xa0 \\xa0The streaming premiere of Marvel Studios’ “Shang-Chi and The Legend of The Ten Rings”\\xa0\\r\\n●\\xa0\\xa0 \\xa0The Disney family-friendly adventure film “Jungle Cruise,” available to all subscribers\\r\\n●\\xa0\\xa0 \\xa0The new Disney+ Original movie “Home Sweet Home Alone,” a reimagining of the popular holiday franchise\\r\\n●\\xa0\\xa0 \\xa0An all-new original series of shorts from Walt Disney Animation Studios called “Olaf Presents,” which sees Frozen's beloved snowman retelling several classic Disney tales as only he can\\xa0\\r\\n●\\xa0\\xa0 \\xa0An animated short film “Ciao Alberto” from Pixar, featuring characters from this summer's animated hit breakout film “Luca”\\xa0\\r\\n●\\xa0\\xa0 \\xa0A new short from The Simpsons that pays tribute to Disney+'s marquee brands\\r\\n●\\xa0\\xa0 \\xa0The first five episodes from season 2 of “The World According to Jeff Goldblum” from National Geographic\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the origins and legacy of Star Wars’ legendary bounty hunter, Boba Fett\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the Marvel Cinematic Universe on Disney+ with an exciting look towards the future\\r\\n●\\xa0\\xa0 \\xa0“Dopesick,” an original series starring Michael Keaton, which will be released in international markets as part of the Star general entertainment content offering\"}), Match({'ruleId': 'WHITESPACE_RULE', 'message': 'Possible typo: you repeated a whitespace', 'replacements': ['\\xa0'], 'offsetInContext': 43, 'context': '...s’ legendary bounty hunter, Boba Fett\\r ●\\xa0\\xa0 \\xa0A special celebrating the Marvel Cinemat...', 'offset': 914, 'errorLength': 4, 'category': 'TYPOGRAPHY', 'ruleIssueType': 'whitespace', 'sentence': \"●\\xa0\\xa0 \\xa0The streaming premiere of Marvel Studios’ “Shang-Chi and The Legend of The Ten Rings”\\xa0\\r\\n●\\xa0\\xa0 \\xa0The Disney family-friendly adventure film “Jungle Cruise,” available to all subscribers\\r\\n●\\xa0\\xa0 \\xa0The new Disney+ Original movie “Home Sweet Home Alone,” a reimagining of the popular holiday franchise\\r\\n●\\xa0\\xa0 \\xa0An all-new original series of shorts from Walt Disney Animation Studios called “Olaf Presents,” which sees Frozen's beloved snowman retelling several classic Disney tales as only he can\\xa0\\r\\n●\\xa0\\xa0 \\xa0An animated short film “Ciao Alberto” from Pixar, featuring characters from this summer's animated hit breakout film “Luca”\\xa0\\r\\n●\\xa0\\xa0 \\xa0A new short from The Simpsons that pays tribute to Disney+'s marquee brands\\r\\n●\\xa0\\xa0 \\xa0The first five episodes from season 2 of “The World According to Jeff Goldblum” from National Geographic\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the origins and legacy of Star Wars’ legendary bounty hunter, Boba Fett\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the Marvel Cinematic Universe on Disney+ with an exciting look towards the future\\r\\n●\\xa0\\xa0 \\xa0“Dopesick,” an original series starring Michael Keaton, which will be released in international markets as part of the Star general entertainment content offering\"}), Match({'ruleId': 'WHITESPACE_RULE', 'message': 'Possible typo: you repeated a whitespace', 'replacements': ['\\xa0'], 'offsetInContext': 43, 'context': '...h an exciting look towards the future\\r ●\\xa0\\xa0 \\xa0“Dopesick,” an original series starring ...', 'offset': 1024, 'errorLength': 4, 'category': 'TYPOGRAPHY', 'ruleIssueType': 'whitespace', 'sentence': \"●\\xa0\\xa0 \\xa0The streaming premiere of Marvel Studios’ “Shang-Chi and The Legend of The Ten Rings”\\xa0\\r\\n●\\xa0\\xa0 \\xa0The Disney family-friendly adventure film “Jungle Cruise,” available to all subscribers\\r\\n●\\xa0\\xa0 \\xa0The new Disney+ Original movie “Home Sweet Home Alone,” a reimagining of the popular holiday franchise\\r\\n●\\xa0\\xa0 \\xa0An all-new original series of shorts from Walt Disney Animation Studios called “Olaf Presents,” which sees Frozen's beloved snowman retelling several classic Disney tales as only he can\\xa0\\r\\n●\\xa0\\xa0 \\xa0An animated short film “Ciao Alberto” from Pixar, featuring characters from this summer's animated hit breakout film “Luca”\\xa0\\r\\n●\\xa0\\xa0 \\xa0A new short from The Simpsons that pays tribute to Disney+'s marquee brands\\r\\n●\\xa0\\xa0 \\xa0The first five episodes from season 2 of “The World According to Jeff Goldblum” from National Geographic\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the origins and legacy of Star Wars’ legendary bounty hunter, Boba Fett\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the Marvel Cinematic Universe on Disney+ with an exciting look towards the future\\r\\n●\\xa0\\xa0 \\xa0“Dopesick,” an original series starring Michael Keaton, which will be released in international markets as part of the Star general entertainment content offering\"}), Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['Dope sick'], 'offsetInContext': 43, 'context': '...exciting look towards the future\\r ●\\xa0\\xa0 \\xa0“Dopesick,” an original series starring Michael K...', 'offset': 1029, 'errorLength': 8, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': \"●\\xa0\\xa0 \\xa0The streaming premiere of Marvel Studios’ “Shang-Chi and The Legend of The Ten Rings”\\xa0\\r\\n●\\xa0\\xa0 \\xa0The Disney family-friendly adventure film “Jungle Cruise,” available to all subscribers\\r\\n●\\xa0\\xa0 \\xa0The new Disney+ Original movie “Home Sweet Home Alone,” a reimagining of the popular holiday franchise\\r\\n●\\xa0\\xa0 \\xa0An all-new original series of shorts from Walt Disney Animation Studios called “Olaf Presents,” which sees Frozen's beloved snowman retelling several classic Disney tales as only he can\\xa0\\r\\n●\\xa0\\xa0 \\xa0An animated short film “Ciao Alberto” from Pixar, featuring characters from this summer's animated hit breakout film “Luca”\\xa0\\r\\n●\\xa0\\xa0 \\xa0A new short from The Simpsons that pays tribute to Disney+'s marquee brands\\r\\n●\\xa0\\xa0 \\xa0The first five episodes from season 2 of “The World According to Jeff Goldblum” from National Geographic\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the origins and legacy of Star Wars’ legendary bounty hunter, Boba Fett\\r\\n●\\xa0\\xa0 \\xa0A special celebrating the Marvel Cinematic Universe on Disney+ with an exciting look towards the future\\r\\n●\\xa0\\xa0 \\xa0“Dopesick,” an original series starring Michael Keaton, which will be released in international markets as part of the Star general entertainment content offering\"})]\n"
     ]
    }
   ],
   "source": [
    "matches_hwz = []\n",
    "for sent in hwz_text1:\n",
    "    matches_hwz += tool.check(sent)\n",
    "print(matches_hwz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "4fce1623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake. ‘defence’ is British English.', 'replacements': ['defense'], 'offsetInContext': 43, 'context': '...ster during a signing ceremony of a new defence deal at The Elysee Palace in Paris, Fra...', 'offset': 119, 'errorLength': 7, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'French President Emmanuel Macron gives a press conference with Greek Prime Minister during a signing ceremony of a new defence deal at The Elysee Palace in Paris, France September 28, 2021.'}), Match({'ruleId': 'EN_DIACRITICS_REPLACE', 'message': '‘Elysee’ is an imported foreign expression, which originally has a diacritic. Consider using “Élysée”', 'replacements': ['Élysée'], 'offsetInContext': 43, 'context': '...g ceremony of a new defence deal at The Elysee Palace in Paris, France September 28, 2...', 'offset': 139, 'errorLength': 6, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'French President Emmanuel Macron gives a press conference with Greek Prime Minister during a signing ceremony of a new defence deal at The Elysee Palace in Paris, France September 28, 2021.'}), Match({'ruleId': 'EN_COMPOUNDS', 'message': 'This word is normally spelled with a hyphen.', 'replacements': ['soul-searching'], 'offsetInContext': 21, 'context': 'That has caused much soul searching in Paris over its traditional alliances...', 'offset': 21, 'errorLength': 14, 'category': 'MISC', 'ruleIssueType': 'misspelling', 'sentence': 'That has caused much soul searching in Paris over its traditional alliances.'}), Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': [], 'offsetInContext': 43, 'context': '...ean autonomy as Washington increasingly reorientates its interests towards China and the Ind...', 'offset': 145, 'errorLength': 12, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'Speaking for the first time on the issue, Macron on Tuesday seized the opportunity to urge for more European autonomy as Washington increasingly reorientates its interests towards China and the Indo-Pacific.'}), Match({'ruleId': 'EN_UNPAIRED_BRACKETS', 'message': 'Unpaired symbol: ‘\"’ seems to be missing', 'replacements': [], 'offsetInContext': 0, 'context': '\"The Europeans must stop being naive.', 'offset': 0, 'errorLength': 1, 'category': 'PUNCTUATION', 'ruleIssueType': 'typographical', 'sentence': '\"The Europeans must stop being naive.'}), Match({'ruleId': 'COMMA_PARENTHESIS_WHITESPACE', 'message': 'Put a space after the comma, but not before the comma.', 'replacements': [','], 'offsetInContext': 43, 'context': '...rs, which at times harden (their stance) , we need to react and show that we have ...', 'offset': 76, 'errorLength': 2, 'category': 'TYPOGRAPHY', 'ruleIssueType': 'whitespace', 'sentence': 'When we are under pressure from powers, which at times harden (their stance) , we need to react and show that we have the power and capacity to defend ourselves.'}), Match({'ruleId': 'EN_UNPAIRED_BRACKETS', 'message': 'Unpaired symbol: ‘\"’ seems to be missing', 'replacements': [], 'offsetInContext': 43, 'context': '...lating things, but protecting ourselves,\" Macron told a news conference with Gree...', 'offset': 48, 'errorLength': 1, 'category': 'PUNCTUATION', 'ruleIssueType': 'typographical', 'sentence': 'Not escalating things, but protecting ourselves,\" Macron told a news conference with Greek Prime Minister Kyriakos Mitsotakis.'}), Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['Mistakes'], 'offsetInContext': 43, 'context': '...ence with Greek Prime Minister Kyriakos Mitsotakis.', 'offset': 115, 'errorLength': 10, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'Not escalating things, but protecting ourselves,\" Macron told a news conference with Greek Prime Minister Kyriakos Mitsotakis.'}), Match({'ruleId': 'EN_UNPAIRED_BRACKETS', 'message': 'Unpaired symbol: ‘\"’ seems to be missing', 'replacements': [], 'offsetInContext': 0, 'context': '\"This isn\\'t an alternative to the United ...', 'offset': 0, 'errorLength': 1, 'category': 'PUNCTUATION', 'ruleIssueType': 'typographical', 'sentence': '\"This isn\\'t an alternative to the United States alliance.'}), Match({'ruleId': 'EN_UNPAIRED_BRACKETS', 'message': 'Unpaired symbol: ‘\"’ seems to be missing', 'replacements': [], 'offsetInContext': 43, 'context': '...sked to take care of our own protection.\"', 'offset': 165, 'errorLength': 1, 'category': 'PUNCTUATION', 'ruleIssueType': 'typographical', 'sentence': 'It\\'s not a substitution, but to take responsibility of the European pillar within NATO and draw the conclusions that we are asked to take care of our own protection.\"'}), Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake. ‘defence’ is British English.', 'replacements': ['defense'], 'offsetInContext': 43, 'context': '...art of a broader strategic military and defence cooperation pact, comes after Athens ha...', 'offset': 53, 'errorLength': 7, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'The accord, part of a broader strategic military and defence cooperation pact, comes after Athens had already ordered around 24 Dassault-made Rafale fighter jets this year, making it the first European Union country to buy the fighter jet.'}), Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': [], 'offsetInContext': 43, 'context': '...er Athens had already ordered around 24 Dassault-made Rafale fighter jets this year, making i...', 'offset': 128, 'errorLength': 13, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'The accord, part of a broader strategic military and defence cooperation pact, comes after Athens had already ordered around 24 Dassault-made Rafale fighter jets this year, making it the first European Union country to buy the fighter jet.'}), Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['Rafael', 'Raphael', 'Raffle'], 'offsetInContext': 43, 'context': '...already ordered around 24 Dassault-made Rafale fighter jets this year, making it the f...', 'offset': 142, 'errorLength': 6, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'The accord, part of a broader strategic military and defence cooperation pact, comes after Athens had already ordered around 24 Dassault-made Rafale fighter jets this year, making it the first European Union country to buy the fighter jet.'}), Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'message': 'Possible spelling mistake found.', 'replacements': ['Mistakes'], 'offsetInContext': 32, 'context': '\"This will tie us for decades,\" Mitsotakis said.', 'offset': 32, 'errorLength': 10, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': '\"This will tie us for decades,\" Mitsotakis said.'})]\n"
     ]
    }
   ],
   "source": [
    "matches_cna = []\n",
    "for sent in cna_text1:\n",
    "    matches_cna += tool.check(sent)\n",
    "print(matches_cna)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ed9a0a",
   "metadata": {},
   "source": [
    "# Formality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6febd1cd",
   "metadata": {},
   "source": [
    "#### No of second-person pronoun 'you'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "22bd4b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "count = 0 \n",
    "for sent in sof_text1:\n",
    "    if 'you' in sent:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "b0e574cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "count = 0 \n",
    "for sent in sof_text2:\n",
    "    if 'you' in sent:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "ed2d51da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "count = 0 \n",
    "for sent in hwz_text1:\n",
    "    if 'you' in sent:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "e1f62158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "count = 0 \n",
    "for sent in hwz_text2:\n",
    "    if 'you' in sent:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "96d9039a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0 \n",
    "for sent in cna_text1:\n",
    "    if 'you' in sent:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "aa427589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0 \n",
    "for sent in cna_text2:\n",
    "    if 'you' in sent:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad165d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99a2fd79",
   "metadata": {},
   "source": [
    "# So i learnt that this way is not good. i will attempt to try with spacy dependency tracker and then combine with nltk pos tagger to check if there is SVA. thx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f2f2ac",
   "metadata": {},
   "source": [
    "# this is what i will do\n",
    "# 3. continue with the two parts for checking for good grammar (any more ideas?)\n",
    "# 4. think n implement more things to analyse for writing style\n",
    "# Formality vs informality: ??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce88a64c",
   "metadata": {},
   "source": [
    "Findings:\n",
    "1. Length of articles\n",
    "    - SOF consistently the shortest, HWZ and CNA are higher by a big margin (+30 sentences on avg)\n",
    "2. Proper nouns\n",
    "    - SOF has the lowest counts of capitalisation for proper nouns (expected)\n",
    "3. Kind of proper nouns used \n",
    "    - SOF always uses language from programming/coding domain\n",
    "    - HWZ always writes about either telco/pop culture (movies?)\n",
    "    - CNA \n",
    "4. Length of sentences (CHECK THIS!!)\n",
    "    - SOF always has the shortest sentences\n",
    "    - HWZ and CNA has much longer sentences (approx 100 words)\n",
    "5. Counts of extremely short sentences\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12db430e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be770b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368396ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6497e31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8844bad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1306b16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22e7b82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb774e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478a0885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d002c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69569999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c88bb79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b40b7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79ba06d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
