{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "source": [
    "# Import the libraries needed\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import matplotlib as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd\n",
    "import random\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.lang.en import English\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import requests\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "reviews = pd.read_json('reviewSelected100.json', encoding='ISO-8859-1', lines=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Dataset Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tokenisation and Stemming"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "# get reviews for a random business \n",
    "random_business = reviews.sample()\n",
    "random_business_id = random_business.iloc[0]['business_id']\n",
    "small_business_dataset = reviews.loc[reviews['business_id'] == random_business_id]\n",
    "small_business_dataset.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4900</th>\n",
       "      <td>1iXjODJauqgG2K5hy0jj3Q</td>\n",
       "      <td>LF8CqQMpHcKyJffiNtKhcg</td>\n",
       "      <td>JqBtQ1bSynPHE9gbyuSSvA</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Awesome in every almost ever way! What more ca...</td>\n",
       "      <td>2018-10-04 16:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4911</th>\n",
       "      <td>mGg7rywlyN6wFrWxZpCoUw</td>\n",
       "      <td>_4NHePAXLhcloTD04wqpqw</td>\n",
       "      <td>JqBtQ1bSynPHE9gbyuSSvA</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>After reading some previous reviews I came to ...</td>\n",
       "      <td>2013-08-03 19:33:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4917</th>\n",
       "      <td>HCY5_XWWIg1AUs_HuGltdg</td>\n",
       "      <td>LWwch5matbl2UsFoqUZB5Q</td>\n",
       "      <td>JqBtQ1bSynPHE9gbyuSSvA</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>This is a great place to go with family and fr...</td>\n",
       "      <td>2018-04-04 01:03:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4922</th>\n",
       "      <td>tR8CYR6wAf_OvQefJlhXlQ</td>\n",
       "      <td>ZPX9nTtPnNavNEeb9igzkg</td>\n",
       "      <td>JqBtQ1bSynPHE9gbyuSSvA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BEWARE : FOOD POISONING \\n\\n\\n\\n\\nI went here ...</td>\n",
       "      <td>2017-08-16 15:32:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4924</th>\n",
       "      <td>iiuh_crm3osGIA9uwikPjA</td>\n",
       "      <td>hybVA6EEvtou0CayV4M1fQ</td>\n",
       "      <td>JqBtQ1bSynPHE9gbyuSSvA</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fun for the family and they actually make pret...</td>\n",
       "      <td>2017-07-08 18:43:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   review_id                 user_id             business_id  \\\n",
       "4900  1iXjODJauqgG2K5hy0jj3Q  LF8CqQMpHcKyJffiNtKhcg  JqBtQ1bSynPHE9gbyuSSvA   \n",
       "4911  mGg7rywlyN6wFrWxZpCoUw  _4NHePAXLhcloTD04wqpqw  JqBtQ1bSynPHE9gbyuSSvA   \n",
       "4917  HCY5_XWWIg1AUs_HuGltdg  LWwch5matbl2UsFoqUZB5Q  JqBtQ1bSynPHE9gbyuSSvA   \n",
       "4922  tR8CYR6wAf_OvQefJlhXlQ  ZPX9nTtPnNavNEeb9igzkg  JqBtQ1bSynPHE9gbyuSSvA   \n",
       "4924  iiuh_crm3osGIA9uwikPjA  hybVA6EEvtou0CayV4M1fQ  JqBtQ1bSynPHE9gbyuSSvA   \n",
       "\n",
       "      stars  useful  funny  cool  \\\n",
       "4900      5       0      0     0   \n",
       "4911      4       4      3     3   \n",
       "4917      4       1      0     1   \n",
       "4922      1       1      0     0   \n",
       "4924      3       0      0     0   \n",
       "\n",
       "                                                   text                date  \n",
       "4900  Awesome in every almost ever way! What more ca... 2018-10-04 16:50:00  \n",
       "4911  After reading some previous reviews I came to ... 2013-08-03 19:33:36  \n",
       "4917  This is a great place to go with family and fr... 2018-04-04 01:03:01  \n",
       "4922  BEWARE : FOOD POISONING \\n\\n\\n\\n\\nI went here ... 2017-08-16 15:32:04  \n",
       "4924  Fun for the family and they actually make pret... 2017-07-08 18:43:43  "
      ]
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "small_business_dataset_reviews = list(small_business_dataset['text'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "# convert the reviews into a concatenated string \n",
    "b1_review = ''.join(small_business_dataset_reviews)\n",
    "clean_review = re.sub(r\"[^A-Za-z0-9\\s]+\", \"\", b1_review)\n",
    "b1_review = nlp(clean_review)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "# removed punctuation and get the top 10 most common words (including stopwords)\n",
    "b1_review_words = [token.text for token in b1_review if token.is_alpha == True] \n",
    "b1_word_freq = Counter(b1_review_words)\n",
    "common_words = b1_word_freq.most_common(10)\n",
    "print(common_words)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('the', 495), ('and', 360), ('a', 347), ('I', 283), ('to', 230), ('was', 221), ('of', 176), ('is', 154), ('for', 144), ('The', 139)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "# removed punctuation and get the top 10 most common words (excluding stopwords)\n",
    "b1_review_words = [token.text for token in b1_review if token.is_stop != True and token.is_alpha == True] \n",
    "b1_word_freq = Counter(b1_review_words)\n",
    "common_words = b1_word_freq.most_common(10)\n",
    "print(common_words)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('burger', 106), ('nt', 91), ('food', 71), ('good', 70), ('place', 69), ('fries', 61), ('burgers', 54), ('cheese', 45), ('like', 42), ('time', 34)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "# log graph before stemming\n",
    "\n",
    "df = pd.DataFrame(b1_word_freq.items(), columns=['word', 'count'])\n",
    "df = df.sort_values(by=['count'], ascending=False)\n",
    "\n",
    "ticks = [1, 10, 100]\n",
    "figure = sns.barplot(data=df, x='word', y='count', color='orange')\n",
    "figure.set_yscale(\"log\") \n",
    "figure.set_yticks(ticks)\n",
    "figure.set_yticklabels(ticks)\n",
    "figure.set_xticks([])\n",
    "figure.set_xticklabels([])\n",
    "figure.set_xlabel('Words')\n",
    "figure.set_title(\"Distribution of Word Counts Before Stemming (log scale)\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "# now we do some stemming after removing the stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "porter_st = PorterStemmer()\n",
    "lancaster_st = LancasterStemmer()\n",
    "snow_st = SnowballStemmer(\"english\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "# Using Porter Stemmer\n",
    "porter_stemmed_words = [porter_st.stem(word) for word in b1_review_words]\n",
    "porter_freq = Counter(porter_stemmed_words)\n",
    "porter_common = porter_freq.most_common(10)\n",
    "print(porter_common)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('burger', 183), ('nt', 91), ('food', 79), ('place', 74), ('good', 74), ('fri', 68), ('chees', 55), ('order', 49), ('like', 49), ('time', 45)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# log graph after stemming (porter stemmer)\n",
    "\n",
    "df = pd.DataFrame(porter_freq.items(), columns=['word', 'count'])\n",
    "df = df.sort_values(by=['count'], ascending=False)\n",
    "\n",
    "ticks = [1, 10, 100]\n",
    "figure = sns.barplot(data=df, x='word', y='count', color='orange')\n",
    "figure.set_yscale(\"log\") \n",
    "figure.set_yticks(ticks)\n",
    "figure.set_yticklabels(ticks)\n",
    "figure.set_xticks([])\n",
    "figure.set_xticklabels([])\n",
    "figure.set_xlabel('Words')\n",
    "figure.set_title(\"Distribution of Word Counts After Stemming (log scale)\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "# Using Lancaster Stemmer\n",
    "lancaster_stemmed_words = [lancaster_st.stem(word) for word in b1_review_words]\n",
    "lancaster_freq = Counter(lancaster_stemmed_words)\n",
    "lancaster_common = lancaster_freq.most_common(10)\n",
    "print(lancaster_common)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('burg', 183), ('nt', 91), ('food', 80), ('plac', 74), ('good', 74), ('fri', 67), ('serv', 56), ('chees', 55), ('ord', 49), ('lik', 49)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "# Using Snowball Stemmer\n",
    "snow_stemmed_words = [snow_st.stem(word) for word in b1_review_words]\n",
    "snow_freq = Counter(snow_stemmed_words)\n",
    "snow_common = snow_freq.most_common(10)\n",
    "print(snow_common)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('burger', 183), ('nt', 91), ('food', 79), ('place', 74), ('good', 74), ('fri', 68), ('chees', 55), ('order', 49), ('like', 49), ('time', 45)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### POS Tagging"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "random_sentences = reviews.sample(5, random_state=42)\n",
    "random_sentences = list(random_sentences['text'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "random_sentences[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"Que ce soit pour leurs délicieux bubbles tea/smooties, leurs ''Bánh mì'' , leurs petits snacks (viennoiseries, tapioca, ...), on adore Vua et aussi leurs prix très abordables. On y retourne lorsqu'on est dans le Quartier Latin !\""
      ]
     },
     "metadata": {},
     "execution_count": 128
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "nltk_tagged = []\n",
    "for sentence in random_sentences:\n",
    "    nltk_tagged.append((nltk.pos_tag(word_tokenize.tokenize(sentence))))\n",
    "nltk_tagged"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[('Que', 'NNP'),\n",
       "  ('ce', 'NN'),\n",
       "  ('soit', 'VBD'),\n",
       "  ('pour', 'JJ'),\n",
       "  ('leurs', 'NNS'),\n",
       "  ('délicieux', 'VBP'),\n",
       "  ('bubbles', 'NNS'),\n",
       "  ('tea', 'JJ'),\n",
       "  ('smooties', 'NNS'),\n",
       "  ('leurs', 'VBP'),\n",
       "  ('Bánh', 'NNP'),\n",
       "  ('mì', 'NN'),\n",
       "  ('leurs', 'VBZ'),\n",
       "  ('petits', 'NNS'),\n",
       "  ('snacks', 'NNS'),\n",
       "  ('viennoiseries', 'NNS'),\n",
       "  ('tapioca', 'VBP'),\n",
       "  ('on', 'IN'),\n",
       "  ('adore', 'NN'),\n",
       "  ('Vua', 'NNP'),\n",
       "  ('et', 'CC'),\n",
       "  ('aussi', 'JJ'),\n",
       "  ('leurs', 'NNS'),\n",
       "  ('prix', 'VBP'),\n",
       "  ('très', 'JJ'),\n",
       "  ('abordables', 'NNS'),\n",
       "  ('On', 'IN'),\n",
       "  ('y', 'NN'),\n",
       "  ('retourne', 'NN'),\n",
       "  ('lorsqu', 'NN'),\n",
       "  ('on', 'IN'),\n",
       "  ('est', 'JJS'),\n",
       "  ('dans', 'NNS'),\n",
       "  ('le', 'VBP'),\n",
       "  ('Quartier', 'NNP'),\n",
       "  ('Latin', 'NNP')],\n",
       " [('As', 'IN'),\n",
       "  ('I', 'PRP'),\n",
       "  ('ve', 'VBP'),\n",
       "  ('said', 'VBD'),\n",
       "  ('previously', 'RB'),\n",
       "  ('we', 'PRP'),\n",
       "  ('ve', 'VBP'),\n",
       "  ('been', 'VBN'),\n",
       "  ('coming', 'VBG'),\n",
       "  ('to', 'TO'),\n",
       "  ('LMAH', 'NNP'),\n",
       "  ('for', 'IN'),\n",
       "  ('over', 'IN'),\n",
       "  ('10', 'CD'),\n",
       "  ('years', 'NNS'),\n",
       "  ('At', 'IN'),\n",
       "  ('least', 'JJS'),\n",
       "  ('15', 'CD'),\n",
       "  ('And', 'CC'),\n",
       "  ('we', 'PRP'),\n",
       "  ('ve', 'VBP'),\n",
       "  ('ALWAYS', 'NNP'),\n",
       "  ('seen', 'VBN'),\n",
       "  ('Dr', 'NNP'),\n",
       "  ('White', 'NNP'),\n",
       "  ('I', 'PRP'),\n",
       "  ('had', 'VBD'),\n",
       "  ('to', 'TO'),\n",
       "  ('bring', 'VB'),\n",
       "  ('my', 'PRP$'),\n",
       "  ('cat', 'NN'),\n",
       "  ('in', 'IN'),\n",
       "  ('to', 'TO'),\n",
       "  ('have', 'VB'),\n",
       "  ('a', 'DT'),\n",
       "  ('urine', 'JJ'),\n",
       "  ('sample', 'NN'),\n",
       "  ('done', 'VBN'),\n",
       "  ('While', 'IN'),\n",
       "  ('being', 'VBG'),\n",
       "  ('done', 'VBN'),\n",
       "  ('my', 'PRP$'),\n",
       "  ('cat', 'NN'),\n",
       "  ('pee', 'NN'),\n",
       "  ('d', 'NN'),\n",
       "  ('on', 'IN'),\n",
       "  ('himself', 'PRP'),\n",
       "  ('The', 'DT'),\n",
       "  ('vet', 'NN'),\n",
       "  ('or', 'CC'),\n",
       "  ('staff', 'NN'),\n",
       "  ('only', 'RB'),\n",
       "  ('tried', 'VBD'),\n",
       "  ('to', 'TO'),\n",
       "  ('clean', 'VB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('off', 'IN'),\n",
       "  ('of', 'IN'),\n",
       "  ('him', 'PRP'),\n",
       "  ('with', 'IN'),\n",
       "  ('alcohol', 'NN'),\n",
       "  ('They', 'PRP'),\n",
       "  ('didn', 'VBP'),\n",
       "  ('t', 'JJ'),\n",
       "  ('try', 'NN'),\n",
       "  ('to', 'TO'),\n",
       "  ('actually', 'RB'),\n",
       "  ('get', 'VB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('off', 'IN'),\n",
       "  ('of', 'IN'),\n",
       "  ('him', 'PRP'),\n",
       "  ('They', 'PRP'),\n",
       "  ('didn', 'VBP'),\n",
       "  ('t', 'JJ'),\n",
       "  ('even', 'RB'),\n",
       "  ('TELL', 'VBP'),\n",
       "  ('ME', 'NNP'),\n",
       "  ('that', 'IN'),\n",
       "  ('he', 'PRP'),\n",
       "  ('pee', 'VBZ'),\n",
       "  ('d', 'RB'),\n",
       "  ('all', 'DT'),\n",
       "  ('over', 'IN'),\n",
       "  ('his', 'PRP$'),\n",
       "  ('stomach', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('legs', 'NNS'),\n",
       "  ('So', 'RB'),\n",
       "  ('now', 'RB'),\n",
       "  ('I', 'PRP'),\n",
       "  ('e', 'VBP'),\n",
       "  ('had', 'VBD'),\n",
       "  ('to', 'TO'),\n",
       "  ('give', 'VB'),\n",
       "  ('my', 'PRP$'),\n",
       "  ('cat', 'NN'),\n",
       "  ('a', 'DT'),\n",
       "  ('bath', 'NN'),\n",
       "  ('because', 'IN'),\n",
       "  ('they', 'PRP'),\n",
       "  ('can', 'MD'),\n",
       "  ('t', 'VB'),\n",
       "  ('take', 'VB'),\n",
       "  ('a', 'DT'),\n",
       "  ('urine', 'JJ'),\n",
       "  ('sample', 'NN'),\n",
       "  ('properly', 'RB'),\n",
       "  ('I', 'PRP'),\n",
       "  ('am', 'VBP'),\n",
       "  ('LIVID', 'JJ')],\n",
       " [('Pretty', 'NNP'),\n",
       "  ('decent', 'NN'),\n",
       "  ('but', 'CC'),\n",
       "  ('so', 'RB'),\n",
       "  ('spacious', 'JJ'),\n",
       "  ('Very', 'RB'),\n",
       "  ('good', 'JJ'),\n",
       "  ('for', 'IN'),\n",
       "  ('kids', 'NNS'),\n",
       "  ('and', 'CC'),\n",
       "  ('you', 'PRP'),\n",
       "  ('can', 'MD'),\n",
       "  ('order', 'NN'),\n",
       "  ('dim', 'VB'),\n",
       "  ('sum', 'NN'),\n",
       "  ('They', 'PRP'),\n",
       "  ('re', 'VBP'),\n",
       "  ('open', 'JJ'),\n",
       "  ('Free', 'NNP'),\n",
       "  ('wifi', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('awesome', 'VB')],\n",
       " [('Dumpling', 'VBG'),\n",
       "  ('Village', 'NNP'),\n",
       "  ('really', 'RB'),\n",
       "  ('suffering', 'VBG'),\n",
       "  ('from', 'IN'),\n",
       "  ('identity', 'NN'),\n",
       "  ('crisis', 'NN'),\n",
       "  ('Is', 'VBZ'),\n",
       "  ('it', 'PRP'),\n",
       "  ('a', 'DT'),\n",
       "  ('Korean', 'JJ'),\n",
       "  ('Restaurant', 'NNP'),\n",
       "  ('not', 'RB'),\n",
       "  ('really', 'RB'),\n",
       "  ('There', 'EX'),\n",
       "  ('are', 'VBP'),\n",
       "  ('mostly', 'RB'),\n",
       "  ('Northern', 'NNP'),\n",
       "  ('Chinese', 'NNP'),\n",
       "  ('items', 'NNS'),\n",
       "  ('on', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('menu', 'NN'),\n",
       "  ('like', 'IN'),\n",
       "  ('dumplings', 'NNS'),\n",
       "  ('Is', 'VBZ'),\n",
       "  ('it', 'PRP'),\n",
       "  ('a', 'DT'),\n",
       "  ('Northern', 'NNP'),\n",
       "  ('Chinese', 'NNP'),\n",
       "  ('restaurant', 'NN'),\n",
       "  ('not', 'RB'),\n",
       "  ('really', 'RB'),\n",
       "  ('There', 'EX'),\n",
       "  ('are', 'VBP'),\n",
       "  ('a', 'DT'),\n",
       "  ('lot', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('Korean', 'JJ'),\n",
       "  ('dishes', 'NNS'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('menu', 'NN'),\n",
       "  ('like', 'IN'),\n",
       "  ('pork', 'NN'),\n",
       "  ('bone', 'NN'),\n",
       "  ('soup', 'NN'),\n",
       "  ('cold', 'VBD'),\n",
       "  ('wheat', 'NN'),\n",
       "  ('bucknoodle', 'NN'),\n",
       "  ('soup', 'NN'),\n",
       "  ('kimchi', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('bean', 'NN'),\n",
       "  ('sprout', 'NN'),\n",
       "  ('as', 'IN'),\n",
       "  ('appetitizers', 'NNS'),\n",
       "  ('The', 'DT'),\n",
       "  ('only', 'JJ'),\n",
       "  ('Korean', 'JJ'),\n",
       "  ('characters', 'NNS'),\n",
       "  ('are', 'VBP'),\n",
       "  ('the', 'DT'),\n",
       "  ('3', 'CD'),\n",
       "  ('on', 'IN'),\n",
       "  ('their', 'PRP$'),\n",
       "  ('business', 'NN'),\n",
       "  ('sign', 'NN'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('front', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('all', 'PDT'),\n",
       "  ('the', 'DT'),\n",
       "  ('rest', 'NN'),\n",
       "  ('are', 'VBP'),\n",
       "  ('in', 'IN'),\n",
       "  ('Chinese', 'NNP'),\n",
       "  ('and', 'CC'),\n",
       "  ('English', 'NNP'),\n",
       "  ('All', 'NNP'),\n",
       "  ('the', 'DT'),\n",
       "  ('wait', 'NN'),\n",
       "  ('staffs', 'NNS'),\n",
       "  ('here', 'RB'),\n",
       "  ('speak', 'VBP'),\n",
       "  ('Mandarian', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('even', 'RB'),\n",
       "  ('most', 'JJS'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('patrons', 'NNS'),\n",
       "  ('are', 'VBP'),\n",
       "  ('Chinese', 'JJ'),\n",
       "  ('It', 'PRP'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('located', 'VBN'),\n",
       "  ('in', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('really', 'RB'),\n",
       "  ('tiny', 'JJ'),\n",
       "  ('strip', 'NN'),\n",
       "  ('mall', 'NN'),\n",
       "  ('with', 'IN'),\n",
       "  ('limited', 'JJ'),\n",
       "  ('parkings', 'NNS'),\n",
       "  ('To', 'TO'),\n",
       "  ('tell', 'VB'),\n",
       "  ('you', 'PRP'),\n",
       "  ('the', 'DT'),\n",
       "  ('truth', 'NN'),\n",
       "  ('I', 'PRP'),\n",
       "  ('am', 'VBP'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('area', 'NN'),\n",
       "  ('for', 'IN'),\n",
       "  ('over', 'IN'),\n",
       "  ('10', 'CD'),\n",
       "  ('years', 'NNS'),\n",
       "  ('I', 'PRP'),\n",
       "  ('never', 'RB'),\n",
       "  ('notice', 'VBP'),\n",
       "  ('it', 'PRP'),\n",
       "  ('until', 'IN'),\n",
       "  ('I', 'PRP'),\n",
       "  ('read', 'VBP'),\n",
       "  ('the', 'DT'),\n",
       "  ('reviews', 'NNS'),\n",
       "  ('on', 'IN'),\n",
       "  ('yelp', 'NN'),\n",
       "  ('We', 'PRP'),\n",
       "  ('arrived', 'VBD'),\n",
       "  ('around', 'RB'),\n",
       "  ('6', 'CD'),\n",
       "  ('pm', 'NN'),\n",
       "  ('on', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('Saturday', 'NNP'),\n",
       "  ('The', 'DT'),\n",
       "  ('restaurant', 'NN'),\n",
       "  ('was', 'VBD'),\n",
       "  ('almost', 'RB'),\n",
       "  ('full', 'JJ'),\n",
       "  ('The', 'DT'),\n",
       "  ('tables', 'NNS'),\n",
       "  ('are', 'VBP'),\n",
       "  ('not', 'RB'),\n",
       "  ('really', 'RB'),\n",
       "  ('packed', 'VBN'),\n",
       "  ('together', 'RB'),\n",
       "  ('so', 'IN'),\n",
       "  ('you', 'PRP'),\n",
       "  ('still', 'RB'),\n",
       "  ('have', 'VBP'),\n",
       "  ('a', 'DT'),\n",
       "  ('certain', 'JJ'),\n",
       "  ('degree', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('privacy', 'NN'),\n",
       "  ('at', 'IN'),\n",
       "  ('least', 'JJS'),\n",
       "  ('I', 'PRP'),\n",
       "  ('cannot', 'VBP'),\n",
       "  ('tell', 'VB'),\n",
       "  ('what', 'WP'),\n",
       "  ('the', 'DT'),\n",
       "  ('table', 'NN'),\n",
       "  ('next', 'JJ'),\n",
       "  ('to', 'TO'),\n",
       "  ('me', 'PRP'),\n",
       "  ('were', 'VBD'),\n",
       "  ('eating', 'VBG'),\n",
       "  ('We', 'PRP'),\n",
       "  ('decided', 'VBD'),\n",
       "  ('on', 'IN'),\n",
       "  ('my', 'PRP$'),\n",
       "  ('favourite', 'JJ'),\n",
       "  ('chives', 'NNS'),\n",
       "  ('and', 'CC'),\n",
       "  ('pork', 'NN'),\n",
       "  ('dumplings', 'NNS'),\n",
       "  ('kimchi', 'VBP'),\n",
       "  ('fried', 'VBN'),\n",
       "  ('rice', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('Korean', 'NNP'),\n",
       "  ('cold', 'VBD'),\n",
       "  ('bucknoodle', 'RP'),\n",
       "  ('soup', 'NN'),\n",
       "  ('They', 'PRP'),\n",
       "  ('are', 'VBP'),\n",
       "  ('all', 'DT'),\n",
       "  ('4', 'CD'),\n",
       "  ('99', 'CD'),\n",
       "  ('The', 'DT'),\n",
       "  ('cold', 'JJ'),\n",
       "  ('noodle', 'JJ'),\n",
       "  ('soup', 'NN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('so', 'RB'),\n",
       "  ('so', 'RB'),\n",
       "  ('good', 'JJ'),\n",
       "  ('Nice', 'NNP'),\n",
       "  ('and', 'CC'),\n",
       "  ('refreshing', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('the', 'DT'),\n",
       "  ('soup', 'NN'),\n",
       "  ('based', 'VBN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('a', 'DT'),\n",
       "  ('little', 'JJ'),\n",
       "  ('sour', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('it', 'PRP'),\n",
       "  ('really', 'RB'),\n",
       "  ('stimulate', 'VB'),\n",
       "  ('your', 'PRP$'),\n",
       "  ('tastebuds', 'NNS'),\n",
       "  ('and', 'CC'),\n",
       "  ('just', 'RB'),\n",
       "  ('make', 'VB'),\n",
       "  ('you', 'PRP'),\n",
       "  ('want', 'VB'),\n",
       "  ('to', 'TO'),\n",
       "  ('eat', 'VB'),\n",
       "  ('more', 'JJR'),\n",
       "  ('I', 'PRP'),\n",
       "  ('can', 'MD'),\n",
       "  ('finish', 'VB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('all', 'DT'),\n",
       "  ('myself', 'PRP'),\n",
       "  ('I', 'PRP'),\n",
       "  ('don', 'VBP'),\n",
       "  ('t', 'JJ'),\n",
       "  ('want', 'VBP'),\n",
       "  ('to', 'TO'),\n",
       "  ('share', 'NN'),\n",
       "  ('I', 'PRP'),\n",
       "  ('want', 'VBP'),\n",
       "  ('one', 'CD'),\n",
       "  ('all', 'DT'),\n",
       "  ('for', 'IN'),\n",
       "  ('myself', 'PRP'),\n",
       "  ('next', 'JJ'),\n",
       "  ('time', 'NN'),\n",
       "  ('The', 'DT'),\n",
       "  ('kimchi', 'NNS'),\n",
       "  ('fried', 'VBD'),\n",
       "  ('rice', 'NN'),\n",
       "  ('hmmmmm', 'NN'),\n",
       "  ('not', 'RB'),\n",
       "  ('good', 'JJ'),\n",
       "  ('A', 'NNP'),\n",
       "  ('little', 'NN'),\n",
       "  ('on', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('oily', 'JJ'),\n",
       "  ('side', 'NN'),\n",
       "  ('There', 'EX'),\n",
       "  ('are', 'VBP'),\n",
       "  ('not', 'RB'),\n",
       "  ('much', 'JJ'),\n",
       "  ('taste', 'NN'),\n",
       "  ('not', 'RB'),\n",
       "  ('spicy', 'RB'),\n",
       "  ('enough', 'IN'),\n",
       "  ('We', 'PRP'),\n",
       "  ('could', 'MD'),\n",
       "  ('not', 'RB'),\n",
       "  ('finish', 'VB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('and', 'CC'),\n",
       "  ('end', 'VB'),\n",
       "  ('up', 'RB'),\n",
       "  ('have', 'VBP'),\n",
       "  ('to', 'TO'),\n",
       "  ('pack', 'VB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('all', 'DT'),\n",
       "  ('to', 'TO'),\n",
       "  ('go', 'VB'),\n",
       "  ('not', 'RB'),\n",
       "  ('even', 'RB'),\n",
       "  ('sure', 'JJ'),\n",
       "  ('I', 'PRP'),\n",
       "  ('will', 'MD'),\n",
       "  ('eat', 'VB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('but', 'CC'),\n",
       "  ('cannot', 'VBZ'),\n",
       "  ('just', 'RB'),\n",
       "  ('let', 'VB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('all', 'DT'),\n",
       "  ('go', 'VBP'),\n",
       "  ('to', 'TO'),\n",
       "  ('waste', 'VB'),\n",
       "  ('The', 'DT'),\n",
       "  ('dumplings', 'NNS'),\n",
       "  ('arrived', 'VBD'),\n",
       "  ('last', 'JJ'),\n",
       "  ('But', 'CC'),\n",
       "  ('it', 'PRP'),\n",
       "  ('really', 'RB'),\n",
       "  ('worth', 'VBZ'),\n",
       "  ('the', 'DT'),\n",
       "  ('wait', 'NN'),\n",
       "  ('14', 'CD'),\n",
       "  ('big', 'JJ'),\n",
       "  ('fat', 'NN'),\n",
       "  ('hot', 'JJ'),\n",
       "  ('dumplings', 'NNS'),\n",
       "  ('filled', 'VBN'),\n",
       "  ('up', 'RP'),\n",
       "  ('the', 'DT'),\n",
       "  ('whole', 'JJ'),\n",
       "  ('steamer', 'NN'),\n",
       "  ('Yes', 'NNP'),\n",
       "  ('I', 'PRP'),\n",
       "  ('counted', 'VBD'),\n",
       "  ('them', 'PRP'),\n",
       "  ('14', 'CD'),\n",
       "  ('of', 'IN'),\n",
       "  ('them', 'PRP'),\n",
       "  ('for', 'IN'),\n",
       "  ('4', 'CD'),\n",
       "  ('99', 'CD'),\n",
       "  ('They', 'PRP'),\n",
       "  ('are', 'VBP'),\n",
       "  ('all', 'DT'),\n",
       "  ('freshly', 'RB'),\n",
       "  ('made', 'VBN'),\n",
       "  ('freshly', 'RB'),\n",
       "  ('steamed', 'VBN'),\n",
       "  ('The', 'DT'),\n",
       "  ('skin', 'NN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('nice', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('thin', 'JJ'),\n",
       "  ('not', 'RB'),\n",
       "  ('chewy', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('thick', 'JJ'),\n",
       "  ('Oh', 'NNP'),\n",
       "  ('so', 'RB'),\n",
       "  ('delicious', 'JJ'),\n",
       "  ('One', 'CD'),\n",
       "  ('bite', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('all', 'PDT'),\n",
       "  ('the', 'DT'),\n",
       "  ('soup', 'NN'),\n",
       "  ('are', 'VBP'),\n",
       "  ('ozzing', 'VBG'),\n",
       "  ('out', 'RP'),\n",
       "  ('But', 'CC'),\n",
       "  ('if', 'IN'),\n",
       "  ('they', 'PRP'),\n",
       "  ('are', 'VBP'),\n",
       "  ('not', 'RB'),\n",
       "  ('burning', 'VBG'),\n",
       "  ('hot', 'JJ'),\n",
       "  ('you', 'PRP'),\n",
       "  ('can', 'MD'),\n",
       "  ('just', 'RB'),\n",
       "  ('stuff', 'VB'),\n",
       "  ('the', 'DT'),\n",
       "  ('whole', 'JJ'),\n",
       "  ('thing', 'NN'),\n",
       "  ('into', 'IN'),\n",
       "  ('your', 'PRP$'),\n",
       "  ('mouth', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('let', 'VB'),\n",
       "  ('the', 'DT'),\n",
       "  ('soup', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('favour', 'NN'),\n",
       "  ('just', 'RB'),\n",
       "  ('explosed', 'VBN'),\n",
       "  ('in', 'IN'),\n",
       "  ('your', 'PRP$'),\n",
       "  ('mouth', 'NN'),\n",
       "  ('Just', 'RB'),\n",
       "  ('a', 'DT'),\n",
       "  ('warning', 'NN'),\n",
       "  ('If', 'IN'),\n",
       "  ('you', 'PRP'),\n",
       "  ('going', 'VBG'),\n",
       "  ('out', 'RP'),\n",
       "  ('on', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('date', 'NN'),\n",
       "  ('please', 'NN'),\n",
       "  ('don', 'VB'),\n",
       "  ('t', 'JJ'),\n",
       "  ('come', 'VBN'),\n",
       "  ('here', 'RB'),\n",
       "  ('Even', 'RB'),\n",
       "  ('it', 'PRP'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('a', 'DT'),\n",
       "  ('good', 'JJ'),\n",
       "  ('place', 'NN'),\n",
       "  ('for', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('cheap', 'JJ'),\n",
       "  ('date', 'NN'),\n",
       "  ('our', 'PRP$'),\n",
       "  ('bill', 'NN'),\n",
       "  ('was', 'VBD'),\n",
       "  ('18', 'CD'),\n",
       "  ('for', 'IN'),\n",
       "  ('2', 'CD'),\n",
       "  ('and', 'CC'),\n",
       "  ('we', 'PRP'),\n",
       "  ('were', 'VBD'),\n",
       "  ('full', 'JJ'),\n",
       "  ('But', 'CC'),\n",
       "  ('the', 'DT'),\n",
       "  ('place', 'NN'),\n",
       "  ('can', 'MD'),\n",
       "  ('be', 'VB'),\n",
       "  ('noisy', 'VBN'),\n",
       "  ('the', 'DT'),\n",
       "  ('food', 'NN'),\n",
       "  ('too', 'RB'),\n",
       "  ('good', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('your', 'PRP$'),\n",
       "  ('date', 'NN'),\n",
       "  ('will', 'MD'),\n",
       "  ('be', 'VB'),\n",
       "  ('too', 'RB'),\n",
       "  ('busy', 'JJ'),\n",
       "  ('eating', 'VBG'),\n",
       "  ('and', 'CC'),\n",
       "  ('just', 'RB'),\n",
       "  ('ignore', 'VB'),\n",
       "  ('you', 'PRP'),\n",
       "  ('Or', 'CC'),\n",
       "  ('you', 'PRP'),\n",
       "  ('will', 'MD'),\n",
       "  ('keep', 'VB'),\n",
       "  ('eating', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('eating', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('you', 'PRP'),\n",
       "  ('freak', 'VBP'),\n",
       "  ('all', 'DT'),\n",
       "  ('your', 'PRP$'),\n",
       "  ('friends', 'NNS'),\n",
       "  ('out', 'RP'),\n",
       "  ('The', 'DT'),\n",
       "  ('services', 'NNS'),\n",
       "  ('here', 'RB'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('cold', 'JJ'),\n",
       "  ('but', 'CC'),\n",
       "  ('efficient', 'JJ'),\n",
       "  ('We', 'PRP'),\n",
       "  ('were', 'VBD'),\n",
       "  ('given', 'VBN'),\n",
       "  ('extra', 'JJ'),\n",
       "  ('napkins', 'NNS'),\n",
       "  ('without', 'IN'),\n",
       "  ('requesting', 'VBG'),\n",
       "  ('Maybe', 'RB'),\n",
       "  ('we', 'PRP'),\n",
       "  ('looked', 'VBD'),\n",
       "  ('really', 'RB'),\n",
       "  ('messy', 'JJ'),\n",
       "  ('Cash', 'NNP'),\n",
       "  ('only', 'RB')],\n",
       " [('best', 'JJS'),\n",
       "  ('pizza', 'NN'),\n",
       "  ('in', 'IN'),\n",
       "  ('south', 'JJ'),\n",
       "  ('side', 'NN'),\n",
       "  ('huge', 'JJ'),\n",
       "  ('drink', 'NN'),\n",
       "  ('selection', 'NN'),\n",
       "  ('awesome', 'VBP'),\n",
       "  ('atmosphere', 'RB'),\n",
       "  ('4', 'CD'),\n",
       "  ('for', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('slice', 'NN'),\n",
       "  ('that', 'WDT'),\n",
       "  ('could', 'MD'),\n",
       "  ('easily', 'RB'),\n",
       "  ('feed', 'VB'),\n",
       "  ('2', 'CD'),\n",
       "  ('people', 'NNS')]]"
      ]
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "spacy_tagged = []\n",
    "for sentence in random_sentences:\n",
    "    spacy_tagged.append(nlp(sentence))\n",
    "for tagged in spacy_tagged:\n",
    "    for token in tagged:\n",
    "        print(f'{token.text:{8}} {token.pos_:{6}}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Que      PROPN \n",
      "ce       PROPN \n",
      "soit     ADJ   \n",
      "pour     NOUN  \n",
      "leurs    VERB  \n",
      "délicieux NOUN  \n",
      "bubbles  NOUN  \n",
      "tea      NOUN  \n",
      "/        SYM   \n",
      "smooties NOUN  \n",
      ",        PUNCT \n",
      "leurs    VERB  \n",
      "''       PUNCT \n",
      "Bánh     PROPN \n",
      "mì       INTJ  \n",
      "''       PUNCT \n",
      ",        PUNCT \n",
      "leurs    NOUN  \n",
      "petits   VERB  \n",
      "snacks   NOUN  \n",
      "(        PUNCT \n",
      "viennoiseries NOUN  \n",
      ",        PUNCT \n",
      "tapioca  INTJ  \n",
      ",        PUNCT \n",
      "...      PUNCT \n",
      ")        PUNCT \n",
      ",        PUNCT \n",
      "on       ADP   \n",
      "adore    PROPN \n",
      "Vua      PROPN \n",
      "et       PROPN \n",
      "aussi    PROPN \n",
      "leurs    VERB  \n",
      "prix     NOUN  \n",
      "très     ADJ   \n",
      "abordables NOUN  \n",
      ".        PUNCT \n",
      "On       ADP   \n",
      "y        PROPN \n",
      "retourne VERB  \n",
      "lorsqu'on PROPN \n",
      "est      PROPN \n",
      "dans     PROPN \n",
      "le       X     \n",
      "Quartier PROPN \n",
      "Latin    PROPN \n",
      "!        PUNCT \n",
      "As       ADP   \n",
      "I        PRON  \n",
      "'ve      AUX   \n",
      "said     VERB  \n",
      "previously ADV   \n",
      "...      PUNCT \n",
      "we've    PROPN \n",
      "been     AUX   \n",
      "coming   VERB  \n",
      "to       ADP   \n",
      "LMAH     PROPN \n",
      "for      ADP   \n",
      "over     ADP   \n",
      "10       NUM   \n",
      "years    NOUN  \n",
      ".        PUNCT \n",
      "At       ADV   \n",
      "least    ADJ   \n",
      "15       NUM   \n",
      ".        PUNCT \n",
      "And      CCONJ \n",
      "we       PRON  \n",
      "'ve      AUX   \n",
      "ALWAYS   ADV   \n",
      "seen     VERB  \n",
      "Dr.      PROPN \n",
      "White    PROPN \n",
      ".        PUNCT \n",
      "\n",
      "        SPACE \n",
      "I        PRON  \n",
      "had      VERB  \n",
      "to       PART  \n",
      "bring    VERB  \n",
      "my       PRON  \n",
      "cat      NOUN  \n",
      "in       ADP   \n",
      "to       PART  \n",
      "have     VERB  \n",
      "a        DET   \n",
      "urine    NOUN  \n",
      "sample   NOUN  \n",
      "done     VERB  \n",
      ".        PUNCT \n",
      "While    SCONJ \n",
      "being    AUX   \n",
      "done     VERB  \n",
      ",        PUNCT \n",
      "my       PRON  \n",
      "cat      NOUN  \n",
      "pee'd    ADV   \n",
      "on       ADP   \n",
      "himself  PRON  \n",
      ".        PUNCT \n",
      "The      DET   \n",
      "vet      NOUN  \n",
      "or       CCONJ \n",
      "staff    NOUN  \n",
      "only     ADV   \n",
      "tried    VERB  \n",
      "to       PART  \n",
      "clean    VERB  \n",
      "it       PRON  \n",
      "off      ADP   \n",
      "of       ADP   \n",
      "him      PRON  \n",
      "with     ADP   \n",
      "alcohol  NOUN  \n",
      ".        PUNCT \n",
      "They     PRON  \n",
      "did      AUX   \n",
      "n't      PART  \n",
      "try      VERB  \n",
      "to       PART  \n",
      "actually ADV   \n",
      "get      VERB  \n",
      "it       PRON  \n",
      "off      ADP   \n",
      "of       ADP   \n",
      "him      PRON  \n",
      ".        PUNCT \n",
      "They     PRON  \n",
      "did      AUX   \n",
      "n't      PART  \n",
      "even     ADV   \n",
      "TELL     VERB  \n",
      "ME       PRON  \n",
      "that     SCONJ \n",
      "he       PRON  \n",
      "pee'd    VERB  \n",
      "all      ADV   \n",
      "over     ADP   \n",
      "his      PRON  \n",
      "stomach  NOUN  \n",
      "and      CCONJ \n",
      "legs     NOUN  \n",
      ".        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "So       ADV   \n",
      "now      ADV   \n",
      "I        PRON  \n",
      "e        VERB  \n",
      "had      VERB  \n",
      "to       PART  \n",
      "give     VERB  \n",
      "my       PRON  \n",
      "cat      NOUN  \n",
      "a        DET   \n",
      "bath     NOUN  \n",
      "because  SCONJ \n",
      "they     PRON  \n",
      "ca       AUX   \n",
      "n't      PART  \n",
      "take     VERB  \n",
      "a        DET   \n",
      "urine    NOUN  \n",
      "sample   NOUN  \n",
      "properly ADV   \n",
      ".        PUNCT \n",
      "I        PRON  \n",
      "am       AUX   \n",
      "LIVID    PROPN \n",
      ".        PUNCT \n",
      "Pretty   ADV   \n",
      "decent   ADJ   \n",
      "but      CCONJ \n",
      "so       ADV   \n",
      "spacious ADJ   \n",
      "!        PUNCT \n",
      "         SPACE \n",
      "Very     ADV   \n",
      "good     ADJ   \n",
      "for      ADP   \n",
      "kids     NOUN  \n",
      "and      CCONJ \n",
      "you      PRON  \n",
      "can      AUX   \n",
      "order    VERB  \n",
      "dim      NOUN  \n",
      "sum      NOUN  \n",
      "!        PUNCT \n",
      "They     PRON  \n",
      "'re      VERB  \n",
      "open     ADJ   \n",
      "!        PUNCT \n",
      "!        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "Free     ADJ   \n",
      "wifi     NOUN  \n",
      "and      CCONJ \n",
      "awesome  ADJ   \n",
      ":)       PUNCT \n",
      "Dumpling PROPN \n",
      "Village  PROPN \n",
      "really   ADV   \n",
      "suffering VERB  \n",
      "from     ADP   \n",
      "identity NOUN  \n",
      "crisis   NOUN  \n",
      "!        PUNCT \n",
      "!        PUNCT \n",
      "Is       AUX   \n",
      "it       PRON  \n",
      "a        DET   \n",
      "Korean   PROPN \n",
      "Restaurant PROPN \n",
      ",        PUNCT \n",
      "not      PART  \n",
      "really   ADV   \n",
      ".        PUNCT \n",
      "There    PRON  \n",
      "are      AUX   \n",
      "mostly   ADV   \n",
      "Northern ADJ   \n",
      "Chinese  ADJ   \n",
      "items    NOUN  \n",
      "on       ADP   \n",
      "the      DET   \n",
      "menu     NOUN  \n",
      "like     ADP   \n",
      "dumplings NOUN  \n",
      ".        PUNCT \n",
      "Is       AUX   \n",
      "it       PRON  \n",
      "a        DET   \n",
      "Northern ADJ   \n",
      "Chinese  ADJ   \n",
      "restaurant NOUN  \n",
      ",        PUNCT \n",
      "not      PART  \n",
      "really   ADV   \n",
      "There    PRON  \n",
      "are      AUX   \n",
      "a        DET   \n",
      "lot      NOUN  \n",
      "of       ADP   \n",
      "Korean   ADJ   \n",
      "dishes   NOUN  \n",
      "         SPACE \n",
      "in       ADP   \n",
      "the      DET   \n",
      "menu     NOUN  \n",
      "like     ADP   \n",
      "pork     NOUN  \n",
      "bone     NOUN  \n",
      "soup     NOUN  \n",
      ",        PUNCT \n",
      "cold     ADJ   \n",
      "wheat    NOUN  \n",
      "bucknoodle NOUN  \n",
      "soup     NOUN  \n",
      ",        PUNCT \n",
      "kimchi   PROPN \n",
      "and      CCONJ \n",
      "bean     NOUN  \n",
      "sprout   NOUN  \n",
      "as       ADP   \n",
      "appetitizers NOUN  \n",
      ".        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "The      DET   \n",
      "only     ADJ   \n",
      "Korean   ADJ   \n",
      "characters NOUN  \n",
      "are      AUX   \n",
      "the      DET   \n",
      "3        NUM   \n",
      "on       ADP   \n",
      "their    PRON  \n",
      "business NOUN  \n",
      "sign     NOUN  \n",
      "in       ADP   \n",
      "the      DET   \n",
      "front    NOUN  \n",
      "..       PUNCT \n",
      "and      CCONJ \n",
      "all      DET   \n",
      "the      DET   \n",
      "rest     NOUN  \n",
      "are      VERB  \n",
      "in       ADP   \n",
      "Chinese  PROPN \n",
      "and      CCONJ \n",
      "English  PROPN \n",
      ".        PUNCT \n",
      "All      DET   \n",
      "the      DET   \n",
      "wait     ADJ   \n",
      "staffs   NOUN  \n",
      "here     ADV   \n",
      "speak    VERB  \n",
      "Mandarian PROPN \n",
      "and      CCONJ \n",
      "even     ADV   \n",
      "most     ADJ   \n",
      "of       ADP   \n",
      "the      DET   \n",
      "patrons  NOUN  \n",
      "are      VERB  \n",
      "Chinese  ADJ   \n",
      ".        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "It       PRON  \n",
      "is       AUX   \n",
      "located  VERB  \n",
      "in       ADP   \n",
      "a        DET   \n",
      "really   ADV   \n",
      "tiny     ADJ   \n",
      "strip    NOUN  \n",
      "mall     NOUN  \n",
      "..       PUNCT \n",
      "with     ADP   \n",
      "limited  ADJ   \n",
      "parkings NOUN  \n",
      "!        PUNCT \n",
      "To       PART  \n",
      "tell     VERB  \n",
      "you      PRON  \n",
      "the      DET   \n",
      "truth    NOUN  \n",
      "I        PRON  \n",
      "am       VERB  \n",
      "in       ADP   \n",
      "the      DET   \n",
      "area     NOUN  \n",
      "for      ADP   \n",
      "over     ADP   \n",
      "10       NUM   \n",
      "years    NOUN  \n",
      "I        PRON  \n",
      "never    ADV   \n",
      "notice   VERB  \n",
      "it       PRON  \n",
      "until    ADP   \n",
      "I        PRON  \n",
      "read     VERB  \n",
      "the      DET   \n",
      "reviews  NOUN  \n",
      "on       ADP   \n",
      "yelp     NOUN  \n",
      "!        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "We       PRON  \n",
      "arrived  VERB  \n",
      "around   ADV   \n",
      "6        NUM   \n",
      "pm       NOUN  \n",
      "on       ADP   \n",
      "a        DET   \n",
      "Saturday PROPN \n",
      ".        PUNCT \n",
      "The      DET   \n",
      "restaurant NOUN  \n",
      "was      AUX   \n",
      "almost   ADV   \n",
      "full     ADJ   \n",
      ".        PUNCT \n",
      "         SPACE \n",
      "The      DET   \n",
      "tables   NOUN  \n",
      "are      AUX   \n",
      "not      PART  \n",
      "really   ADV   \n",
      "packed   VERB  \n",
      "together ADV   \n",
      ",        PUNCT \n",
      "so       ADV   \n",
      "you      PRON  \n",
      "still    ADV   \n",
      "have     VERB  \n",
      "a        DET   \n",
      "certain  ADJ   \n",
      "degree   NOUN  \n",
      "of       ADP   \n",
      "privacy  NOUN  \n",
      "at       ADP   \n",
      "least    ADJ   \n",
      "I        PRON  \n",
      "can      AUX   \n",
      "not      PART  \n",
      "tell     VERB  \n",
      "what     PRON  \n",
      "the      DET   \n",
      "table    NOUN  \n",
      "next     ADV   \n",
      "to       ADP   \n",
      "me       PRON  \n",
      "were     AUX   \n",
      "eating   VERB  \n",
      ".        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "We       PRON  \n",
      "decided  VERB  \n",
      "on       ADP   \n",
      "my       PRON  \n",
      "favourite ADJ   \n",
      "chives   NOUN  \n",
      "and      CCONJ \n",
      "pork     NOUN  \n",
      "dumplings NOUN  \n",
      ",        PUNCT \n",
      "kimchi   PROPN \n",
      "fried    VERB  \n",
      "rice     NOUN  \n",
      "and      CCONJ \n",
      "Korean   ADJ   \n",
      "cold     ADJ   \n",
      "bucknoodle NOUN  \n",
      "soup     NOUN  \n",
      ".        PUNCT \n",
      "They     PRON  \n",
      "are      AUX   \n",
      "all      ADV   \n",
      "$        SYM   \n",
      "4.99     NUM   \n",
      ".        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "The      DET   \n",
      "cold     ADJ   \n",
      "noodle   NOUN  \n",
      "soup     NOUN  \n",
      "is       AUX   \n",
      "so       ADV   \n",
      "so       ADV   \n",
      "good     ADJ   \n",
      "!        PUNCT \n",
      "Nice     ADJ   \n",
      "and      CCONJ \n",
      "refreshing ADJ   \n",
      "!        PUNCT \n",
      "and      CCONJ \n",
      "the      DET   \n",
      "soup     NOUN  \n",
      "based    VERB  \n",
      "is       AUX   \n",
      "a        DET   \n",
      "little   ADJ   \n",
      "sour     ADJ   \n",
      "and      CCONJ \n",
      "it       PRON  \n",
      "really   ADV   \n",
      "stimulate VERB  \n",
      "your     PRON  \n",
      "tastebuds NOUN  \n",
      "and      CCONJ \n",
      "just     ADV   \n",
      "make     VERB  \n",
      "you      PRON  \n",
      "want     VERB  \n",
      "to       PART  \n",
      "eat      VERB  \n",
      "more     ADJ   \n",
      "!        PUNCT \n",
      "(        PUNCT \n",
      "I        PRON  \n",
      "can      AUX   \n",
      "finish   VERB  \n",
      "it       PRON  \n",
      "all      DET   \n",
      "myself   PRON  \n",
      "!        PUNCT \n",
      "I        PRON  \n",
      "do       AUX   \n",
      "n't      PART  \n",
      "want     VERB  \n",
      "to       PART  \n",
      "share    VERB  \n",
      "!        PUNCT \n",
      "I        PRON  \n",
      "want     VERB  \n",
      "one      NUM   \n",
      "all      DET   \n",
      "for      ADP   \n",
      "myself   PRON  \n",
      "next     ADJ   \n",
      "time     NOUN  \n",
      "!        PUNCT \n",
      ")        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "The      DET   \n",
      "kimchi   PROPN \n",
      "fried    VERB  \n",
      "rice     NOUN  \n",
      "..       PUNCT \n",
      "hmmmmm   ADV   \n",
      "not      PART  \n",
      "good     ADJ   \n",
      "!        PUNCT \n",
      "A        DET   \n",
      "little   ADJ   \n",
      "on       ADP   \n",
      "the      DET   \n",
      "oily     ADJ   \n",
      "side     NOUN  \n",
      ".        PUNCT \n",
      "There    PRON  \n",
      "are      AUX   \n",
      "not      PART  \n",
      "much     ADJ   \n",
      "taste    NOUN  \n",
      ",        PUNCT \n",
      "not      PART  \n",
      "spicy    ADJ   \n",
      "enough   ADV   \n",
      "?        PUNCT \n",
      "We       PRON  \n",
      "could    AUX   \n",
      "not      PART  \n",
      "finish   VERB  \n",
      "it       PRON  \n",
      "and      CCONJ \n",
      "end      VERB  \n",
      "up       ADP   \n",
      "have     VERB  \n",
      "to       PART  \n",
      "pack     VERB  \n",
      "it       PRON  \n",
      "all      DET   \n",
      "to       PART  \n",
      "go       VERB  \n",
      "...      PUNCT \n",
      "(not     INTJ  \n",
      "even     ADV   \n",
      "sure     ADJ   \n",
      "I        PRON  \n",
      "will     AUX   \n",
      "eat      VERB  \n",
      "it       PRON  \n",
      ",        PUNCT \n",
      "but      CCONJ \n",
      "can      AUX   \n",
      "not      PART  \n",
      "just     ADV   \n",
      "let      VERB  \n",
      "it       PRON  \n",
      "all      DET   \n",
      "go       VERB  \n",
      "to       AUX   \n",
      "waste    VERB  \n",
      ")        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "The      DET   \n",
      "dumplings NOUN  \n",
      "arrived  VERB  \n",
      "last     ADJ   \n",
      "!        PUNCT \n",
      "But      CCONJ \n",
      "it       PRON  \n",
      "really   ADV   \n",
      "worth    ADJ   \n",
      "the      DET   \n",
      "wait     NOUN  \n",
      "!        PUNCT \n",
      "14       NUM   \n",
      "big      ADJ   \n",
      "fat      ADJ   \n",
      "hot      ADJ   \n",
      "dumplings NOUN  \n",
      "filled   VERB  \n",
      "up       ADP   \n",
      "the      DET   \n",
      "whole    ADJ   \n",
      "steamer  NOUN  \n",
      "!        PUNCT \n",
      "Yes      INTJ  \n",
      "I        PRON  \n",
      "counted  VERB  \n",
      "them     PRON  \n",
      "14       NUM   \n",
      "of       ADP   \n",
      "them     PRON  \n",
      "for      ADP   \n",
      "$        SYM   \n",
      "4.99     NUM   \n",
      ".        PUNCT \n",
      "They     PRON  \n",
      "are      AUX   \n",
      "all      DET   \n",
      "freshly  ADV   \n",
      "made     VERB  \n",
      ",        PUNCT \n",
      "freshly  ADV   \n",
      "steamed  ADJ   \n",
      "!        PUNCT \n",
      "The      DET   \n",
      "skin     NOUN  \n",
      "is       AUX   \n",
      "nice     ADJ   \n",
      "and      CCONJ \n",
      "thin     ADJ   \n",
      ",        PUNCT \n",
      "not      PART  \n",
      "chewy    NOUN  \n",
      "and      CCONJ \n",
      "thick    ADJ   \n",
      "!        PUNCT \n",
      "Oh       INTJ  \n",
      "so       ADV   \n",
      "delicious ADJ   \n",
      "!        PUNCT \n",
      "One      NUM   \n",
      "bite     NOUN  \n",
      "and      CCONJ \n",
      "all      DET   \n",
      "the      DET   \n",
      "soup     NOUN  \n",
      "are      AUX   \n",
      "ozzing   VERB  \n",
      "out      ADP   \n",
      "!        PUNCT \n",
      "But      CCONJ \n",
      "if       SCONJ \n",
      "they     PRON  \n",
      "are      AUX   \n",
      "not      PART  \n",
      "burning  VERB  \n",
      "hot      ADJ   \n",
      ",        PUNCT \n",
      "you      PRON  \n",
      "can      AUX   \n",
      "just     ADV   \n",
      "stuff    VERB  \n",
      "the      DET   \n",
      "whole    ADJ   \n",
      "thing    NOUN  \n",
      "into     ADP   \n",
      "your     PRON  \n",
      "mouth    NOUN  \n",
      "and      CCONJ \n",
      "let      VERB  \n",
      "the      DET   \n",
      "soup     NOUN  \n",
      "and      CCONJ \n",
      "favour   NOUN  \n",
      "just     ADV   \n",
      "explosed VERB  \n",
      "in       ADP   \n",
      "your     PRON  \n",
      "mouth    NOUN  \n",
      ".        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "Just     ADV   \n",
      "a        DET   \n",
      "warning  NOUN  \n",
      ".        PUNCT \n",
      "If       SCONJ \n",
      "you      PRON  \n",
      "going    VERB  \n",
      "out      ADP   \n",
      "on       ADP   \n",
      "a        DET   \n",
      "date     NOUN  \n",
      ",        PUNCT \n",
      "please   INTJ  \n",
      "do       AUX   \n",
      "n't      PART  \n",
      "come     VERB  \n",
      "here     ADV   \n",
      ".        PUNCT \n",
      "Even     ADV   \n",
      "it       PRON  \n",
      "is       VERB  \n",
      "a        DET   \n",
      "good     ADJ   \n",
      "place    NOUN  \n",
      "for      ADP   \n",
      "a        DET   \n",
      "cheap    ADJ   \n",
      "date     NOUN  \n",
      ",        PUNCT \n",
      "our      PRON  \n",
      "bill     NOUN  \n",
      "was      AUX   \n",
      "$        SYM   \n",
      "18       NUM   \n",
      "for      ADP   \n",
      "2        NUM   \n",
      "and      CCONJ \n",
      "we       PRON  \n",
      "were     VERB  \n",
      "full     ADJ   \n",
      "!        PUNCT \n",
      "But      CCONJ \n",
      "the      DET   \n",
      "place    NOUN  \n",
      "can      AUX   \n",
      "be       VERB  \n",
      "noisy    ADJ   \n",
      ",        PUNCT \n",
      "the      DET   \n",
      "food     NOUN  \n",
      "too      ADV   \n",
      "good     ADJ   \n",
      "and      CCONJ \n",
      "your     PRON  \n",
      "date     NOUN  \n",
      "will     AUX   \n",
      "be       VERB  \n",
      "too      ADV   \n",
      "busy     ADJ   \n",
      "eating   VERB  \n",
      "and      CCONJ \n",
      "just     ADV   \n",
      "ignore   VERB  \n",
      "you      PRON  \n",
      "!        PUNCT \n",
      "Or       CCONJ \n",
      "you      PRON  \n",
      "will     AUX   \n",
      "keep     VERB  \n",
      "eating   VERB  \n",
      "and      CCONJ \n",
      "eating   VERB  \n",
      "and      CCONJ \n",
      "you      PRON  \n",
      "freak    VERB  \n",
      "all      DET   \n",
      "your     PRON  \n",
      "friends  NOUN  \n",
      "out      ADP   \n",
      "!        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "The      DET   \n",
      "services NOUN  \n",
      "here     ADV   \n",
      "is       AUX   \n",
      "cold     ADJ   \n",
      "but      CCONJ \n",
      "efficient ADJ   \n",
      ".        PUNCT \n",
      "We       PRON  \n",
      "were     AUX   \n",
      "given    VERB  \n",
      "extra    ADJ   \n",
      "napkins  NOUN  \n",
      "without  ADP   \n",
      "requesting VERB  \n",
      "...      PUNCT \n",
      "Maybe    ADV   \n",
      "we       PRON  \n",
      "looked   VERB  \n",
      "really   ADV   \n",
      "messy    ADJ   \n",
      "?        PUNCT \n",
      "?        PUNCT \n",
      "\n",
      "\n",
      "       SPACE \n",
      "Cash     VERB  \n",
      "only     ADV   \n",
      "!        PUNCT \n",
      "best     ADJ   \n",
      "pizza    NOUN  \n",
      "in       ADP   \n",
      "south    ADJ   \n",
      "side     NOUN  \n",
      ".        PUNCT \n",
      "huge     ADJ   \n",
      "drink    NOUN  \n",
      "selection NOUN  \n",
      ".        PUNCT \n",
      "awesome  ADJ   \n",
      "atmosphere NOUN  \n",
      ".        PUNCT \n",
      "$        SYM   \n",
      "4        NUM   \n",
      "for      ADP   \n",
      "a        DET   \n",
      "slice    NOUN  \n",
      "that     DET   \n",
      "could    AUX   \n",
      "easily   ADV   \n",
      "feed     VERB  \n",
      "2        NUM   \n",
      "people   NOUN  \n",
      "!        PUNCT \n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true,
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# WORK COMPLETED UP TILL HERE."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Writing Style"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### search how to find a random url"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "source": [
    "# I think that the results of find_all might be more relevant but we can discuss this\n",
    "page1 = requests.get('https://stackoverflow.com/questions/14413969/why-does-next-raise-a-stopiteration-but-for-do-a-normal-return') # def not inspired by any errors that we have been facing\n",
    "soup1 = BeautifulSoup(page1.content, \"html.parser\")\n",
    "text = list(soup1.find_all(\"p\"))\n",
    "text = [txt.get_text() for txt in text]\n",
    "text"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Find centralized, trusted content and collaborate around the technologies you use most.',\n",
       " 'Teams',\n",
       " 'Q&A for work',\n",
       " 'Connect and share knowledge within a single location that is structured and easy to search.',\n",
       " 'In this piece of code, why does using for result in no StopIteration\\nor is the for loop trapping all exceptions and then silently exiting?\\nIn which case, why do we have the extraneous return?? Or is the\\nraise StopIteration caused by: return None?',\n",
       " 'Assuming StopIteration is being triggered by: return None.\\nWhen is GeneratorExit generated?',\n",
       " 'If I manually do a:',\n",
       " \"In which case why don't I see a traceback?\",\n",
       " 'The for loop listens for StopIteration explicitly.',\n",
       " \"The purpose of the for statement is to loop over the sequence provided by an iterator and the exception is used to signal that the iterator is now done; for doesn't catch other exceptions raised by the object being iterated over, just that one.\",\n",
       " \"That's because StopIteration is the normal, expected signal to tell whomever is iterating that there is nothing more to be produced.\",\n",
       " 'A generator function is a special kind of iterator; it indeed raises StopIteration when the function is done (i.e. when it returns, so yes, return None raises StopIteration). It is a requirement of iterators; they must raise StopIteration when they are done; in fact, once a StopIteration has been raised, attempting to get another element from them (through next(), or calling the .next() (py 2) or .__next__() (py 3) method on the iterator) must always raise StopIteration again.',\n",
       " 'GeneratorExit is an exception to communicate in the other direction. You are explicitly closing a generator with a yield expression, and the way Python communicates that closure to the generator is by raising GeneratorExit inside of that function. You explicitly catch that exception inside of countdown, its purpose is to let a generator clean up resources as needed when closing.',\n",
       " 'A GeneratorExit is not propagated to the caller; see the generator.close() documentation.',\n",
       " 'Thanks for contributing an answer to Stack Overflow!',\n",
       " 'But avoid …',\n",
       " 'To learn more, see our tips on writing great answers.',\n",
       " 'Required, but never shown',\n",
       " 'Required, but never shown',\n",
       " '\\r\\n                                                By clicking “Post Your Answer”, you agree to our terms of service, privacy policy and cookie policy\\n',\n",
       " 'To subscribe to this RSS feed, copy and paste this URL into your RSS reader.',\n",
       " '\\r\\nsite design / logo © 2021 Stack Exchange Inc; user contributions licensed under cc by-sa.                    rev\\xa02021.9.10.40187\\n',\n",
       " '\\r\\n                        Your privacy\\r\\n                    ',\n",
       " '\\r\\n                        By clicking “Accept all cookies”, you agree Stack Exchange can store cookies on your device and disclose information in accordance with our Cookie Policy.\\r\\n                    ']"
      ]
     },
     "metadata": {},
     "execution_count": 139
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "page2 = urlopen('https://stackoverflow.com/questions/7239220/creating-an-array-of-structs-in-c')\n",
    "html2 = page2.read().decode(\"utf-8\")\n",
    "soup2 = BeautifulSoup(html2, \"html.parser\")\n",
    "text2 = soup2.get_text()\n",
    "text2 = text2.replace('\\n', ' ')\n",
    "text2 = text2.replace('\\r', ' ')\n",
    "stackoverflow2 = text2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "skipped this section because need to discuss"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Most-frequent (NN, JJ) pairs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "source": [
    "rating1 = reviews.loc[reviews['stars'] == 1]\n",
    "rating1 = rating1.sample(50)\n",
    "rating1 = list(rating1['text'])\n",
    "\n",
    "rating1 = [nlp(rating) for rating in rating1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "doc = nlp(\"this food is the best thing I've had in a long time\")\n",
    "displacy.serve(doc, style=\"dep\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a946aaee58e84c688a1137017a68c194-0\" class=\"displacy\" width=\"2325\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">this</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">food</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">best</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">thing</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">'ve</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">had</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">long</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">time</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a946aaee58e84c688a1137017a68c194-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a946aaee58e84c688a1137017a68c194-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a946aaee58e84c688a1137017a68c194-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a946aaee58e84c688a1137017a68c194-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a946aaee58e84c688a1137017a68c194-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,89.5 920.0,89.5 920.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a946aaee58e84c688a1137017a68c194-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a946aaee58e84c688a1137017a68c194-0-3\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a946aaee58e84c688a1137017a68c194-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a946aaee58e84c688a1137017a68c194-0-4\" stroke-width=\"2px\" d=\"M420,264.5 C420,2.0 925.0,2.0 925.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a946aaee58e84c688a1137017a68c194-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,266.5 L933.0,254.5 917.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a946aaee58e84c688a1137017a68c194-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,89.5 1445.0,89.5 1445.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a946aaee58e84c688a1137017a68c194-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a946aaee58e84c688a1137017a68c194-0-6\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a946aaee58e84c688a1137017a68c194-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a946aaee58e84c688a1137017a68c194-0-7\" stroke-width=\"2px\" d=\"M945,264.5 C945,2.0 1450.0,2.0 1450.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a946aaee58e84c688a1137017a68c194-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,266.5 L1458.0,254.5 1442.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a946aaee58e84c688a1137017a68c194-0-8\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,177.0 1615.0,177.0 1615.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a946aaee58e84c688a1137017a68c194-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1615.0,266.5 L1623.0,254.5 1607.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a946aaee58e84c688a1137017a68c194-0-9\" stroke-width=\"2px\" d=\"M1820,264.5 C1820,89.5 2145.0,89.5 2145.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a946aaee58e84c688a1137017a68c194-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,266.5 L1812,254.5 1828,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a946aaee58e84c688a1137017a68c194-0-10\" stroke-width=\"2px\" d=\"M1995,264.5 C1995,177.0 2140.0,177.0 2140.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a946aaee58e84c688a1137017a68c194-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1995,266.5 L1987,254.5 2003,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a946aaee58e84c688a1137017a68c194-0-11\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,2.0 2150.0,2.0 2150.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a946aaee58e84c688a1137017a68c194-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2150.0,266.5 L2158.0,254.5 2142.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "source": [
    "doc = nlp(\"good food, but service is mediocre\")\n",
    "displacy.serve(doc, style=\"dep\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"744c149611094310b88f925c69a1dbb0-0\" class=\"displacy\" width=\"1100\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">good</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">food,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">but</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">service</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">mediocre</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-744c149611094310b88f925c69a1dbb0-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-744c149611094310b88f925c69a1dbb0-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-744c149611094310b88f925c69a1dbb0-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-744c149611094310b88f925c69a1dbb0-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-744c149611094310b88f925c69a1dbb0-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-744c149611094310b88f925c69a1dbb0-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-744c149611094310b88f925c69a1dbb0-0-3\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-744c149611094310b88f925c69a1dbb0-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-744c149611094310b88f925c69a1dbb0-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-744c149611094310b88f925c69a1dbb0-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "noun_adjective_pairs = []\n",
    "for rating in rating1:\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DISCUSS!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "source": [
    "# TODO \n",
    "noun_adjective_pairs = []\n",
    "for rating in rating1:\n",
    "    for i, token in enumerate(rating):\n",
    "        if token.pos_ not in ('NOUN', 'PROPN'):\n",
    "            continue\n",
    "        for j in range(i + 1, len(rating)):\n",
    "            if rating[j].pos_ == 'ADJ':\n",
    "                noun_adjective_pairs.append((token, rating[j]))\n",
    "                break\n",
    "print(rating1[0])\n",
    "noun_adjective_pairs[:10]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Consistently terrible service (even for a Denny's) at this location. I hadn't been for years because I have always had such awful service here, but after a winning streak at several surrounding Denny's, I thought I'd give \"the bad Denny's\" a try again.\n",
      "\n",
      "Bad mistake. We left before even ordering food and I won't be back again. Went across the street to Olive Garden, which really knows how to elevate mediocre food with excellent service.\n",
      "\n",
      "If you hate food, enjoy depressing scenes of humanity and waiting endlessly for service that doesn't arrive, this is the Denny's of your dreams.\n",
      "\n",
      "All snotty snark aside, the server was very genuinely apologetic for the bad service. I actually felt bad for her. Just not bad enough to waste sixty dollars on awful food.\n",
      "\n",
      "Nice try, Denny's.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(service, such),\n",
       " (Denny, such),\n",
       " (location, such),\n",
       " (years, such),\n",
       " (service, several),\n",
       " (streak, several),\n",
       " (Denny, bad),\n",
       " (Denny, Bad),\n",
       " (try, Bad),\n",
       " (mistake, mediocre)]"
      ]
     },
     "metadata": {},
     "execution_count": 140
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Jeth\n",
    "\n",
    "lol i can't stand using nltk since it's slower than spacy so lemme put some spacy code here and we can also compare the results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Indicative Adjective"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "source": [
    "# hi cloud, i need your linguistic knowledge to help me out here\n",
    "def get_adjective_phrases(text):\n",
    "    doc = nlp(text)\n",
    "    phrases = []\n",
    "    for token in doc:\n",
    "        phrase = ''\n",
    "        if (token.pos_ == 'ADJ') and (token.dep_ in ['dobj','pobj','nsubj','nsubjpass']):\n",
    "            for subtoken in token.children:\n",
    "                if (subtoken.pos_ == 'ADJ') or (subtoken.pos_ == 'ADV') or (subtoken.dep_ == 'compound'):\n",
    "                    phrase += subtoken.text + ' '\n",
    "            if len(phrase)!=0:\n",
    "                phrase += token.text\n",
    "        if  len(phrase)!=0:\n",
    "            phrases.append(phrase)\n",
    "    return phrases"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "source": [
    "adjective_phrases = get_adjective_phrases(clean_review)\n",
    "adjective_phrases[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['cooked poor',\n",
       " 'empty handed',\n",
       " 'very good',\n",
       " 'so much',\n",
       " 'probably best',\n",
       " 'just as bad',\n",
       " 'as much',\n",
       " 'little pricey']"
      ]
     },
     "metadata": {},
     "execution_count": 137
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "source": [
    "indicative_phrases = Counter(adjective_phrases).most_common(10)\n",
    "indicative_phrases"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('cooked poor', 1),\n",
       " ('empty handed', 1),\n",
       " ('very good', 1),\n",
       " ('so much', 1),\n",
       " ('probably best', 1),\n",
       " ('just as bad', 1),\n",
       " ('as much', 1),\n",
       " ('little pricey', 1)]"
      ]
     },
     "metadata": {},
     "execution_count": 138
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "i think the above can be turned into a function so that it takes in a random business id and it returns the most common phrases: to be discussed"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}